{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path\n",
    "import errno\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "if sys.version_info[0] == 2:\n",
    "    import cPickle as pickle\n",
    "else:\n",
    "    import pickle\n",
    "\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "NUM_TRAIN=49000\n",
    "train_batch_size=4\n",
    "test_batch_size=4\n",
    "\n",
    "\n",
    "cifar10_train = torchvision.datasets.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = torch.utils.data.DataLoader(cifar10_train, batch_size=train_batch_size, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = torchvision.datasets.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = torch.utils.data.DataLoader(cifar10_val, batch_size=train_batch_size, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "cifar10_test = torchvision.datasets.CIFAR10('./cs231n/datasets', train=False, download=True, \n",
    "                            transform=transform)\n",
    "loader_test = torch.utils.data.DataLoader(cifar10_test, batch_size=test_batch_size)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 32, 32, 3)\n",
      "(1000, 32, 32, 3)\n",
      "(5000, 32, 32, 3)\n",
      "(1000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as dset\n",
    "from PIL import Image    \n",
    "import os\n",
    "import os.path\n",
    "import errno\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "class CIFAR100(dset.CIFAR10):\n",
    "\n",
    "    base_folder = '.'\n",
    "    train_list = [\n",
    "        ['train', '16019d7e3df5f24257cddd939b257f8d'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test', 'f0ef6b0ae62326f3e7ffdfab6717acfc'],\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, root, train=True,\n",
    "                 transform=None, target_transform=None,\n",
    "                 download=False):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train  # training set or test set\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError('Dataset not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        # now load the picked numpy arrays\n",
    "        self.test_data = []\n",
    "        if self.train:\n",
    "            self.train_data = []\n",
    "            self.train_labels = []\n",
    "            for fentry in self.train_list:\n",
    "                f = fentry[0]\n",
    "                file = os.path.join(self.root, self.base_folder, f)\n",
    "                fo = open(file, 'rb')\n",
    "                if sys.version_info[0] == 2:\n",
    "                    entry = pickle.load(fo)\n",
    "                else:\n",
    "                    entry = pickle.load(fo, encoding='latin1')\n",
    "                self.train_data.append(entry['data'])\n",
    "                if 'labels' in entry:\n",
    "                    self.train_labels += entry['labels']\n",
    "                else:\n",
    "                    self.train_labels += entry['fine_labels']\n",
    "                fo.close()\n",
    "\n",
    "            self.train_data = np.concatenate(self.train_data)\n",
    "            self.train_data = self.train_data.reshape((5000, 3, 32, 32))\n",
    "            self.train_data = self.train_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "            print(self.train_data.shape)\n",
    "        else:\n",
    "            f = 'test'\n",
    "            file = os.path.join(self.root, self.base_folder, f)\n",
    "            fo = open(file, 'rb')\n",
    "            if sys.version_info[0] == 2:\n",
    "                entry = pickle.load(fo)\n",
    "            else:\n",
    "                entry = pickle.load(fo, encoding='latin1')\n",
    "            self.test_data = np.array(entry['data'])\n",
    "            if 'labels' in entry:\n",
    "                self.test_labels = entry['data']\n",
    "            else:\n",
    "                self.test_labels = entry['fine_labels']\n",
    "            fo.close()\n",
    "            self.test_data = self.test_data.reshape((1000, 3, 32, 32))\n",
    "            self.test_data = self.test_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "            print(self.test_data.shape)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        if self.train:\n",
    "            img, target = self.train_data[index], self.train_labels[index]\n",
    "        else:\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img.astype('uint8')).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)                \n",
    "            \n",
    "    def _check_integrity(self):\n",
    "        return True\n",
    "    \n",
    "\n",
    "\n",
    "if sys.version_info[0] == 2:\n",
    "    import cPickle as pickle\n",
    "else:\n",
    "    import pickle\n",
    "\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "A_train = CIFAR100('./class1', train=True, download=False,\n",
    "                             transform=transform)\n",
    "loaderA_train = torch.utils.data.DataLoader(A_train, batch_size=4)\n",
    "\n",
    "\n",
    "\n",
    "A_test = CIFAR100('./class1', train=False, download=False,\n",
    "                             transform=transform)\n",
    "loaderA_test = torch.utils.data.DataLoader(A_test, batch_size=4)\n",
    "\n",
    "\n",
    "B_train = CIFAR100('./class2', train=True, download=False,\n",
    "                             transform=transform)\n",
    "loaderB_train = torch.utils.data.DataLoader(B_train, batch_size=4)\n",
    "\n",
    "\n",
    "B_test = CIFAR100('./class2', train=False, download=False,\n",
    "                             transform=transform)\n",
    "loaderB_test = torch.utils.data.DataLoader(B_test, batch_size=4)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right\n"
     ]
    }
   ],
   "source": [
    "class ConvPool_CNN_C(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super (ConvPool_CNN_C, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 96, kernel_size=3, stride=1, padding=1)\n",
    "        nn.init.kaiming_normal_(self.conv1.weight)\n",
    "        nn.init.constant_(self.conv1.bias, 0)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout2d(0.2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(96, 96, kernel_size=3, stride=1, padding=1)\n",
    "        nn.init.kaiming_normal_(self.conv2.weight)\n",
    "        nn.init.constant_(self.conv2.bias, 0)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(96, 96, kernel_size=3, stride=1, padding=1)\n",
    "        nn.init.kaiming_normal_(self.conv3.weight)\n",
    "        nn.init.constant_(self.conv3.bias, 0)\n",
    "        \n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(96, 192, kernel_size=3, stride=1, padding=1)\n",
    "        nn.init.kaiming_normal_(self.conv4.weight)\n",
    "        nn.init.constant_(self.conv4.bias, 0)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(192, 192, kernel_size=3, stride=1, padding=1)\n",
    "        nn.init.kaiming_normal_(self.conv5.weight)\n",
    "        nn.init.constant_(self.conv5.bias, 0)\n",
    "        \n",
    "        self.conv6 = nn.Conv2d(192, 192, kernel_size=3, stride=1, padding=1)\n",
    "        nn.init.kaiming_normal_(self.conv6.weight)\n",
    "        nn.init.constant_(self.conv6.bias, 0)\n",
    "        \n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(192, 192, kernel_size=3, padding=3)\n",
    "        nn.init.kaiming_normal_(self.conv7.weight)\n",
    "        nn.init.constant_(self.conv7.bias, 0)\n",
    "        \n",
    "        self.conv8 = nn.Conv2d(192, 192, kernel_size=1)\n",
    "        nn.init.kaiming_normal_(self.conv8.weight)\n",
    "        nn.init.constant_(self.conv8.bias, 0)\n",
    "        \n",
    "        self.conv9 = nn.Conv2d(192, self.num_classes, kernel_size=1)\n",
    "        nn.init.kaiming_normal_(self.conv9.weight)\n",
    "        nn.init.constant_(self.conv9.bias, 0)\n",
    "        \n",
    "        self.glb_avg = nn.AvgPool2d(6)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = self.dropout1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.maxpool1(out)\n",
    "        out = self.dropout2(out)\n",
    "        \n",
    "        out = self.conv4(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.conv5(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.conv6(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.maxpool2(out)\n",
    "        out = self.dropout3(out)\n",
    "        \n",
    "        out = self.conv7(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.conv8(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.conv9(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.glb_avg(out)\n",
    "        out = out.view(-1, self.num_classes)\n",
    "        return out\n",
    "import new_ALL_Conv\n",
    "convpool_cnn_c = new_ALL_Conv.ConvPool_CNN_C()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import cPickle\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "USE_GPU = True\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples *100\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples,  acc))\n",
    "    return acc*100\n",
    "\n",
    "def running_model_B(run_num, net, net_name, lr_list, epoch_list, loader_train, \n",
    "                   loader_test):\n",
    "    train_batch_size = 4\n",
    "    test_batch_size = 4\n",
    "    \n",
    "\n",
    "    # Constant to control how frequently we print train loss\n",
    "    print_every = 100\n",
    "\n",
    "    print('using device:', device)\n",
    "    \n",
    "    #net = BaseNet_A()\n",
    "    net = net.to(device=device)\n",
    "    criterion = nn.CrossEntropyLoss()        \n",
    "        \n",
    "    lr_1, lr_2, lr_3, lr_4 = lr_list[0], lr_list[1], lr_list[2], lr_list[3]\n",
    "    weight_decay = 0.001\n",
    "\n",
    "    max_epoch = 350\n",
    "    display_interval = 500\n",
    "\n",
    "    train_size = 5000\n",
    "    test_size = 1000\n",
    "\n",
    "    num_train_batch = train_size/train_batch_size\n",
    "    num_test_batch = test_size/test_batch_size\n",
    "\n",
    "    train_loss = np.zeros((max_epoch,1))\n",
    "    val_acc = np.zeros((max_epoch,1))\n",
    "    #train_acc = np.zeros((max_epoch,1))\n",
    "    #test_loss = np.zeros((max_epoch,1))\n",
    "    #test_acc = np.zeros((max_epoch,1))\n",
    "\n",
    "    epoch_acc = [] # max_epoch x num\n",
    "    print(\"begin training\")\n",
    "    for epoch in range(max_epoch):\n",
    "        if(epoch<epoch_list[0]):\n",
    "            lr = lr_1\n",
    "        elif(epoch<epoch_list[1]):\n",
    "            lr = lr_2\n",
    "        elif(epoch<epoch_list[2]):\n",
    "            lr = lr_3\n",
    "        else:\n",
    "            lr = lr_4\n",
    "    \n",
    "        optimizer = optim.SGD( net.parameters(), lr=0.001,\n",
    "                              momentum=0.9, weight_decay=weight_decay)\n",
    "    \n",
    "        running_epoch_loss = 0.\n",
    "        running_loss_print = 0.\n",
    "        epoch_total_num = 0\n",
    "        correct_num = 0\n",
    "    \n",
    "        i_acc = []\n",
    "        #for i, data in enumerate(trainloader):\n",
    "        for i, data in enumerate(loader_train):\n",
    "            net.train()\n",
    "        \n",
    "            inputs_data, labels_data = data\n",
    "            inputs, labels = Variable(inputs_data), Variable(labels_data)\n",
    "            inputs = inputs.to(device=device, dtype=dtype)\n",
    "            labels = labels.to(device=device, dtype=torch.long)\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            running_epoch_loss += loss.item()\n",
    "            running_loss_print += loss.item()\n",
    "            if i%500 == 499: #net a, b, c 500 print once\n",
    "                \n",
    "                acc = check_accuracy(loader_test, net)\n",
    "                i_acc.append(acc)\n",
    "                print('%d epoch, %5d iteration, loss:%.3f' \n",
    "                      %(epoch+1, i+1, running_loss_print/500) )\n",
    "                running_loss_print = 0.\n",
    "            \n",
    "            #_, pred = torch.max(outputs, 1)\n",
    "            #epoch_total_num += labels.size(0)\n",
    "            #correct_num += (pred==labels).sum()\n",
    "        \n",
    "        \n",
    "        train_loss[epoch] = running_epoch_loss/num_train_batch\n",
    "        epoch_acc.append(i_acc)\n",
    "        \n",
    "        val_acc[epoch] = np.sum(epoch_acc[epoch])/49\n",
    "        #val_acc[epoch] = np.sum(epoch_acc[epoch])\n",
    "        #train_acc[epoch] = correct_num/epoch_total_num*100\n",
    "    \n",
    "    \n",
    "        # test accuracy and loss\n",
    "        '''\n",
    "        ts_runningloss_epoch = 0.\n",
    "        ts_correct = 0\n",
    "        ts_epoch_num = 0\n",
    "        for data in testloader:\n",
    "            inputs_data, labels_data = data\n",
    "            inputs, labels = Variable(inputs_data), Variable(labels_data)\n",
    "            inputs = inputs.to(device=device, dtype=dtype)\n",
    "            labels = labels.to(device=device, dtype=torch.long)\n",
    "        \n",
    "            net.eval()\n",
    "            ts_outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "            ts_runningloss_epoch += loss.item()\n",
    "            _, ts_pred = torch.max(ts_outputs, 1)\n",
    "        \n",
    "            ts_epoch_num += labels.size(0)\n",
    "            ts_correct += (ts_pred==labels).sum()\n",
    "        test_loss[epoch] = ts_runningloss_epoch/num_test_batch\n",
    "        test_acc[epoch] = ts_correct/ts_epoch_num*100\n",
    "        '''\n",
    "        print(\" num %d epoch \" %epoch)\n",
    "        print(\"####### Training Loss #######\")\n",
    "        print(train_loss[epoch])\n",
    "        #print(\"####### Validation Accuracy #######\")\n",
    "        #print(val_acc[epoch])\n",
    "        #print(\"####### Training Accuracy #######\")\n",
    "        #print(train_acc[epoch])\n",
    "        #print(\"####### Testing Loss #######\")\n",
    "        #print(test_loss[epoch])\n",
    "        #print(\"####### Testing Accuracy #######\")\n",
    "        #print(test_acc[epoch])\n",
    "    \n",
    "    print('finish training \\n')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "##################################################################################################\n",
    "    print('now begin saving datum for next step plotting')\n",
    "    \n",
    "    save_path = '../datum_for_plotting/run_num_' + str(run_num)+'/'+ net_name\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    f = open(save_path + '/train_loss.save', 'wb')\n",
    "    cPickle.dump(train_loss, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "\n",
    "    f = open(save_path + '/val_acc.save', 'wb')\n",
    "    cPickle.dump(val_acc, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "\n",
    "    f = open(save_path + '/epoch_acc.save', 'wb')\n",
    "    cPickle.dump(epoch_acc, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "\n",
    "    array_epoch_acc = np.array(epoch_acc)\n",
    "    f = open(save_path + '/array_epoch_acc.save', 'wb')\n",
    "    cPickle.dump(array_epoch_acc, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "\n",
    "    f = open(save_path + '/test_acc.save', 'wb')\n",
    "    cPickle.dump(test_acc, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "\n",
    "    torch.save(net, save_path+'/'+ net_name +'.pkl') # save whole net structure and params\n",
    "    torch.save(net.state_dict, save_path+'/'+ net_name +'_params.pkl') # only save model params\n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "##################################################################################################    \n",
    "    print(\"now plotting accuracies and losses\")  \n",
    "    itern_axis_train = np.array(np.linspace(1,max_epoch,num=max_epoch))\n",
    "    itern_axis_test = np.array(np.linspace(1,max_epoch, num=max_epoch))\n",
    "\n",
    "    plt.plot(itern_axis_train, train_loss,'-b.', label='Train')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.savefig(save_path + '/train_loss' + str(max_epoch) + '.png')\n",
    "    \n",
    "    a = np.concatenate(array_epoch_acc)\n",
    "    length = a.shape[0]\n",
    "    plt.plot(length, a, '--r', label='Test')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('loss')\n",
    "    plt.savefig(save_path + '/testing_accuracy' + str(max_epoch) + '.png')\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n",
      "begin training\n",
      "Checking accuracy on test set\n",
      "Got 97 / 1000 correct (9.70)\n",
      "1 epoch,   500 iteration, loss:2.307\n",
      "Checking accuracy on test set\n",
      "Got 100 / 1000 correct (10.00)\n",
      "1 epoch,  1000 iteration, loss:2.302\n",
      " num 0 epoch \n",
      "####### Training Loss #######\n",
      "[2.30412699]\n",
      "Checking accuracy on test set\n",
      "Got 102 / 1000 correct (10.20)\n",
      "2 epoch,   500 iteration, loss:2.303\n",
      "Checking accuracy on test set\n",
      "Got 104 / 1000 correct (10.40)\n",
      "2 epoch,  1000 iteration, loss:2.302\n",
      " num 1 epoch \n",
      "####### Training Loss #######\n",
      "[2.30241282]\n",
      "Checking accuracy on test set\n",
      "Got 98 / 1000 correct (9.80)\n",
      "3 epoch,   500 iteration, loss:2.302\n",
      "Checking accuracy on test set\n",
      "Got 114 / 1000 correct (11.40)\n",
      "3 epoch,  1000 iteration, loss:2.301\n",
      " num 2 epoch \n",
      "####### Training Loss #######\n",
      "[2.30114633]\n",
      "Checking accuracy on test set\n",
      "Got 158 / 1000 correct (15.80)\n",
      "4 epoch,   500 iteration, loss:2.301\n",
      "Checking accuracy on test set\n",
      "Got 168 / 1000 correct (16.80)\n",
      "4 epoch,  1000 iteration, loss:2.293\n",
      " num 3 epoch \n",
      "####### Training Loss #######\n",
      "[2.29680176]\n",
      "Checking accuracy on test set\n",
      "Got 166 / 1000 correct (16.60)\n",
      "5 epoch,   500 iteration, loss:2.295\n",
      "Checking accuracy on test set\n",
      "Got 152 / 1000 correct (15.20)\n",
      "5 epoch,  1000 iteration, loss:2.283\n",
      " num 4 epoch \n",
      "####### Training Loss #######\n",
      "[2.28661029]\n",
      "Checking accuracy on test set\n",
      "Got 167 / 1000 correct (16.70)\n",
      "6 epoch,   500 iteration, loss:2.290\n",
      "Checking accuracy on test set\n",
      "Got 153 / 1000 correct (15.30)\n",
      "6 epoch,  1000 iteration, loss:2.275\n",
      " num 5 epoch \n",
      "####### Training Loss #######\n",
      "[2.2811299]\n",
      "Checking accuracy on test set\n",
      "Got 185 / 1000 correct (18.50)\n",
      "7 epoch,   500 iteration, loss:2.281\n",
      "Checking accuracy on test set\n",
      "Got 215 / 1000 correct (21.50)\n",
      "7 epoch,  1000 iteration, loss:2.256\n",
      " num 6 epoch \n",
      "####### Training Loss #######\n",
      "[2.26205313]\n",
      "Checking accuracy on test set\n",
      "Got 234 / 1000 correct (23.40)\n",
      "8 epoch,   500 iteration, loss:2.249\n",
      "Checking accuracy on test set\n",
      "Got 272 / 1000 correct (27.20)\n",
      "8 epoch,  1000 iteration, loss:2.197\n",
      " num 7 epoch \n",
      "####### Training Loss #######\n",
      "[2.20408468]\n",
      "Checking accuracy on test set\n",
      "Got 267 / 1000 correct (26.70)\n",
      "9 epoch,   500 iteration, loss:2.074\n",
      "Checking accuracy on test set\n",
      "Got 344 / 1000 correct (34.40)\n",
      "9 epoch,  1000 iteration, loss:2.016\n",
      " num 8 epoch \n",
      "####### Training Loss #######\n",
      "[2.01517568]\n",
      "Checking accuracy on test set\n",
      "Got 327 / 1000 correct (32.70)\n",
      "10 epoch,   500 iteration, loss:1.939\n",
      "Checking accuracy on test set\n",
      "Got 347 / 1000 correct (34.70)\n",
      "10 epoch,  1000 iteration, loss:1.882\n",
      " num 9 epoch \n",
      "####### Training Loss #######\n",
      "[1.88573155]\n",
      "Checking accuracy on test set\n",
      "Got 388 / 1000 correct (38.80)\n",
      "11 epoch,   500 iteration, loss:1.827\n",
      "Checking accuracy on test set\n",
      "Got 366 / 1000 correct (36.60)\n",
      "11 epoch,  1000 iteration, loss:1.768\n",
      " num 10 epoch \n",
      "####### Training Loss #######\n",
      "[1.76784549]\n",
      "Checking accuracy on test set\n",
      "Got 443 / 1000 correct (44.30)\n",
      "12 epoch,   500 iteration, loss:1.687\n",
      "Checking accuracy on test set\n",
      "Got 421 / 1000 correct (42.10)\n",
      "12 epoch,  1000 iteration, loss:1.621\n",
      " num 11 epoch \n",
      "####### Training Loss #######\n",
      "[1.62872145]\n",
      "Checking accuracy on test set\n",
      "Got 491 / 1000 correct (49.10)\n",
      "13 epoch,   500 iteration, loss:1.564\n",
      "Checking accuracy on test set\n",
      "Got 502 / 1000 correct (50.20)\n",
      "13 epoch,  1000 iteration, loss:1.508\n",
      " num 12 epoch \n",
      "####### Training Loss #######\n",
      "[1.51072459]\n",
      "Checking accuracy on test set\n",
      "Got 543 / 1000 correct (54.30)\n",
      "14 epoch,   500 iteration, loss:1.466\n",
      "Checking accuracy on test set\n",
      "Got 519 / 1000 correct (51.90)\n",
      "14 epoch,  1000 iteration, loss:1.412\n",
      " num 13 epoch \n",
      "####### Training Loss #######\n",
      "[1.41785412]\n",
      "Checking accuracy on test set\n",
      "Got 556 / 1000 correct (55.60)\n",
      "15 epoch,   500 iteration, loss:1.359\n",
      "Checking accuracy on test set\n",
      "Got 542 / 1000 correct (54.20)\n",
      "15 epoch,  1000 iteration, loss:1.325\n",
      " num 14 epoch \n",
      "####### Training Loss #######\n",
      "[1.3248061]\n",
      "Checking accuracy on test set\n",
      "Got 603 / 1000 correct (60.30)\n",
      "16 epoch,   500 iteration, loss:1.253\n",
      "Checking accuracy on test set\n",
      "Got 585 / 1000 correct (58.50)\n",
      "16 epoch,  1000 iteration, loss:1.254\n",
      " num 15 epoch \n",
      "####### Training Loss #######\n",
      "[1.23409229]\n",
      "Checking accuracy on test set\n",
      "Got 603 / 1000 correct (60.30)\n",
      "17 epoch,   500 iteration, loss:1.211\n",
      "Checking accuracy on test set\n",
      "Got 584 / 1000 correct (58.40)\n",
      "17 epoch,  1000 iteration, loss:1.191\n",
      " num 16 epoch \n",
      "####### Training Loss #######\n",
      "[1.17867328]\n",
      "Checking accuracy on test set\n",
      "Got 587 / 1000 correct (58.70)\n",
      "18 epoch,   500 iteration, loss:1.146\n",
      "Checking accuracy on test set\n",
      "Got 607 / 1000 correct (60.70)\n",
      "18 epoch,  1000 iteration, loss:1.137\n",
      " num 17 epoch \n",
      "####### Training Loss #######\n",
      "[1.12693971]\n",
      "Checking accuracy on test set\n",
      "Got 639 / 1000 correct (63.90)\n",
      "19 epoch,   500 iteration, loss:1.091\n",
      "Checking accuracy on test set\n",
      "Got 595 / 1000 correct (59.50)\n",
      "19 epoch,  1000 iteration, loss:1.066\n",
      " num 18 epoch \n",
      "####### Training Loss #######\n",
      "[1.06199783]\n",
      "Checking accuracy on test set\n",
      "Got 635 / 1000 correct (63.50)\n",
      "20 epoch,   500 iteration, loss:1.045\n",
      "Checking accuracy on test set\n",
      "Got 617 / 1000 correct (61.70)\n",
      "20 epoch,  1000 iteration, loss:1.028\n",
      " num 19 epoch \n",
      "####### Training Loss #######\n",
      "[1.01958646]\n",
      "Checking accuracy on test set\n",
      "Got 651 / 1000 correct (65.10)\n",
      "21 epoch,   500 iteration, loss:0.989\n",
      "Checking accuracy on test set\n",
      "Got 647 / 1000 correct (64.70)\n",
      "21 epoch,  1000 iteration, loss:0.992\n",
      " num 20 epoch \n",
      "####### Training Loss #######\n",
      "[0.97698432]\n",
      "Checking accuracy on test set\n",
      "Got 661 / 1000 correct (66.10)\n",
      "22 epoch,   500 iteration, loss:0.954\n",
      "Checking accuracy on test set\n",
      "Got 629 / 1000 correct (62.90)\n",
      "22 epoch,  1000 iteration, loss:0.925\n",
      " num 21 epoch \n",
      "####### Training Loss #######\n",
      "[0.92518934]\n",
      "Checking accuracy on test set\n",
      "Got 665 / 1000 correct (66.50)\n",
      "23 epoch,   500 iteration, loss:0.906\n",
      "Checking accuracy on test set\n",
      "Got 659 / 1000 correct (65.90)\n",
      "23 epoch,  1000 iteration, loss:0.903\n",
      " num 22 epoch \n",
      "####### Training Loss #######\n",
      "[0.88771534]\n",
      "Checking accuracy on test set\n",
      "Got 644 / 1000 correct (64.40)\n",
      "24 epoch,   500 iteration, loss:0.851\n",
      "Checking accuracy on test set\n",
      "Got 636 / 1000 correct (63.60)\n",
      "24 epoch,  1000 iteration, loss:0.863\n",
      " num 23 epoch \n",
      "####### Training Loss #######\n",
      "[0.83715363]\n",
      "Checking accuracy on test set\n",
      "Got 685 / 1000 correct (68.50)\n",
      "25 epoch,   500 iteration, loss:0.834\n",
      "Checking accuracy on test set\n",
      "Got 684 / 1000 correct (68.40)\n",
      "25 epoch,  1000 iteration, loss:0.836\n",
      " num 24 epoch \n",
      "####### Training Loss #######\n",
      "[0.80970625]\n",
      "Checking accuracy on test set\n",
      "Got 674 / 1000 correct (67.40)\n",
      "26 epoch,   500 iteration, loss:0.785\n",
      "Checking accuracy on test set\n",
      "Got 655 / 1000 correct (65.50)\n",
      "26 epoch,  1000 iteration, loss:0.794\n",
      " num 25 epoch \n",
      "####### Training Loss #######\n",
      "[0.7754769]\n",
      "Checking accuracy on test set\n",
      "Got 680 / 1000 correct (68.00)\n",
      "27 epoch,   500 iteration, loss:0.768\n",
      "Checking accuracy on test set\n",
      "Got 686 / 1000 correct (68.60)\n",
      "27 epoch,  1000 iteration, loss:0.740\n",
      " num 26 epoch \n",
      "####### Training Loss #######\n",
      "[0.7387653]\n",
      "Checking accuracy on test set\n",
      "Got 676 / 1000 correct (67.60)\n",
      "28 epoch,   500 iteration, loss:0.723\n",
      "Checking accuracy on test set\n",
      "Got 682 / 1000 correct (68.20)\n",
      "28 epoch,  1000 iteration, loss:0.712\n",
      " num 27 epoch \n",
      "####### Training Loss #######\n",
      "[0.70493816]\n",
      "Checking accuracy on test set\n",
      "Got 711 / 1000 correct (71.10)\n",
      "29 epoch,   500 iteration, loss:0.713\n",
      "Checking accuracy on test set\n",
      "Got 668 / 1000 correct (66.80)\n",
      "29 epoch,  1000 iteration, loss:0.665\n",
      " num 28 epoch \n",
      "####### Training Loss #######\n",
      "[0.67838653]\n",
      "Checking accuracy on test set\n",
      "Got 688 / 1000 correct (68.80)\n",
      "30 epoch,   500 iteration, loss:0.655\n",
      "Checking accuracy on test set\n",
      "Got 697 / 1000 correct (69.70)\n",
      "30 epoch,  1000 iteration, loss:0.636\n",
      " num 29 epoch \n",
      "####### Training Loss #######\n",
      "[0.63580171]\n",
      "Checking accuracy on test set\n",
      "Got 693 / 1000 correct (69.30)\n",
      "31 epoch,   500 iteration, loss:0.625\n",
      "Checking accuracy on test set\n",
      "Got 684 / 1000 correct (68.40)\n",
      "31 epoch,  1000 iteration, loss:0.615\n",
      " num 30 epoch \n",
      "####### Training Loss #######\n",
      "[0.59987469]\n",
      "Checking accuracy on test set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "32 epoch,   500 iteration, loss:0.629\n",
      "Checking accuracy on test set\n",
      "Got 650 / 1000 correct (65.00)\n",
      "32 epoch,  1000 iteration, loss:0.622\n",
      " num 31 epoch \n",
      "####### Training Loss #######\n",
      "[0.60688531]\n",
      "Checking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 705 / 1000 correct (70.50)\n",
      "33 epoch,   500 iteration, loss:0.586\n",
      "Checking accuracy on test set\n",
      "Got 692 / 1000 correct (69.20)\n",
      "33 epoch,  1000 iteration, loss:0.589\n",
      " num 32 epoch \n",
      "####### Training Loss #######\n",
      "[0.57235052]\n",
      "Checking accuracy on test set\n",
      "Got 725 / 1000 correct (72.50)\n",
      "34 epoch,   500 iteration, loss:0.546\n",
      "Checking accuracy on test set\n",
      "Got 693 / 1000 correct (69.30)\n",
      "34 epoch,  1000 iteration, loss:0.581\n",
      " num 33 epoch \n",
      "####### Training Loss #######\n",
      "[0.55203993]\n",
      "Checking accuracy on test set\n",
      "Got 717 / 1000 correct (71.70)\n",
      "35 epoch,   500 iteration, loss:0.523\n",
      "Checking accuracy on test set\n",
      "Got 711 / 1000 correct (71.10)\n",
      "35 epoch,  1000 iteration, loss:0.528\n",
      " num 34 epoch \n",
      "####### Training Loss #######\n",
      "[0.51936967]\n",
      "Checking accuracy on test set\n",
      "Got 694 / 1000 correct (69.40)\n",
      "36 epoch,   500 iteration, loss:0.508\n",
      "Checking accuracy on test set\n",
      "Got 681 / 1000 correct (68.10)\n",
      "36 epoch,  1000 iteration, loss:0.527\n",
      " num 35 epoch \n",
      "####### Training Loss #######\n",
      "[0.51074522]\n",
      "Checking accuracy on test set\n",
      "Got 719 / 1000 correct (71.90)\n",
      "37 epoch,   500 iteration, loss:0.506\n",
      "Checking accuracy on test set\n",
      "Got 712 / 1000 correct (71.20)\n",
      "37 epoch,  1000 iteration, loss:0.467\n",
      " num 36 epoch \n",
      "####### Training Loss #######\n",
      "[0.47760412]\n",
      "Checking accuracy on test set\n",
      "Got 691 / 1000 correct (69.10)\n",
      "38 epoch,   500 iteration, loss:0.497\n",
      "Checking accuracy on test set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "38 epoch,  1000 iteration, loss:0.491\n",
      " num 37 epoch \n",
      "####### Training Loss #######\n",
      "[0.47397107]\n",
      "Checking accuracy on test set\n",
      "Got 694 / 1000 correct (69.40)\n",
      "39 epoch,   500 iteration, loss:0.446\n",
      "Checking accuracy on test set\n",
      "Got 679 / 1000 correct (67.90)\n",
      "39 epoch,  1000 iteration, loss:0.458\n",
      " num 38 epoch \n",
      "####### Training Loss #######\n",
      "[0.45215183]\n",
      "Checking accuracy on test set\n",
      "Got 721 / 1000 correct (72.10)\n",
      "40 epoch,   500 iteration, loss:0.450\n",
      "Checking accuracy on test set\n",
      "Got 715 / 1000 correct (71.50)\n",
      "40 epoch,  1000 iteration, loss:0.429\n",
      " num 39 epoch \n",
      "####### Training Loss #######\n",
      "[0.43666761]\n",
      "Checking accuracy on test set\n",
      "Got 705 / 1000 correct (70.50)\n",
      "41 epoch,   500 iteration, loss:0.422\n",
      "Checking accuracy on test set\n",
      "Got 692 / 1000 correct (69.20)\n",
      "41 epoch,  1000 iteration, loss:0.388\n",
      " num 40 epoch \n",
      "####### Training Loss #######\n",
      "[0.39796667]\n",
      "Checking accuracy on test set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "42 epoch,   500 iteration, loss:0.406\n",
      "Checking accuracy on test set\n",
      "Got 721 / 1000 correct (72.10)\n",
      "42 epoch,  1000 iteration, loss:0.405\n",
      " num 41 epoch \n",
      "####### Training Loss #######\n",
      "[0.39858851]\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "43 epoch,   500 iteration, loss:0.396\n",
      "Checking accuracy on test set\n",
      "Got 720 / 1000 correct (72.00)\n",
      "43 epoch,  1000 iteration, loss:0.403\n",
      " num 42 epoch \n",
      "####### Training Loss #######\n",
      "[0.39028214]\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "44 epoch,   500 iteration, loss:0.354\n",
      "Checking accuracy on test set\n",
      "Got 714 / 1000 correct (71.40)\n",
      "44 epoch,  1000 iteration, loss:0.381\n",
      " num 43 epoch \n",
      "####### Training Loss #######\n",
      "[0.36392381]\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "45 epoch,   500 iteration, loss:0.349\n",
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "45 epoch,  1000 iteration, loss:0.387\n",
      " num 44 epoch \n",
      "####### Training Loss #######\n",
      "[0.35611423]\n",
      "Checking accuracy on test set\n",
      "Got 716 / 1000 correct (71.60)\n",
      "46 epoch,   500 iteration, loss:0.354\n",
      "Checking accuracy on test set\n",
      "Got 721 / 1000 correct (72.10)\n",
      "46 epoch,  1000 iteration, loss:0.340\n",
      " num 45 epoch \n",
      "####### Training Loss #######\n",
      "[0.34569368]\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "47 epoch,   500 iteration, loss:0.309\n",
      "Checking accuracy on test set\n",
      "Got 709 / 1000 correct (70.90)\n",
      "47 epoch,  1000 iteration, loss:0.355\n",
      " num 46 epoch \n",
      "####### Training Loss #######\n",
      "[0.32475894]\n",
      "Checking accuracy on test set\n",
      "Got 732 / 1000 correct (73.20)\n",
      "48 epoch,   500 iteration, loss:0.289\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "48 epoch,  1000 iteration, loss:0.315\n",
      " num 47 epoch \n",
      "####### Training Loss #######\n",
      "[0.29816546]\n",
      "Checking accuracy on test set\n",
      "Got 710 / 1000 correct (71.00)\n",
      "49 epoch,   500 iteration, loss:0.293\n",
      "Checking accuracy on test set\n",
      "Got 729 / 1000 correct (72.90)\n",
      "49 epoch,  1000 iteration, loss:0.305\n",
      " num 48 epoch \n",
      "####### Training Loss #######\n",
      "[0.2959019]\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "50 epoch,   500 iteration, loss:0.275\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "50 epoch,  1000 iteration, loss:0.297\n",
      " num 49 epoch \n",
      "####### Training Loss #######\n",
      "[0.28940203]\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "51 epoch,   500 iteration, loss:0.275\n",
      "Checking accuracy on test set\n",
      "Got 725 / 1000 correct (72.50)\n",
      "51 epoch,  1000 iteration, loss:0.310\n",
      " num 50 epoch \n",
      "####### Training Loss #######\n",
      "[0.28425435]\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "52 epoch,   500 iteration, loss:0.297\n",
      "Checking accuracy on test set\n",
      "Got 720 / 1000 correct (72.00)\n",
      "52 epoch,  1000 iteration, loss:0.294\n",
      " num 51 epoch \n",
      "####### Training Loss #######\n",
      "[0.284927]\n",
      "Checking accuracy on test set\n",
      "Got 728 / 1000 correct (72.80)\n",
      "53 epoch,   500 iteration, loss:0.274\n",
      "Checking accuracy on test set\n",
      "Got 726 / 1000 correct (72.60)\n",
      "53 epoch,  1000 iteration, loss:0.282\n",
      " num 52 epoch \n",
      "####### Training Loss #######\n",
      "[0.28042957]\n",
      "Checking accuracy on test set\n",
      "Got 716 / 1000 correct (71.60)\n",
      "54 epoch,   500 iteration, loss:0.265\n",
      "Checking accuracy on test set\n",
      "Got 724 / 1000 correct (72.40)\n",
      "54 epoch,  1000 iteration, loss:0.270\n",
      " num 53 epoch \n",
      "####### Training Loss #######\n",
      "[0.26488413]\n",
      "Checking accuracy on test set\n",
      "Got 721 / 1000 correct (72.10)\n",
      "55 epoch,   500 iteration, loss:0.246\n",
      "Checking accuracy on test set\n",
      "Got 691 / 1000 correct (69.10)\n",
      "55 epoch,  1000 iteration, loss:0.298\n",
      " num 54 epoch \n",
      "####### Training Loss #######\n",
      "[0.27072668]\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "56 epoch,   500 iteration, loss:0.247\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "56 epoch,  1000 iteration, loss:0.263\n",
      " num 55 epoch \n",
      "####### Training Loss #######\n",
      "[0.25623273]\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "57 epoch,   500 iteration, loss:0.259\n",
      "Checking accuracy on test set\n",
      "Got 729 / 1000 correct (72.90)\n",
      "57 epoch,  1000 iteration, loss:0.268\n",
      " num 56 epoch \n",
      "####### Training Loss #######\n",
      "[0.25657103]\n",
      "Checking accuracy on test set\n",
      "Got 721 / 1000 correct (72.10)\n",
      "58 epoch,   500 iteration, loss:0.230\n",
      "Checking accuracy on test set\n",
      "Got 718 / 1000 correct (71.80)\n",
      "58 epoch,  1000 iteration, loss:0.251\n",
      " num 57 epoch \n",
      "####### Training Loss #######\n",
      "[0.2307197]\n",
      "Checking accuracy on test set\n",
      "Got 708 / 1000 correct (70.80)\n",
      "59 epoch,   500 iteration, loss:0.223\n",
      "Checking accuracy on test set\n",
      "Got 705 / 1000 correct (70.50)\n",
      "59 epoch,  1000 iteration, loss:0.232\n",
      " num 58 epoch \n",
      "####### Training Loss #######\n",
      "[0.22247501]\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "60 epoch,   500 iteration, loss:0.212\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "60 epoch,  1000 iteration, loss:0.239\n",
      " num 59 epoch \n",
      "####### Training Loss #######\n",
      "[0.2335443]\n",
      "Checking accuracy on test set\n",
      "Got 719 / 1000 correct (71.90)\n",
      "61 epoch,   500 iteration, loss:0.233\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "61 epoch,  1000 iteration, loss:0.212\n",
      " num 60 epoch \n",
      "####### Training Loss #######\n",
      "[0.22242349]\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "62 epoch,   500 iteration, loss:0.241\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "62 epoch,  1000 iteration, loss:0.221\n",
      " num 61 epoch \n",
      "####### Training Loss #######\n",
      "[0.22817811]\n",
      "Checking accuracy on test set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "63 epoch,   500 iteration, loss:0.197\n",
      "Checking accuracy on test set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "63 epoch,  1000 iteration, loss:0.211\n",
      " num 62 epoch \n",
      "####### Training Loss #######\n",
      "[0.20746597]\n",
      "Checking accuracy on test set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "64 epoch,   500 iteration, loss:0.193\n",
      "Checking accuracy on test set\n",
      "Got 711 / 1000 correct (71.10)\n",
      "64 epoch,  1000 iteration, loss:0.193\n",
      " num 63 epoch \n",
      "####### Training Loss #######\n",
      "[0.19662518]\n",
      "Checking accuracy on test set\n",
      "Got 716 / 1000 correct (71.60)\n",
      "65 epoch,   500 iteration, loss:0.196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "65 epoch,  1000 iteration, loss:0.191\n",
      " num 64 epoch \n",
      "####### Training Loss #######\n",
      "[0.18886367]\n",
      "Checking accuracy on test set\n",
      "Got 762 / 1000 correct (76.20)\n",
      "66 epoch,   500 iteration, loss:0.166\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "66 epoch,  1000 iteration, loss:0.186\n",
      " num 65 epoch \n",
      "####### Training Loss #######\n",
      "[0.17659084]\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "67 epoch,   500 iteration, loss:0.159\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "67 epoch,  1000 iteration, loss:0.197\n",
      " num 66 epoch \n",
      "####### Training Loss #######\n",
      "[0.18133748]\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "68 epoch,   500 iteration, loss:0.153\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "68 epoch,  1000 iteration, loss:0.190\n",
      " num 67 epoch \n",
      "####### Training Loss #######\n",
      "[0.17054572]\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "69 epoch,   500 iteration, loss:0.170\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "69 epoch,  1000 iteration, loss:0.205\n",
      " num 68 epoch \n",
      "####### Training Loss #######\n",
      "[0.19217298]\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "70 epoch,   500 iteration, loss:0.158\n",
      "Checking accuracy on test set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "70 epoch,  1000 iteration, loss:0.174\n",
      " num 69 epoch \n",
      "####### Training Loss #######\n",
      "[0.16482971]\n",
      "Checking accuracy on test set\n",
      "Got 762 / 1000 correct (76.20)\n",
      "71 epoch,   500 iteration, loss:0.182\n",
      "Checking accuracy on test set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "71 epoch,  1000 iteration, loss:0.178\n",
      " num 70 epoch \n",
      "####### Training Loss #######\n",
      "[0.18093856]\n",
      "Checking accuracy on test set\n",
      "Got 765 / 1000 correct (76.50)\n",
      "72 epoch,   500 iteration, loss:0.160\n",
      "Checking accuracy on test set\n",
      "Got 726 / 1000 correct (72.60)\n",
      "72 epoch,  1000 iteration, loss:0.156\n",
      " num 71 epoch \n",
      "####### Training Loss #######\n",
      "[0.15443241]\n",
      "Checking accuracy on test set\n",
      "Got 753 / 1000 correct (75.30)\n",
      "73 epoch,   500 iteration, loss:0.217\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "73 epoch,  1000 iteration, loss:0.180\n",
      " num 72 epoch \n",
      "####### Training Loss #######\n",
      "[0.18662506]\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "74 epoch,   500 iteration, loss:0.159\n",
      "Checking accuracy on test set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "74 epoch,  1000 iteration, loss:0.161\n",
      " num 73 epoch \n",
      "####### Training Loss #######\n",
      "[0.16177909]\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "75 epoch,   500 iteration, loss:0.170\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "75 epoch,  1000 iteration, loss:0.178\n",
      " num 74 epoch \n",
      "####### Training Loss #######\n",
      "[0.17035868]\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "76 epoch,   500 iteration, loss:0.154\n",
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "76 epoch,  1000 iteration, loss:0.173\n",
      " num 75 epoch \n",
      "####### Training Loss #######\n",
      "[0.163025]\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "77 epoch,   500 iteration, loss:0.140\n",
      "Checking accuracy on test set\n",
      "Got 762 / 1000 correct (76.20)\n",
      "77 epoch,  1000 iteration, loss:0.144\n",
      " num 76 epoch \n",
      "####### Training Loss #######\n",
      "[0.14914986]\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "78 epoch,   500 iteration, loss:0.134\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "78 epoch,  1000 iteration, loss:0.154\n",
      " num 77 epoch \n",
      "####### Training Loss #######\n",
      "[0.15061589]\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "79 epoch,   500 iteration, loss:0.122\n",
      "Checking accuracy on test set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "79 epoch,  1000 iteration, loss:0.168\n",
      " num 78 epoch \n",
      "####### Training Loss #######\n",
      "[0.14887621]\n",
      "Checking accuracy on test set\n",
      "Got 755 / 1000 correct (75.50)\n",
      "80 epoch,   500 iteration, loss:0.152\n",
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "80 epoch,  1000 iteration, loss:0.129\n",
      " num 79 epoch \n",
      "####### Training Loss #######\n",
      "[0.13886126]\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "81 epoch,   500 iteration, loss:0.141\n",
      "Checking accuracy on test set\n",
      "Got 717 / 1000 correct (71.70)\n",
      "81 epoch,  1000 iteration, loss:0.127\n",
      " num 80 epoch \n",
      "####### Training Loss #######\n",
      "[0.14072732]\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "82 epoch,   500 iteration, loss:0.143\n",
      "Checking accuracy on test set\n",
      "Got 694 / 1000 correct (69.40)\n",
      "82 epoch,  1000 iteration, loss:0.131\n",
      " num 81 epoch \n",
      "####### Training Loss #######\n",
      "[0.13891935]\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "83 epoch,   500 iteration, loss:0.110\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "83 epoch,  1000 iteration, loss:0.138\n",
      " num 82 epoch \n",
      "####### Training Loss #######\n",
      "[0.1236993]\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "84 epoch,   500 iteration, loss:0.150\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "84 epoch,  1000 iteration, loss:0.111\n",
      " num 83 epoch \n",
      "####### Training Loss #######\n",
      "[0.13015314]\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "85 epoch,   500 iteration, loss:0.152\n",
      "Checking accuracy on test set\n",
      "Got 726 / 1000 correct (72.60)\n",
      "85 epoch,  1000 iteration, loss:0.149\n",
      " num 84 epoch \n",
      "####### Training Loss #######\n",
      "[0.14459653]\n",
      "Checking accuracy on test set\n",
      "Got 708 / 1000 correct (70.80)\n",
      "86 epoch,   500 iteration, loss:0.151\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "86 epoch,  1000 iteration, loss:0.124\n",
      " num 85 epoch \n",
      "####### Training Loss #######\n",
      "[0.14379259]\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "87 epoch,   500 iteration, loss:0.112\n",
      "Checking accuracy on test set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "87 epoch,  1000 iteration, loss:0.119\n",
      " num 86 epoch \n",
      "####### Training Loss #######\n",
      "[0.11751519]\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "88 epoch,   500 iteration, loss:0.126\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "88 epoch,  1000 iteration, loss:0.112\n",
      " num 87 epoch \n",
      "####### Training Loss #######\n",
      "[0.11326434]\n",
      "Checking accuracy on test set\n",
      "Got 755 / 1000 correct (75.50)\n",
      "89 epoch,   500 iteration, loss:0.129\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "89 epoch,  1000 iteration, loss:0.112\n",
      " num 88 epoch \n",
      "####### Training Loss #######\n",
      "[0.13287498]\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "90 epoch,   500 iteration, loss:0.143\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "90 epoch,  1000 iteration, loss:0.138\n",
      " num 89 epoch \n",
      "####### Training Loss #######\n",
      "[0.12860753]\n",
      "Checking accuracy on test set\n",
      "Got 759 / 1000 correct (75.90)\n",
      "91 epoch,   500 iteration, loss:0.126\n",
      "Checking accuracy on test set\n",
      "Got 762 / 1000 correct (76.20)\n",
      "91 epoch,  1000 iteration, loss:0.098\n",
      " num 90 epoch \n",
      "####### Training Loss #######\n",
      "[0.12561554]\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "92 epoch,   500 iteration, loss:0.121\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "92 epoch,  1000 iteration, loss:0.143\n",
      " num 91 epoch \n",
      "####### Training Loss #######\n",
      "[0.1290813]\n",
      "Checking accuracy on test set\n",
      "Got 759 / 1000 correct (75.90)\n",
      "93 epoch,   500 iteration, loss:0.110\n",
      "Checking accuracy on test set\n",
      "Got 753 / 1000 correct (75.30)\n",
      "93 epoch,  1000 iteration, loss:0.133\n",
      " num 92 epoch \n",
      "####### Training Loss #######\n",
      "[0.11257367]\n",
      "Checking accuracy on test set\n",
      "Got 781 / 1000 correct (78.10)\n",
      "94 epoch,   500 iteration, loss:0.115\n",
      "Checking accuracy on test set\n",
      "Got 729 / 1000 correct (72.90)\n",
      "94 epoch,  1000 iteration, loss:0.107\n",
      " num 93 epoch \n",
      "####### Training Loss #######\n",
      "[0.10606759]\n",
      "Checking accuracy on test set\n",
      "Got 728 / 1000 correct (72.80)\n",
      "95 epoch,   500 iteration, loss:0.135\n",
      "Checking accuracy on test set\n",
      "Got 753 / 1000 correct (75.30)\n",
      "95 epoch,  1000 iteration, loss:0.135\n",
      " num 94 epoch \n",
      "####### Training Loss #######\n",
      "[0.12972075]\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "96 epoch,   500 iteration, loss:0.096\n",
      "Checking accuracy on test set\n",
      "Got 760 / 1000 correct (76.00)\n",
      "96 epoch,  1000 iteration, loss:0.105\n",
      " num 95 epoch \n",
      "####### Training Loss #######\n",
      "[0.09776585]\n",
      "Checking accuracy on test set\n",
      "Got 703 / 1000 correct (70.30)\n",
      "97 epoch,   500 iteration, loss:0.130\n",
      "Checking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 747 / 1000 correct (74.70)\n",
      "97 epoch,  1000 iteration, loss:0.117\n",
      " num 96 epoch \n",
      "####### Training Loss #######\n",
      "[0.12809811]\n",
      "Checking accuracy on test set\n",
      "Got 768 / 1000 correct (76.80)\n",
      "98 epoch,   500 iteration, loss:0.100\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "98 epoch,  1000 iteration, loss:0.101\n",
      " num 97 epoch \n",
      "####### Training Loss #######\n",
      "[0.09612415]\n",
      "Checking accuracy on test set\n",
      "Got 760 / 1000 correct (76.00)\n",
      "99 epoch,   500 iteration, loss:0.111\n",
      "Checking accuracy on test set\n",
      "Got 717 / 1000 correct (71.70)\n",
      "99 epoch,  1000 iteration, loss:0.091\n",
      " num 98 epoch \n",
      "####### Training Loss #######\n",
      "[0.09893966]\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "100 epoch,   500 iteration, loss:0.100\n",
      "Checking accuracy on test set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "100 epoch,  1000 iteration, loss:0.152\n",
      " num 99 epoch \n",
      "####### Training Loss #######\n",
      "[0.1286833]\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "101 epoch,   500 iteration, loss:0.087\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "101 epoch,  1000 iteration, loss:0.107\n",
      " num 100 epoch \n",
      "####### Training Loss #######\n",
      "[0.09627056]\n",
      "Checking accuracy on test set\n",
      "Got 753 / 1000 correct (75.30)\n",
      "102 epoch,   500 iteration, loss:0.105\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "102 epoch,  1000 iteration, loss:0.100\n",
      " num 101 epoch \n",
      "####### Training Loss #######\n",
      "[0.10598656]\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "103 epoch,   500 iteration, loss:0.072\n",
      "Checking accuracy on test set\n",
      "Got 697 / 1000 correct (69.70)\n",
      "103 epoch,  1000 iteration, loss:0.134\n",
      " num 102 epoch \n",
      "####### Training Loss #######\n",
      "[0.10744999]\n",
      "Checking accuracy on test set\n",
      "Got 762 / 1000 correct (76.20)\n",
      "104 epoch,   500 iteration, loss:0.138\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "104 epoch,  1000 iteration, loss:0.089\n",
      " num 103 epoch \n",
      "####### Training Loss #######\n",
      "[0.11218753]\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "105 epoch,   500 iteration, loss:0.094\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "105 epoch,  1000 iteration, loss:0.118\n",
      " num 104 epoch \n",
      "####### Training Loss #######\n",
      "[0.10154673]\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "106 epoch,   500 iteration, loss:0.136\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "106 epoch,  1000 iteration, loss:0.110\n",
      " num 105 epoch \n",
      "####### Training Loss #######\n",
      "[0.11598987]\n",
      "Checking accuracy on test set\n",
      "Got 753 / 1000 correct (75.30)\n",
      "107 epoch,   500 iteration, loss:0.111\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "107 epoch,  1000 iteration, loss:0.111\n",
      " num 106 epoch \n",
      "####### Training Loss #######\n",
      "[0.10298301]\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "108 epoch,   500 iteration, loss:0.111\n",
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "108 epoch,  1000 iteration, loss:0.106\n",
      " num 107 epoch \n",
      "####### Training Loss #######\n",
      "[0.10309348]\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "109 epoch,   500 iteration, loss:0.106\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "109 epoch,  1000 iteration, loss:0.117\n",
      " num 108 epoch \n",
      "####### Training Loss #######\n",
      "[0.11659125]\n",
      "Checking accuracy on test set\n",
      "Got 710 / 1000 correct (71.00)\n",
      "110 epoch,   500 iteration, loss:0.078\n",
      "Checking accuracy on test set\n",
      "Got 728 / 1000 correct (72.80)\n",
      "110 epoch,  1000 iteration, loss:0.109\n",
      " num 109 epoch \n",
      "####### Training Loss #######\n",
      "[0.09805081]\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "111 epoch,   500 iteration, loss:0.091\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "111 epoch,  1000 iteration, loss:0.102\n",
      " num 110 epoch \n",
      "####### Training Loss #######\n",
      "[0.09363019]\n",
      "Checking accuracy on test set\n",
      "Got 759 / 1000 correct (75.90)\n",
      "112 epoch,   500 iteration, loss:0.102\n",
      "Checking accuracy on test set\n",
      "Got 755 / 1000 correct (75.50)\n",
      "112 epoch,  1000 iteration, loss:0.089\n",
      " num 111 epoch \n",
      "####### Training Loss #######\n",
      "[0.10098646]\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "113 epoch,   500 iteration, loss:0.096\n",
      "Checking accuracy on test set\n",
      "Got 761 / 1000 correct (76.10)\n",
      "113 epoch,  1000 iteration, loss:0.114\n",
      " num 112 epoch \n",
      "####### Training Loss #######\n",
      "[0.09525781]\n",
      "Checking accuracy on test set\n",
      "Got 765 / 1000 correct (76.50)\n",
      "114 epoch,   500 iteration, loss:0.078\n",
      "Checking accuracy on test set\n",
      "Got 767 / 1000 correct (76.70)\n",
      "114 epoch,  1000 iteration, loss:0.118\n",
      " num 113 epoch \n",
      "####### Training Loss #######\n",
      "[0.09531634]\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "115 epoch,   500 iteration, loss:0.099\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "115 epoch,  1000 iteration, loss:0.072\n",
      " num 114 epoch \n",
      "####### Training Loss #######\n",
      "[0.08632]\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "116 epoch,   500 iteration, loss:0.094\n",
      "Checking accuracy on test set\n",
      "Got 753 / 1000 correct (75.30)\n",
      "116 epoch,  1000 iteration, loss:0.107\n",
      " num 115 epoch \n",
      "####### Training Loss #######\n",
      "[0.09891498]\n",
      "Checking accuracy on test set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "117 epoch,   500 iteration, loss:0.115\n",
      "Checking accuracy on test set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "117 epoch,  1000 iteration, loss:0.075\n",
      " num 116 epoch \n",
      "####### Training Loss #######\n",
      "[0.11166472]\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "118 epoch,   500 iteration, loss:0.081\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "118 epoch,  1000 iteration, loss:0.084\n",
      " num 117 epoch \n",
      "####### Training Loss #######\n",
      "[0.07865339]\n",
      "Checking accuracy on test set\n",
      "Got 719 / 1000 correct (71.90)\n",
      "119 epoch,   500 iteration, loss:0.095\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "119 epoch,  1000 iteration, loss:0.121\n",
      " num 118 epoch \n",
      "####### Training Loss #######\n",
      "[0.1100148]\n",
      "Checking accuracy on test set\n",
      "Got 754 / 1000 correct (75.40)\n",
      "120 epoch,   500 iteration, loss:0.087\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "120 epoch,  1000 iteration, loss:0.074\n",
      " num 119 epoch \n",
      "####### Training Loss #######\n",
      "[0.08088363]\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "121 epoch,   500 iteration, loss:0.089\n",
      "Checking accuracy on test set\n",
      "Got 767 / 1000 correct (76.70)\n",
      "121 epoch,  1000 iteration, loss:0.083\n",
      " num 120 epoch \n",
      "####### Training Loss #######\n",
      "[0.08306763]\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "122 epoch,   500 iteration, loss:0.091\n",
      "Checking accuracy on test set\n",
      "Got 768 / 1000 correct (76.80)\n",
      "122 epoch,  1000 iteration, loss:0.079\n",
      " num 121 epoch \n",
      "####### Training Loss #######\n",
      "[0.08591039]\n",
      "Checking accuracy on test set\n",
      "Got 714 / 1000 correct (71.40)\n",
      "123 epoch,   500 iteration, loss:0.091\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "123 epoch,  1000 iteration, loss:0.129\n",
      " num 122 epoch \n",
      "####### Training Loss #######\n",
      "[0.1066781]\n",
      "Checking accuracy on test set\n",
      "Got 754 / 1000 correct (75.40)\n",
      "124 epoch,   500 iteration, loss:0.072\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "124 epoch,  1000 iteration, loss:0.105\n",
      " num 123 epoch \n",
      "####### Training Loss #######\n",
      "[0.08810481]\n",
      "Checking accuracy on test set\n",
      "Got 722 / 1000 correct (72.20)\n",
      "125 epoch,   500 iteration, loss:0.106\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "125 epoch,  1000 iteration, loss:0.084\n",
      " num 124 epoch \n",
      "####### Training Loss #######\n",
      "[0.09974485]\n",
      "Checking accuracy on test set\n",
      "Got 754 / 1000 correct (75.40)\n",
      "126 epoch,   500 iteration, loss:0.065\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "126 epoch,  1000 iteration, loss:0.093\n",
      " num 125 epoch \n",
      "####### Training Loss #######\n",
      "[0.08200535]\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "127 epoch,   500 iteration, loss:0.097\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "127 epoch,  1000 iteration, loss:0.086\n",
      " num 126 epoch \n",
      "####### Training Loss #######\n",
      "[0.08127834]\n",
      "Checking accuracy on test set\n",
      "Got 775 / 1000 correct (77.50)\n",
      "128 epoch,   500 iteration, loss:0.085\n",
      "Checking accuracy on test set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "128 epoch,  1000 iteration, loss:0.062\n",
      " num 127 epoch \n",
      "####### Training Loss #######\n",
      "[0.07184934]\n",
      "Checking accuracy on test set\n",
      "Got 778 / 1000 correct (77.80)\n",
      "129 epoch,   500 iteration, loss:0.093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "129 epoch,  1000 iteration, loss:0.111\n",
      " num 128 epoch \n",
      "####### Training Loss #######\n",
      "[0.09583357]\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "130 epoch,   500 iteration, loss:0.048\n",
      "Checking accuracy on test set\n",
      "Got 759 / 1000 correct (75.90)\n",
      "130 epoch,  1000 iteration, loss:0.092\n",
      " num 129 epoch \n",
      "####### Training Loss #######\n",
      "[0.06993333]\n",
      "Checking accuracy on test set\n",
      "Got 772 / 1000 correct (77.20)\n",
      "131 epoch,   500 iteration, loss:0.083\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "131 epoch,  1000 iteration, loss:0.103\n",
      " num 130 epoch \n",
      "####### Training Loss #######\n",
      "[0.09804816]\n",
      "Checking accuracy on test set\n",
      "Got 761 / 1000 correct (76.10)\n",
      "132 epoch,   500 iteration, loss:0.067\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "132 epoch,  1000 iteration, loss:0.075\n",
      " num 131 epoch \n",
      "####### Training Loss #######\n",
      "[0.08101595]\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "133 epoch,   500 iteration, loss:0.115\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "133 epoch,  1000 iteration, loss:0.103\n",
      " num 132 epoch \n",
      "####### Training Loss #######\n",
      "[0.10710754]\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "134 epoch,   500 iteration, loss:0.117\n",
      "Checking accuracy on test set\n",
      "Got 755 / 1000 correct (75.50)\n",
      "134 epoch,  1000 iteration, loss:0.094\n",
      " num 133 epoch \n",
      "####### Training Loss #######\n",
      "[0.11057629]\n",
      "Checking accuracy on test set\n",
      "Got 766 / 1000 correct (76.60)\n",
      "135 epoch,   500 iteration, loss:0.103\n",
      "Checking accuracy on test set\n",
      "Got 760 / 1000 correct (76.00)\n",
      "135 epoch,  1000 iteration, loss:0.085\n",
      " num 134 epoch \n",
      "####### Training Loss #######\n",
      "[0.090435]\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "136 epoch,   500 iteration, loss:0.075\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "136 epoch,  1000 iteration, loss:0.085\n",
      " num 135 epoch \n",
      "####### Training Loss #######\n",
      "[0.08203082]\n",
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "137 epoch,   500 iteration, loss:0.104\n",
      "Checking accuracy on test set\n",
      "Got 761 / 1000 correct (76.10)\n",
      "137 epoch,  1000 iteration, loss:0.071\n",
      " num 136 epoch \n",
      "####### Training Loss #######\n",
      "[0.09228165]\n",
      "Checking accuracy on test set\n",
      "Got 761 / 1000 correct (76.10)\n",
      "138 epoch,   500 iteration, loss:0.088\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "138 epoch,  1000 iteration, loss:0.085\n",
      " num 137 epoch \n",
      "####### Training Loss #######\n",
      "[0.09312688]\n",
      "Checking accuracy on test set\n",
      "Got 762 / 1000 correct (76.20)\n",
      "139 epoch,   500 iteration, loss:0.083\n",
      "Checking accuracy on test set\n",
      "Got 766 / 1000 correct (76.60)\n",
      "139 epoch,  1000 iteration, loss:0.114\n",
      " num 138 epoch \n",
      "####### Training Loss #######\n",
      "[0.10185541]\n",
      "Checking accuracy on test set\n",
      "Got 767 / 1000 correct (76.70)\n",
      "140 epoch,   500 iteration, loss:0.090\n",
      "Checking accuracy on test set\n",
      "Got 753 / 1000 correct (75.30)\n",
      "140 epoch,  1000 iteration, loss:0.073\n",
      " num 139 epoch \n",
      "####### Training Loss #######\n",
      "[0.07634788]\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "141 epoch,   500 iteration, loss:0.072\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "141 epoch,  1000 iteration, loss:0.114\n",
      " num 140 epoch \n",
      "####### Training Loss #######\n",
      "[0.08840416]\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "142 epoch,   500 iteration, loss:0.062\n",
      "Checking accuracy on test set\n",
      "Got 771 / 1000 correct (77.10)\n",
      "142 epoch,  1000 iteration, loss:0.093\n",
      " num 141 epoch \n",
      "####### Training Loss #######\n",
      "[0.08339967]\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "143 epoch,   500 iteration, loss:0.128\n",
      "Checking accuracy on test set\n",
      "Got 760 / 1000 correct (76.00)\n",
      "143 epoch,  1000 iteration, loss:0.071\n",
      " num 142 epoch \n",
      "####### Training Loss #######\n",
      "[0.09615805]\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "144 epoch,   500 iteration, loss:0.075\n",
      "Checking accuracy on test set\n",
      "Got 695 / 1000 correct (69.50)\n",
      "144 epoch,  1000 iteration, loss:0.096\n",
      " num 143 epoch \n",
      "####### Training Loss #######\n",
      "[0.09033701]\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "145 epoch,   500 iteration, loss:0.084\n",
      "Checking accuracy on test set\n",
      "Got 776 / 1000 correct (77.60)\n",
      "145 epoch,  1000 iteration, loss:0.065\n",
      " num 144 epoch \n",
      "####### Training Loss #######\n",
      "[0.07634016]\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "146 epoch,   500 iteration, loss:0.115\n",
      "Checking accuracy on test set\n",
      "Got 772 / 1000 correct (77.20)\n",
      "146 epoch,  1000 iteration, loss:0.057\n",
      " num 145 epoch \n",
      "####### Training Loss #######\n",
      "[0.08836697]\n",
      "Checking accuracy on test set\n",
      "Got 759 / 1000 correct (75.90)\n",
      "147 epoch,   500 iteration, loss:0.066\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "147 epoch,  1000 iteration, loss:0.109\n",
      " num 146 epoch \n",
      "####### Training Loss #######\n",
      "[0.0919678]\n",
      "Checking accuracy on test set\n",
      "Got 782 / 1000 correct (78.20)\n",
      "148 epoch,   500 iteration, loss:0.065\n",
      "Checking accuracy on test set\n",
      "Got 728 / 1000 correct (72.80)\n",
      "148 epoch,  1000 iteration, loss:0.097\n",
      " num 147 epoch \n",
      "####### Training Loss #######\n",
      "[0.08355235]\n",
      "Checking accuracy on test set\n",
      "Got 761 / 1000 correct (76.10)\n",
      "149 epoch,   500 iteration, loss:0.075\n",
      "Checking accuracy on test set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "149 epoch,  1000 iteration, loss:0.079\n",
      " num 148 epoch \n",
      "####### Training Loss #######\n",
      "[0.07629506]\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "150 epoch,   500 iteration, loss:0.092\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "150 epoch,  1000 iteration, loss:0.089\n",
      " num 149 epoch \n",
      "####### Training Loss #######\n",
      "[0.0873617]\n",
      "Checking accuracy on test set\n",
      "Got 774 / 1000 correct (77.40)\n",
      "151 epoch,   500 iteration, loss:0.079\n",
      "Checking accuracy on test set\n",
      "Got 771 / 1000 correct (77.10)\n",
      "151 epoch,  1000 iteration, loss:0.089\n",
      " num 150 epoch \n",
      "####### Training Loss #######\n",
      "[0.08078162]\n",
      "Checking accuracy on test set\n",
      "Got 722 / 1000 correct (72.20)\n",
      "152 epoch,   500 iteration, loss:0.081\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "152 epoch,  1000 iteration, loss:0.100\n",
      " num 151 epoch \n",
      "####### Training Loss #######\n",
      "[0.08251345]\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "153 epoch,   500 iteration, loss:0.105\n",
      "Checking accuracy on test set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "153 epoch,  1000 iteration, loss:0.097\n",
      " num 152 epoch \n",
      "####### Training Loss #######\n",
      "[0.09739707]\n",
      "Checking accuracy on test set\n",
      "Got 762 / 1000 correct (76.20)\n",
      "154 epoch,   500 iteration, loss:0.076\n",
      "Checking accuracy on test set\n",
      "Got 782 / 1000 correct (78.20)\n",
      "154 epoch,  1000 iteration, loss:0.099\n",
      " num 153 epoch \n",
      "####### Training Loss #######\n",
      "[0.08596377]\n",
      "Checking accuracy on test set\n",
      "Got 762 / 1000 correct (76.20)\n",
      "155 epoch,   500 iteration, loss:0.061\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "155 epoch,  1000 iteration, loss:0.078\n",
      " num 154 epoch \n",
      "####### Training Loss #######\n",
      "[0.07366364]\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "156 epoch,   500 iteration, loss:0.081\n",
      "Checking accuracy on test set\n",
      "Got 726 / 1000 correct (72.60)\n",
      "156 epoch,  1000 iteration, loss:0.080\n",
      " num 155 epoch \n",
      "####### Training Loss #######\n",
      "[0.0882122]\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "157 epoch,   500 iteration, loss:0.074\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "157 epoch,  1000 iteration, loss:0.095\n",
      " num 156 epoch \n",
      "####### Training Loss #######\n",
      "[0.07881892]\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "158 epoch,   500 iteration, loss:0.062\n",
      "Checking accuracy on test set\n",
      "Got 755 / 1000 correct (75.50)\n",
      "158 epoch,  1000 iteration, loss:0.070\n",
      " num 157 epoch \n",
      "####### Training Loss #######\n",
      "[0.07342185]\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "159 epoch,   500 iteration, loss:0.099\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "159 epoch,  1000 iteration, loss:0.081\n",
      " num 158 epoch \n",
      "####### Training Loss #######\n",
      "[0.08594931]\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "160 epoch,   500 iteration, loss:0.085\n",
      "Checking accuracy on test set\n",
      "Got 780 / 1000 correct (78.00)\n",
      "160 epoch,  1000 iteration, loss:0.076\n",
      " num 159 epoch \n",
      "####### Training Loss #######\n",
      "[0.07345847]\n",
      "Checking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 761 / 1000 correct (76.10)\n",
      "161 epoch,   500 iteration, loss:0.078\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "161 epoch,  1000 iteration, loss:0.079\n",
      " num 160 epoch \n",
      "####### Training Loss #######\n",
      "[0.07413144]\n",
      "Checking accuracy on test set\n",
      "Got 753 / 1000 correct (75.30)\n",
      "162 epoch,   500 iteration, loss:0.109\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "162 epoch,  1000 iteration, loss:0.090\n",
      " num 161 epoch \n",
      "####### Training Loss #######\n",
      "[0.09102428]\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "163 epoch,   500 iteration, loss:0.099\n",
      "Checking accuracy on test set\n",
      "Got 760 / 1000 correct (76.00)\n",
      "163 epoch,  1000 iteration, loss:0.062\n",
      " num 162 epoch \n",
      "####### Training Loss #######\n",
      "[0.08549188]\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "164 epoch,   500 iteration, loss:0.081\n",
      "Checking accuracy on test set\n",
      "Got 766 / 1000 correct (76.60)\n",
      "164 epoch,  1000 iteration, loss:0.106\n",
      " num 163 epoch \n",
      "####### Training Loss #######\n",
      "[0.08231844]\n",
      "Checking accuracy on test set\n",
      "Got 767 / 1000 correct (76.70)\n",
      "165 epoch,   500 iteration, loss:0.084\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "165 epoch,  1000 iteration, loss:0.063\n",
      " num 164 epoch \n",
      "####### Training Loss #######\n",
      "[0.0811929]\n",
      "Checking accuracy on test set\n",
      "Got 767 / 1000 correct (76.70)\n",
      "166 epoch,   500 iteration, loss:0.077\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "166 epoch,  1000 iteration, loss:0.077\n",
      " num 165 epoch \n",
      "####### Training Loss #######\n",
      "[0.08456683]\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "167 epoch,   500 iteration, loss:0.075\n",
      "Checking accuracy on test set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "167 epoch,  1000 iteration, loss:0.057\n",
      " num 166 epoch \n",
      "####### Training Loss #######\n",
      "[0.06623164]\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "168 epoch,   500 iteration, loss:0.070\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "168 epoch,  1000 iteration, loss:0.084\n",
      " num 167 epoch \n",
      "####### Training Loss #######\n",
      "[0.07928394]\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "169 epoch,   500 iteration, loss:0.099\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "169 epoch,  1000 iteration, loss:0.093\n",
      " num 168 epoch \n",
      "####### Training Loss #######\n",
      "[0.09412271]\n",
      "Checking accuracy on test set\n",
      "Got 776 / 1000 correct (77.60)\n",
      "170 epoch,   500 iteration, loss:0.081\n",
      "Checking accuracy on test set\n",
      "Got 762 / 1000 correct (76.20)\n",
      "170 epoch,  1000 iteration, loss:0.073\n",
      " num 169 epoch \n",
      "####### Training Loss #######\n",
      "[0.07794816]\n",
      "Checking accuracy on test set\n",
      "Got 782 / 1000 correct (78.20)\n",
      "171 epoch,   500 iteration, loss:0.104\n",
      "Checking accuracy on test set\n",
      "Got 725 / 1000 correct (72.50)\n",
      "171 epoch,  1000 iteration, loss:0.082\n",
      " num 170 epoch \n",
      "####### Training Loss #######\n",
      "[0.09482222]\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "172 epoch,   500 iteration, loss:0.080\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "172 epoch,  1000 iteration, loss:0.060\n",
      " num 171 epoch \n",
      "####### Training Loss #######\n",
      "[0.07404224]\n",
      "Checking accuracy on test set\n",
      "Got 767 / 1000 correct (76.70)\n",
      "173 epoch,   500 iteration, loss:0.085\n",
      "Checking accuracy on test set\n",
      "Got 772 / 1000 correct (77.20)\n",
      "173 epoch,  1000 iteration, loss:0.095\n",
      " num 172 epoch \n",
      "####### Training Loss #######\n",
      "[0.0856669]\n",
      "Checking accuracy on test set\n",
      "Got 784 / 1000 correct (78.40)\n",
      "174 epoch,   500 iteration, loss:0.051\n",
      "Checking accuracy on test set\n",
      "Got 777 / 1000 correct (77.70)\n",
      "174 epoch,  1000 iteration, loss:0.067\n",
      " num 173 epoch \n",
      "####### Training Loss #######\n",
      "[0.06282512]\n",
      "Checking accuracy on test set\n",
      "Got 709 / 1000 correct (70.90)\n",
      "175 epoch,   500 iteration, loss:0.081\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "175 epoch,  1000 iteration, loss:0.086\n",
      " num 174 epoch \n",
      "####### Training Loss #######\n",
      "[0.08904685]\n",
      "Checking accuracy on test set\n",
      "Got 765 / 1000 correct (76.50)\n",
      "176 epoch,   500 iteration, loss:0.072\n",
      "Checking accuracy on test set\n",
      "Got 768 / 1000 correct (76.80)\n",
      "176 epoch,  1000 iteration, loss:0.062\n",
      " num 175 epoch \n",
      "####### Training Loss #######\n",
      "[0.07040498]\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "177 epoch,   500 iteration, loss:0.081\n",
      "Checking accuracy on test set\n",
      "Got 780 / 1000 correct (78.00)\n",
      "177 epoch,  1000 iteration, loss:0.079\n",
      " num 176 epoch \n",
      "####### Training Loss #######\n",
      "[0.06992586]\n",
      "Checking accuracy on test set\n",
      "Got 761 / 1000 correct (76.10)\n",
      "178 epoch,   500 iteration, loss:0.063\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "178 epoch,  1000 iteration, loss:0.077\n",
      " num 177 epoch \n",
      "####### Training Loss #######\n",
      "[0.07406942]\n",
      "Checking accuracy on test set\n",
      "Got 760 / 1000 correct (76.00)\n",
      "179 epoch,   500 iteration, loss:0.065\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "179 epoch,  1000 iteration, loss:0.054\n",
      " num 178 epoch \n",
      "####### Training Loss #######\n",
      "[0.05929574]\n",
      "Checking accuracy on test set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "180 epoch,   500 iteration, loss:0.071\n",
      "Checking accuracy on test set\n",
      "Got 753 / 1000 correct (75.30)\n",
      "180 epoch,  1000 iteration, loss:0.064\n",
      " num 179 epoch \n",
      "####### Training Loss #######\n",
      "[0.06826907]\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "181 epoch,   500 iteration, loss:0.063\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "181 epoch,  1000 iteration, loss:0.077\n",
      " num 180 epoch \n",
      "####### Training Loss #######\n",
      "[0.07442947]\n",
      "Checking accuracy on test set\n",
      "Got 772 / 1000 correct (77.20)\n",
      "182 epoch,   500 iteration, loss:0.090\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "182 epoch,  1000 iteration, loss:0.071\n",
      " num 181 epoch \n",
      "####### Training Loss #######\n",
      "[0.07521057]\n",
      "Checking accuracy on test set\n",
      "Got 755 / 1000 correct (75.50)\n",
      "183 epoch,   500 iteration, loss:0.092\n",
      "Checking accuracy on test set\n",
      "Got 721 / 1000 correct (72.10)\n",
      "183 epoch,  1000 iteration, loss:0.123\n",
      " num 182 epoch \n",
      "####### Training Loss #######\n",
      "[0.1038211]\n",
      "Checking accuracy on test set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "184 epoch,   500 iteration, loss:0.087\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "184 epoch,  1000 iteration, loss:0.077\n",
      " num 183 epoch \n",
      "####### Training Loss #######\n",
      "[0.09398361]\n",
      "Checking accuracy on test set\n",
      "Got 768 / 1000 correct (76.80)\n",
      "185 epoch,   500 iteration, loss:0.061\n",
      "Checking accuracy on test set\n",
      "Got 766 / 1000 correct (76.60)\n",
      "185 epoch,  1000 iteration, loss:0.067\n",
      " num 184 epoch \n",
      "####### Training Loss #######\n",
      "[0.06611031]\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "186 epoch,   500 iteration, loss:0.094\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "186 epoch,  1000 iteration, loss:0.074\n",
      " num 185 epoch \n",
      "####### Training Loss #######\n",
      "[0.0816872]\n",
      "Checking accuracy on test set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "187 epoch,   500 iteration, loss:0.082\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "187 epoch,  1000 iteration, loss:0.089\n",
      " num 186 epoch \n",
      "####### Training Loss #######\n",
      "[0.08293054]\n",
      "Checking accuracy on test set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "188 epoch,   500 iteration, loss:0.063\n",
      "Checking accuracy on test set\n",
      "Got 762 / 1000 correct (76.20)\n",
      "188 epoch,  1000 iteration, loss:0.083\n",
      " num 187 epoch \n",
      "####### Training Loss #######\n",
      "[0.06787157]\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "189 epoch,   500 iteration, loss:0.089\n",
      "Checking accuracy on test set\n",
      "Got 768 / 1000 correct (76.80)\n",
      "189 epoch,  1000 iteration, loss:0.061\n",
      " num 188 epoch \n",
      "####### Training Loss #######\n",
      "[0.07826679]\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "190 epoch,   500 iteration, loss:0.068\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "190 epoch,  1000 iteration, loss:0.079\n",
      " num 189 epoch \n",
      "####### Training Loss #######\n",
      "[0.07408805]\n",
      "Checking accuracy on test set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "191 epoch,   500 iteration, loss:0.044\n",
      "Checking accuracy on test set\n",
      "Got 759 / 1000 correct (75.90)\n",
      "191 epoch,  1000 iteration, loss:0.078\n",
      " num 190 epoch \n",
      "####### Training Loss #######\n",
      "[0.06553661]\n",
      "Checking accuracy on test set\n",
      "Got 722 / 1000 correct (72.20)\n",
      "192 epoch,   500 iteration, loss:0.066\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "192 epoch,  1000 iteration, loss:0.101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num 191 epoch \n",
      "####### Training Loss #######\n",
      "[0.08737085]\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "193 epoch,   500 iteration, loss:0.091\n",
      "Checking accuracy on test set\n",
      "Got 765 / 1000 correct (76.50)\n",
      "193 epoch,  1000 iteration, loss:0.045\n",
      " num 192 epoch \n",
      "####### Training Loss #######\n",
      "[0.0677037]\n",
      "Checking accuracy on test set\n",
      "Got 765 / 1000 correct (76.50)\n",
      "194 epoch,   500 iteration, loss:0.060\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "194 epoch,  1000 iteration, loss:0.085\n",
      " num 193 epoch \n",
      "####### Training Loss #######\n",
      "[0.07131779]\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "195 epoch,   500 iteration, loss:0.078\n",
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "195 epoch,  1000 iteration, loss:0.092\n",
      " num 194 epoch \n",
      "####### Training Loss #######\n",
      "[0.07893835]\n",
      "Checking accuracy on test set\n",
      "Got 760 / 1000 correct (76.00)\n",
      "196 epoch,   500 iteration, loss:0.085\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "196 epoch,  1000 iteration, loss:0.068\n",
      " num 195 epoch \n",
      "####### Training Loss #######\n",
      "[0.07806946]\n",
      "Checking accuracy on test set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "197 epoch,   500 iteration, loss:0.089\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "197 epoch,  1000 iteration, loss:0.063\n",
      " num 196 epoch \n",
      "####### Training Loss #######\n",
      "[0.07590247]\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "198 epoch,   500 iteration, loss:0.066\n",
      "Checking accuracy on test set\n",
      "Got 755 / 1000 correct (75.50)\n",
      "198 epoch,  1000 iteration, loss:0.073\n",
      " num 197 epoch \n",
      "####### Training Loss #######\n",
      "[0.06731673]\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "199 epoch,   500 iteration, loss:0.041\n",
      "Checking accuracy on test set\n",
      "Got 729 / 1000 correct (72.90)\n",
      "199 epoch,  1000 iteration, loss:0.091\n",
      " num 198 epoch \n",
      "####### Training Loss #######\n",
      "[0.06903028]\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "200 epoch,   500 iteration, loss:0.060\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "200 epoch,  1000 iteration, loss:0.088\n",
      " num 199 epoch \n",
      "####### Training Loss #######\n",
      "[0.07762373]\n",
      "Checking accuracy on test set\n",
      "Got 768 / 1000 correct (76.80)\n",
      "201 epoch,   500 iteration, loss:0.089\n",
      "Checking accuracy on test set\n",
      "Got 759 / 1000 correct (75.90)\n",
      "201 epoch,  1000 iteration, loss:0.056\n",
      " num 200 epoch \n",
      "####### Training Loss #######\n",
      "[0.06988893]\n",
      "Checking accuracy on test set\n",
      "Got 770 / 1000 correct (77.00)\n",
      "202 epoch,   500 iteration, loss:0.071\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "202 epoch,  1000 iteration, loss:0.043\n",
      " num 201 epoch \n",
      "####### Training Loss #######\n",
      "[0.06547144]\n",
      "Checking accuracy on test set\n",
      "Got 774 / 1000 correct (77.40)\n",
      "203 epoch,   500 iteration, loss:0.061\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "203 epoch,  1000 iteration, loss:0.085\n",
      " num 202 epoch \n",
      "####### Training Loss #######\n",
      "[0.07495779]\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "204 epoch,   500 iteration, loss:0.065\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "204 epoch,  1000 iteration, loss:0.051\n",
      " num 203 epoch \n",
      "####### Training Loss #######\n",
      "[0.05885914]\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "205 epoch,   500 iteration, loss:0.064\n",
      "Checking accuracy on test set\n",
      "Got 768 / 1000 correct (76.80)\n",
      "205 epoch,  1000 iteration, loss:0.069\n",
      " num 204 epoch \n",
      "####### Training Loss #######\n",
      "[0.06462733]\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "206 epoch,   500 iteration, loss:0.069\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "206 epoch,  1000 iteration, loss:0.110\n",
      " num 205 epoch \n",
      "####### Training Loss #######\n",
      "[0.083159]\n",
      "Checking accuracy on test set\n",
      "Got 766 / 1000 correct (76.60)\n",
      "207 epoch,   500 iteration, loss:0.042\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "207 epoch,  1000 iteration, loss:0.058\n",
      " num 206 epoch \n",
      "####### Training Loss #######\n",
      "[0.05840917]\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "208 epoch,   500 iteration, loss:0.085\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "208 epoch,  1000 iteration, loss:0.069\n",
      " num 207 epoch \n",
      "####### Training Loss #######\n",
      "[0.08043092]\n",
      "Checking accuracy on test set\n",
      "Got 722 / 1000 correct (72.20)\n",
      "209 epoch,   500 iteration, loss:0.064\n",
      "Checking accuracy on test set\n",
      "Got 759 / 1000 correct (75.90)\n",
      "209 epoch,  1000 iteration, loss:0.101\n",
      " num 208 epoch \n",
      "####### Training Loss #######\n",
      "[0.07401927]\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "210 epoch,   500 iteration, loss:0.061\n",
      "Checking accuracy on test set\n",
      "Got 760 / 1000 correct (76.00)\n",
      "210 epoch,  1000 iteration, loss:0.070\n",
      " num 209 epoch \n",
      "####### Training Loss #######\n",
      "[0.06075989]\n",
      "Checking accuracy on test set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "211 epoch,   500 iteration, loss:0.085\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "211 epoch,  1000 iteration, loss:0.077\n",
      " num 210 epoch \n",
      "####### Training Loss #######\n",
      "[0.08261831]\n",
      "Checking accuracy on test set\n",
      "Got 755 / 1000 correct (75.50)\n",
      "212 epoch,   500 iteration, loss:0.088\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "212 epoch,  1000 iteration, loss:0.086\n",
      " num 211 epoch \n",
      "####### Training Loss #######\n",
      "[0.08280898]\n",
      "Checking accuracy on test set\n",
      "Got 760 / 1000 correct (76.00)\n",
      "213 epoch,   500 iteration, loss:0.056\n",
      "Checking accuracy on test set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "213 epoch,  1000 iteration, loss:0.065\n",
      " num 212 epoch \n",
      "####### Training Loss #######\n",
      "[0.05394437]\n",
      "Checking accuracy on test set\n",
      "Got 781 / 1000 correct (78.10)\n",
      "214 epoch,   500 iteration, loss:0.092\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "214 epoch,  1000 iteration, loss:0.043\n",
      " num 213 epoch \n",
      "####### Training Loss #######\n",
      "[0.07021281]\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "215 epoch,   500 iteration, loss:0.089\n",
      "Checking accuracy on test set\n",
      "Got 755 / 1000 correct (75.50)\n",
      "215 epoch,  1000 iteration, loss:0.060\n",
      " num 214 epoch \n",
      "####### Training Loss #######\n",
      "[0.08066719]\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "216 epoch,   500 iteration, loss:0.099\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "216 epoch,  1000 iteration, loss:0.079\n",
      " num 215 epoch \n",
      "####### Training Loss #######\n",
      "[0.09280645]\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "217 epoch,   500 iteration, loss:0.093\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "217 epoch,  1000 iteration, loss:0.076\n",
      " num 216 epoch \n",
      "####### Training Loss #######\n",
      "[0.07360396]\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "218 epoch,   500 iteration, loss:0.060\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "218 epoch,  1000 iteration, loss:0.069\n",
      " num 217 epoch \n",
      "####### Training Loss #######\n",
      "[0.06026692]\n",
      "Checking accuracy on test set\n",
      "Got 777 / 1000 correct (77.70)\n",
      "219 epoch,   500 iteration, loss:0.071\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "219 epoch,  1000 iteration, loss:0.073\n",
      " num 218 epoch \n",
      "####### Training Loss #######\n",
      "[0.06991616]\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "220 epoch,   500 iteration, loss:0.049\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "220 epoch,  1000 iteration, loss:0.060\n",
      " num 219 epoch \n",
      "####### Training Loss #######\n",
      "[0.06154511]\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "221 epoch,   500 iteration, loss:0.056\n",
      "Checking accuracy on test set\n",
      "Got 760 / 1000 correct (76.00)\n",
      "221 epoch,  1000 iteration, loss:0.063\n",
      " num 220 epoch \n",
      "####### Training Loss #######\n",
      "[0.05558998]\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "222 epoch,   500 iteration, loss:0.069\n",
      "Checking accuracy on test set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "222 epoch,  1000 iteration, loss:0.048\n",
      " num 221 epoch \n",
      "####### Training Loss #######\n",
      "[0.06542511]\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "223 epoch,   500 iteration, loss:0.061\n",
      "Checking accuracy on test set\n",
      "Got 728 / 1000 correct (72.80)\n",
      "223 epoch,  1000 iteration, loss:0.085\n",
      " num 222 epoch \n",
      "####### Training Loss #######\n",
      "[0.0813167]\n",
      "Checking accuracy on test set\n",
      "Got 767 / 1000 correct (76.70)\n",
      "224 epoch,   500 iteration, loss:0.044\n",
      "Checking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 760 / 1000 correct (76.00)\n",
      "224 epoch,  1000 iteration, loss:0.082\n",
      " num 223 epoch \n",
      "####### Training Loss #######\n",
      "[0.06168237]\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "225 epoch,   500 iteration, loss:0.062\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "225 epoch,  1000 iteration, loss:0.065\n",
      " num 224 epoch \n",
      "####### Training Loss #######\n",
      "[0.06002546]\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "226 epoch,   500 iteration, loss:0.054\n",
      "Checking accuracy on test set\n",
      "Got 708 / 1000 correct (70.80)\n",
      "226 epoch,  1000 iteration, loss:0.079\n",
      " num 225 epoch \n",
      "####### Training Loss #######\n",
      "[0.07084378]\n",
      "Checking accuracy on test set\n",
      "Got 765 / 1000 correct (76.50)\n",
      "227 epoch,   500 iteration, loss:0.060\n",
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "227 epoch,  1000 iteration, loss:0.074\n",
      " num 226 epoch \n",
      "####### Training Loss #######\n",
      "[0.07375768]\n",
      "Checking accuracy on test set\n",
      "Got 776 / 1000 correct (77.60)\n",
      "228 epoch,   500 iteration, loss:0.052\n",
      "Checking accuracy on test set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "228 epoch,  1000 iteration, loss:0.073\n",
      " num 227 epoch \n",
      "####### Training Loss #######\n",
      "[0.06066695]\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "229 epoch,   500 iteration, loss:0.060\n",
      "Checking accuracy on test set\n",
      "Got 721 / 1000 correct (72.10)\n",
      "229 epoch,  1000 iteration, loss:0.114\n",
      " num 228 epoch \n",
      "####### Training Loss #######\n",
      "[0.0866185]\n",
      "Checking accuracy on test set\n",
      "Got 755 / 1000 correct (75.50)\n",
      "230 epoch,   500 iteration, loss:0.096\n",
      "Checking accuracy on test set\n",
      "Got 777 / 1000 correct (77.70)\n",
      "230 epoch,  1000 iteration, loss:0.059\n",
      " num 229 epoch \n",
      "####### Training Loss #######\n",
      "[0.08531332]\n",
      "Checking accuracy on test set\n",
      "Got 773 / 1000 correct (77.30)\n",
      "231 epoch,   500 iteration, loss:0.053\n",
      "Checking accuracy on test set\n",
      "Got 765 / 1000 correct (76.50)\n",
      "231 epoch,  1000 iteration, loss:0.049\n",
      " num 230 epoch \n",
      "####### Training Loss #######\n",
      "[0.06024187]\n",
      "Checking accuracy on test set\n",
      "Got 729 / 1000 correct (72.90)\n",
      "232 epoch,   500 iteration, loss:0.101\n",
      "Checking accuracy on test set\n",
      "Got 767 / 1000 correct (76.70)\n",
      "232 epoch,  1000 iteration, loss:0.075\n",
      " num 231 epoch \n",
      "####### Training Loss #######\n",
      "[0.08471584]\n",
      "Checking accuracy on test set\n",
      "Got 770 / 1000 correct (77.00)\n",
      "233 epoch,   500 iteration, loss:0.085\n",
      "Checking accuracy on test set\n",
      "Got 761 / 1000 correct (76.10)\n",
      "233 epoch,  1000 iteration, loss:0.070\n",
      " num 232 epoch \n",
      "####### Training Loss #######\n",
      "[0.0716423]\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "234 epoch,   500 iteration, loss:0.044\n",
      "Checking accuracy on test set\n",
      "Got 774 / 1000 correct (77.40)\n",
      "234 epoch,  1000 iteration, loss:0.037\n",
      " num 233 epoch \n",
      "####### Training Loss #######\n",
      "[0.04392787]\n",
      "Checking accuracy on test set\n",
      "Got 760 / 1000 correct (76.00)\n",
      "235 epoch,   500 iteration, loss:0.069\n",
      "Checking accuracy on test set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "235 epoch,  1000 iteration, loss:0.090\n",
      " num 234 epoch \n",
      "####### Training Loss #######\n",
      "[0.07344901]\n",
      "Checking accuracy on test set\n",
      "Got 774 / 1000 correct (77.40)\n",
      "236 epoch,   500 iteration, loss:0.075\n",
      "Checking accuracy on test set\n",
      "Got 722 / 1000 correct (72.20)\n",
      "236 epoch,  1000 iteration, loss:0.083\n",
      " num 235 epoch \n",
      "####### Training Loss #######\n",
      "[0.07832275]\n",
      "Checking accuracy on test set\n",
      "Got 767 / 1000 correct (76.70)\n",
      "237 epoch,   500 iteration, loss:0.085\n",
      "Checking accuracy on test set\n",
      "Got 774 / 1000 correct (77.40)\n",
      "237 epoch,  1000 iteration, loss:0.036\n",
      " num 236 epoch \n",
      "####### Training Loss #######\n",
      "[0.05431099]\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "238 epoch,   500 iteration, loss:0.069\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "238 epoch,  1000 iteration, loss:0.085\n",
      " num 237 epoch \n",
      "####### Training Loss #######\n",
      "[0.0770175]\n",
      "Checking accuracy on test set\n",
      "Got 769 / 1000 correct (76.90)\n",
      "239 epoch,   500 iteration, loss:0.063\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "239 epoch,  1000 iteration, loss:0.082\n",
      " num 238 epoch \n",
      "####### Training Loss #######\n",
      "[0.0821652]\n",
      "Checking accuracy on test set\n",
      "Got 768 / 1000 correct (76.80)\n",
      "240 epoch,   500 iteration, loss:0.062\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "240 epoch,  1000 iteration, loss:0.038\n",
      " num 239 epoch \n",
      "####### Training Loss #######\n",
      "[0.04672812]\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "241 epoch,   500 iteration, loss:0.082\n",
      "Checking accuracy on test set\n",
      "Got 753 / 1000 correct (75.30)\n",
      "241 epoch,  1000 iteration, loss:0.085\n",
      " num 240 epoch \n",
      "####### Training Loss #######\n",
      "[0.07162627]\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "242 epoch,   500 iteration, loss:0.092\n",
      "Checking accuracy on test set\n",
      "Got 769 / 1000 correct (76.90)\n",
      "242 epoch,  1000 iteration, loss:0.065\n",
      " num 241 epoch \n",
      "####### Training Loss #######\n",
      "[0.07229506]\n",
      "Checking accuracy on test set\n",
      "Got 777 / 1000 correct (77.70)\n",
      "243 epoch,   500 iteration, loss:0.069\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "243 epoch,  1000 iteration, loss:0.084\n",
      " num 242 epoch \n",
      "####### Training Loss #######\n",
      "[0.0760645]\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "244 epoch,   500 iteration, loss:0.083\n",
      "Checking accuracy on test set\n",
      "Got 762 / 1000 correct (76.20)\n",
      "244 epoch,  1000 iteration, loss:0.110\n",
      " num 243 epoch \n",
      "####### Training Loss #######\n",
      "[0.09264194]\n",
      "Checking accuracy on test set\n",
      "Got 770 / 1000 correct (77.00)\n",
      "245 epoch,   500 iteration, loss:0.060\n",
      "Checking accuracy on test set\n",
      "Got 753 / 1000 correct (75.30)\n",
      "245 epoch,  1000 iteration, loss:0.047\n",
      " num 244 epoch \n",
      "####### Training Loss #######\n",
      "[0.0572229]\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "246 epoch,   500 iteration, loss:0.094\n",
      "Checking accuracy on test set\n",
      "Got 765 / 1000 correct (76.50)\n",
      "246 epoch,  1000 iteration, loss:0.043\n",
      " num 245 epoch \n",
      "####### Training Loss #######\n",
      "[0.06024968]\n",
      "Checking accuracy on test set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "247 epoch,   500 iteration, loss:0.084\n",
      "Checking accuracy on test set\n",
      "Got 770 / 1000 correct (77.00)\n",
      "247 epoch,  1000 iteration, loss:0.030\n",
      " num 246 epoch \n",
      "####### Training Loss #######\n",
      "[0.05595605]\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "248 epoch,   500 iteration, loss:0.059\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "248 epoch,  1000 iteration, loss:0.053\n",
      " num 247 epoch \n",
      "####### Training Loss #######\n",
      "[0.05847466]\n",
      "Checking accuracy on test set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "249 epoch,   500 iteration, loss:0.065\n",
      "Checking accuracy on test set\n",
      "Got 760 / 1000 correct (76.00)\n",
      "249 epoch,  1000 iteration, loss:0.071\n",
      " num 248 epoch \n",
      "####### Training Loss #######\n",
      "[0.07146128]\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "250 epoch,   500 iteration, loss:0.069\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "250 epoch,  1000 iteration, loss:0.053\n",
      " num 249 epoch \n",
      "####### Training Loss #######\n",
      "[0.06455184]\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "251 epoch,   500 iteration, loss:0.077\n",
      "Checking accuracy on test set\n",
      "Got 769 / 1000 correct (76.90)\n",
      "251 epoch,  1000 iteration, loss:0.051\n",
      " num 250 epoch \n",
      "####### Training Loss #######\n",
      "[0.05729322]\n",
      "Checking accuracy on test set\n",
      "Got 722 / 1000 correct (72.20)\n",
      "252 epoch,   500 iteration, loss:0.054\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "252 epoch,  1000 iteration, loss:0.072\n",
      " num 251 epoch \n",
      "####### Training Loss #######\n",
      "[0.06485929]\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "253 epoch,   500 iteration, loss:0.069\n",
      "Checking accuracy on test set\n",
      "Got 762 / 1000 correct (76.20)\n",
      "253 epoch,  1000 iteration, loss:0.034\n",
      " num 252 epoch \n",
      "####### Training Loss #######\n",
      "[0.05189916]\n",
      "Checking accuracy on test set\n",
      "Got 791 / 1000 correct (79.10)\n",
      "254 epoch,   500 iteration, loss:0.073\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "254 epoch,  1000 iteration, loss:0.081\n",
      " num 253 epoch \n",
      "####### Training Loss #######\n",
      "[0.07781526]\n",
      "Checking accuracy on test set\n",
      "Got 693 / 1000 correct (69.30)\n",
      "255 epoch,   500 iteration, loss:0.074\n",
      "Checking accuracy on test set\n",
      "Got 719 / 1000 correct (71.90)\n",
      "255 epoch,  1000 iteration, loss:0.103\n",
      " num 254 epoch \n",
      "####### Training Loss #######\n",
      "[0.08220906]\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "256 epoch,   500 iteration, loss:0.063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "256 epoch,  1000 iteration, loss:0.048\n",
      " num 255 epoch \n",
      "####### Training Loss #######\n",
      "[0.05973746]\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "257 epoch,   500 iteration, loss:0.059\n",
      "Checking accuracy on test set\n",
      "Got 755 / 1000 correct (75.50)\n",
      "257 epoch,  1000 iteration, loss:0.055\n",
      " num 256 epoch \n",
      "####### Training Loss #######\n",
      "[0.06335831]\n",
      "Checking accuracy on test set\n",
      "Got 770 / 1000 correct (77.00)\n",
      "258 epoch,   500 iteration, loss:0.078\n",
      "Checking accuracy on test set\n",
      "Got 760 / 1000 correct (76.00)\n",
      "258 epoch,  1000 iteration, loss:0.056\n",
      " num 257 epoch \n",
      "####### Training Loss #######\n",
      "[0.06602053]\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "259 epoch,   500 iteration, loss:0.062\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "259 epoch,  1000 iteration, loss:0.032\n",
      " num 258 epoch \n",
      "####### Training Loss #######\n",
      "[0.05428074]\n",
      "Checking accuracy on test set\n",
      "Got 771 / 1000 correct (77.10)\n",
      "260 epoch,   500 iteration, loss:0.062\n",
      "Checking accuracy on test set\n",
      "Got 754 / 1000 correct (75.40)\n",
      "260 epoch,  1000 iteration, loss:0.057\n",
      " num 259 epoch \n",
      "####### Training Loss #######\n",
      "[0.05621879]\n",
      "Checking accuracy on test set\n",
      "Got 760 / 1000 correct (76.00)\n",
      "261 epoch,   500 iteration, loss:0.062\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "261 epoch,  1000 iteration, loss:0.076\n",
      " num 260 epoch \n",
      "####### Training Loss #######\n",
      "[0.07039631]\n",
      "Checking accuracy on test set\n",
      "Got 765 / 1000 correct (76.50)\n",
      "262 epoch,   500 iteration, loss:0.063\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "262 epoch,  1000 iteration, loss:0.072\n",
      " num 261 epoch \n",
      "####### Training Loss #######\n",
      "[0.06690184]\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "263 epoch,   500 iteration, loss:0.073\n",
      "Checking accuracy on test set\n",
      "Got 753 / 1000 correct (75.30)\n",
      "263 epoch,  1000 iteration, loss:0.086\n",
      " num 262 epoch \n",
      "####### Training Loss #######\n",
      "[0.07759276]\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "264 epoch,   500 iteration, loss:0.050\n",
      "Checking accuracy on test set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "264 epoch,  1000 iteration, loss:0.070\n",
      " num 263 epoch \n",
      "####### Training Loss #######\n",
      "[0.06039943]\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "265 epoch,   500 iteration, loss:0.090\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "265 epoch,  1000 iteration, loss:0.088\n",
      " num 264 epoch \n",
      "####### Training Loss #######\n",
      "[0.08391404]\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "266 epoch,   500 iteration, loss:0.097\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "266 epoch,  1000 iteration, loss:0.075\n",
      " num 265 epoch \n",
      "####### Training Loss #######\n",
      "[0.08373663]\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "267 epoch,   500 iteration, loss:0.090\n",
      "Checking accuracy on test set\n",
      "Got 765 / 1000 correct (76.50)\n",
      "267 epoch,  1000 iteration, loss:0.084\n",
      " num 266 epoch \n",
      "####### Training Loss #######\n",
      "[0.08174195]\n",
      "Checking accuracy on test set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "268 epoch,   500 iteration, loss:0.041\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "268 epoch,  1000 iteration, loss:0.085\n",
      " num 267 epoch \n",
      "####### Training Loss #######\n",
      "[0.07471638]\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "269 epoch,   500 iteration, loss:0.052\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "269 epoch,  1000 iteration, loss:0.081\n",
      " num 268 epoch \n",
      "####### Training Loss #######\n",
      "[0.06852985]\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "270 epoch,   500 iteration, loss:0.067\n",
      "Checking accuracy on test set\n",
      "Got 774 / 1000 correct (77.40)\n",
      "270 epoch,  1000 iteration, loss:0.073\n",
      " num 269 epoch \n",
      "####### Training Loss #######\n",
      "[0.06742117]\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "271 epoch,   500 iteration, loss:0.074\n",
      "Checking accuracy on test set\n",
      "Got 782 / 1000 correct (78.20)\n",
      "271 epoch,  1000 iteration, loss:0.072\n",
      " num 270 epoch \n",
      "####### Training Loss #######\n",
      "[0.06930969]\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "272 epoch,   500 iteration, loss:0.042\n",
      "Checking accuracy on test set\n",
      "Got 761 / 1000 correct (76.10)\n",
      "272 epoch,  1000 iteration, loss:0.059\n",
      " num 271 epoch \n",
      "####### Training Loss #######\n",
      "[0.05246442]\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "273 epoch,   500 iteration, loss:0.058\n",
      "Checking accuracy on test set\n",
      "Got 775 / 1000 correct (77.50)\n",
      "273 epoch,  1000 iteration, loss:0.047\n",
      " num 272 epoch \n",
      "####### Training Loss #######\n",
      "[0.05084501]\n",
      "Checking accuracy on test set\n",
      "Got 712 / 1000 correct (71.20)\n",
      "274 epoch,   500 iteration, loss:0.043\n",
      "Checking accuracy on test set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "274 epoch,  1000 iteration, loss:0.089\n",
      " num 273 epoch \n",
      "####### Training Loss #######\n",
      "[0.05864875]\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "275 epoch,   500 iteration, loss:0.060\n",
      "Checking accuracy on test set\n",
      "Got 773 / 1000 correct (77.30)\n",
      "275 epoch,  1000 iteration, loss:0.054\n",
      " num 274 epoch \n",
      "####### Training Loss #######\n",
      "[0.05448918]\n",
      "Checking accuracy on test set\n",
      "Got 779 / 1000 correct (77.90)\n",
      "276 epoch,   500 iteration, loss:0.061\n",
      "Checking accuracy on test set\n",
      "Got 771 / 1000 correct (77.10)\n",
      "276 epoch,  1000 iteration, loss:0.068\n",
      " num 275 epoch \n",
      "####### Training Loss #######\n",
      "[0.07189312]\n",
      "Checking accuracy on test set\n",
      "Got 760 / 1000 correct (76.00)\n",
      "277 epoch,   500 iteration, loss:0.077\n",
      "Checking accuracy on test set\n",
      "Got 774 / 1000 correct (77.40)\n",
      "277 epoch,  1000 iteration, loss:0.045\n",
      " num 276 epoch \n",
      "####### Training Loss #######\n",
      "[0.06094399]\n",
      "Checking accuracy on test set\n",
      "Got 767 / 1000 correct (76.70)\n",
      "278 epoch,   500 iteration, loss:0.073\n",
      "Checking accuracy on test set\n",
      "Got 773 / 1000 correct (77.30)\n",
      "278 epoch,  1000 iteration, loss:0.048\n",
      " num 277 epoch \n",
      "####### Training Loss #######\n",
      "[0.05355642]\n",
      "Checking accuracy on test set\n",
      "Got 767 / 1000 correct (76.70)\n",
      "279 epoch,   500 iteration, loss:0.068\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "279 epoch,  1000 iteration, loss:0.082\n",
      " num 278 epoch \n",
      "####### Training Loss #######\n",
      "[0.07084685]\n",
      "Checking accuracy on test set\n",
      "Got 724 / 1000 correct (72.40)\n",
      "280 epoch,   500 iteration, loss:0.052\n",
      "Checking accuracy on test set\n",
      "Got 777 / 1000 correct (77.70)\n",
      "280 epoch,  1000 iteration, loss:0.071\n",
      " num 279 epoch \n",
      "####### Training Loss #######\n",
      "[0.06308138]\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "281 epoch,   500 iteration, loss:0.061\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "281 epoch,  1000 iteration, loss:0.072\n",
      " num 280 epoch \n",
      "####### Training Loss #######\n",
      "[0.07018023]\n",
      "Checking accuracy on test set\n",
      "Got 770 / 1000 correct (77.00)\n",
      "282 epoch,   500 iteration, loss:0.038\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "282 epoch,  1000 iteration, loss:0.070\n",
      " num 281 epoch \n",
      "####### Training Loss #######\n",
      "[0.06632691]\n",
      "Checking accuracy on test set\n",
      "Got 755 / 1000 correct (75.50)\n",
      "283 epoch,   500 iteration, loss:0.054\n",
      "Checking accuracy on test set\n",
      "Got 773 / 1000 correct (77.30)\n",
      "283 epoch,  1000 iteration, loss:0.090\n",
      " num 282 epoch \n",
      "####### Training Loss #######\n",
      "[0.06665129]\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "284 epoch,   500 iteration, loss:0.074\n",
      "Checking accuracy on test set\n",
      "Got 776 / 1000 correct (77.60)\n",
      "284 epoch,  1000 iteration, loss:0.078\n",
      " num 283 epoch \n",
      "####### Training Loss #######\n",
      "[0.06734446]\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "285 epoch,   500 iteration, loss:0.101\n",
      "Checking accuracy on test set\n",
      "Got 769 / 1000 correct (76.90)\n",
      "285 epoch,  1000 iteration, loss:0.044\n",
      " num 284 epoch \n",
      "####### Training Loss #######\n",
      "[0.07011608]\n",
      "Checking accuracy on test set\n",
      "Got 713 / 1000 correct (71.30)\n",
      "286 epoch,   500 iteration, loss:0.070\n",
      "Checking accuracy on test set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "286 epoch,  1000 iteration, loss:0.094\n",
      " num 285 epoch \n",
      "####### Training Loss #######\n",
      "[0.08630066]\n",
      "Checking accuracy on test set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "287 epoch,   500 iteration, loss:0.075\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "287 epoch,  1000 iteration, loss:0.067\n",
      " num 286 epoch \n",
      "####### Training Loss #######\n",
      "[0.06261343]\n",
      "Checking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 761 / 1000 correct (76.10)\n",
      "288 epoch,   500 iteration, loss:0.056\n",
      "Checking accuracy on test set\n",
      "Got 755 / 1000 correct (75.50)\n",
      "288 epoch,  1000 iteration, loss:0.071\n",
      " num 287 epoch \n",
      "####### Training Loss #######\n",
      "[0.06381788]\n",
      "Checking accuracy on test set\n",
      "Got 766 / 1000 correct (76.60)\n",
      "289 epoch,   500 iteration, loss:0.040\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "289 epoch,  1000 iteration, loss:0.046\n",
      " num 288 epoch \n",
      "####### Training Loss #######\n",
      "[0.05122744]\n",
      "Checking accuracy on test set\n",
      "Got 768 / 1000 correct (76.80)\n",
      "290 epoch,   500 iteration, loss:0.040\n",
      "Checking accuracy on test set\n",
      "Got 759 / 1000 correct (75.90)\n",
      "290 epoch,  1000 iteration, loss:0.062\n",
      " num 289 epoch \n",
      "####### Training Loss #######\n",
      "[0.05901718]\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "291 epoch,   500 iteration, loss:0.040\n",
      "Checking accuracy on test set\n",
      "Got 770 / 1000 correct (77.00)\n",
      "291 epoch,  1000 iteration, loss:0.055\n",
      " num 290 epoch \n",
      "####### Training Loss #######\n",
      "[0.0518642]\n",
      "Checking accuracy on test set\n",
      "Got 708 / 1000 correct (70.80)\n",
      "292 epoch,   500 iteration, loss:0.060\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "292 epoch,  1000 iteration, loss:0.063\n",
      " num 291 epoch \n",
      "####### Training Loss #######\n",
      "[0.0623399]\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "293 epoch,   500 iteration, loss:0.098\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "293 epoch,  1000 iteration, loss:0.078\n",
      " num 292 epoch \n",
      "####### Training Loss #######\n",
      "[0.07726684]\n",
      "Checking accuracy on test set\n",
      "Got 767 / 1000 correct (76.70)\n",
      "294 epoch,   500 iteration, loss:0.077\n",
      "Checking accuracy on test set\n",
      "Got 754 / 1000 correct (75.40)\n",
      "294 epoch,  1000 iteration, loss:0.056\n",
      " num 293 epoch \n",
      "####### Training Loss #######\n",
      "[0.06615937]\n",
      "Checking accuracy on test set\n",
      "Got 770 / 1000 correct (77.00)\n",
      "295 epoch,   500 iteration, loss:0.068\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "295 epoch,  1000 iteration, loss:0.057\n",
      " num 294 epoch \n",
      "####### Training Loss #######\n",
      "[0.06137483]\n",
      "Checking accuracy on test set\n",
      "Got 762 / 1000 correct (76.20)\n",
      "296 epoch,   500 iteration, loss:0.021\n",
      "Checking accuracy on test set\n",
      "Got 759 / 1000 correct (75.90)\n",
      "296 epoch,  1000 iteration, loss:0.067\n",
      " num 295 epoch \n",
      "####### Training Loss #######\n",
      "[0.04315053]\n",
      "Checking accuracy on test set\n",
      "Got 715 / 1000 correct (71.50)\n",
      "297 epoch,   500 iteration, loss:0.075\n",
      "Checking accuracy on test set\n",
      "Got 775 / 1000 correct (77.50)\n",
      "297 epoch,  1000 iteration, loss:0.046\n",
      " num 296 epoch \n",
      "####### Training Loss #######\n",
      "[0.05908178]\n",
      "Checking accuracy on test set\n",
      "Got 760 / 1000 correct (76.00)\n",
      "298 epoch,   500 iteration, loss:0.089\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "298 epoch,  1000 iteration, loss:0.054\n",
      " num 297 epoch \n",
      "####### Training Loss #######\n",
      "[0.0657523]\n",
      "Checking accuracy on test set\n",
      "Got 781 / 1000 correct (78.10)\n",
      "299 epoch,   500 iteration, loss:0.031\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "299 epoch,  1000 iteration, loss:0.051\n",
      " num 298 epoch \n",
      "####### Training Loss #######\n",
      "[0.04434854]\n",
      "Checking accuracy on test set\n",
      "Got 780 / 1000 correct (78.00)\n",
      "300 epoch,   500 iteration, loss:0.059\n",
      "Checking accuracy on test set\n",
      "Got 770 / 1000 correct (77.00)\n",
      "300 epoch,  1000 iteration, loss:0.051\n",
      " num 299 epoch \n",
      "####### Training Loss #######\n",
      "[0.05600361]\n",
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "301 epoch,   500 iteration, loss:0.082\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "301 epoch,  1000 iteration, loss:0.026\n",
      " num 300 epoch \n",
      "####### Training Loss #######\n",
      "[0.08055651]\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "302 epoch,   500 iteration, loss:0.042\n",
      "Checking accuracy on test set\n",
      "Got 772 / 1000 correct (77.20)\n",
      "302 epoch,  1000 iteration, loss:0.061\n",
      " num 301 epoch \n",
      "####### Training Loss #######\n",
      "[0.05988224]\n",
      "Checking accuracy on test set\n",
      "Got 776 / 1000 correct (77.60)\n",
      "303 epoch,   500 iteration, loss:0.039\n",
      "Checking accuracy on test set\n",
      "Got 769 / 1000 correct (76.90)\n",
      "303 epoch,  1000 iteration, loss:0.066\n",
      " num 302 epoch \n",
      "####### Training Loss #######\n",
      "[0.05179544]\n",
      "Checking accuracy on test set\n",
      "Got 783 / 1000 correct (78.30)\n",
      "304 epoch,   500 iteration, loss:0.060\n",
      "Checking accuracy on test set\n",
      "Got 760 / 1000 correct (76.00)\n",
      "304 epoch,  1000 iteration, loss:0.051\n",
      " num 303 epoch \n",
      "####### Training Loss #######\n",
      "[0.04896366]\n",
      "Checking accuracy on test set\n",
      "Got 707 / 1000 correct (70.70)\n",
      "305 epoch,   500 iteration, loss:0.055\n",
      "Checking accuracy on test set\n",
      "Got 759 / 1000 correct (75.90)\n",
      "305 epoch,  1000 iteration, loss:0.064\n",
      " num 304 epoch \n",
      "####### Training Loss #######\n",
      "[0.05805985]\n",
      "Checking accuracy on test set\n",
      "Got 782 / 1000 correct (78.20)\n",
      "306 epoch,   500 iteration, loss:0.070\n",
      "Checking accuracy on test set\n",
      "Got 789 / 1000 correct (78.90)\n",
      "306 epoch,  1000 iteration, loss:0.059\n",
      " num 305 epoch \n",
      "####### Training Loss #######\n",
      "[0.05996169]\n",
      "Checking accuracy on test set\n",
      "Got 769 / 1000 correct (76.90)\n",
      "307 epoch,   500 iteration, loss:0.041\n",
      "Checking accuracy on test set\n",
      "Got 726 / 1000 correct (72.60)\n",
      "307 epoch,  1000 iteration, loss:0.061\n",
      " num 306 epoch \n",
      "####### Training Loss #######\n",
      "[0.05478074]\n",
      "Checking accuracy on test set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "308 epoch,   500 iteration, loss:0.066\n",
      "Checking accuracy on test set\n",
      "Got 765 / 1000 correct (76.50)\n",
      "308 epoch,  1000 iteration, loss:0.055\n",
      " num 307 epoch \n",
      "####### Training Loss #######\n",
      "[0.05249875]\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "309 epoch,   500 iteration, loss:0.065\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "309 epoch,  1000 iteration, loss:0.070\n",
      " num 308 epoch \n",
      "####### Training Loss #######\n",
      "[0.0713297]\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "310 epoch,   500 iteration, loss:0.062\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "310 epoch,  1000 iteration, loss:0.065\n",
      " num 309 epoch \n",
      "####### Training Loss #######\n",
      "[0.07686537]\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "311 epoch,   500 iteration, loss:0.057\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "311 epoch,  1000 iteration, loss:0.073\n",
      " num 310 epoch \n",
      "####### Training Loss #######\n",
      "[0.06726111]\n",
      "Checking accuracy on test set\n",
      "Got 782 / 1000 correct (78.20)\n",
      "312 epoch,   500 iteration, loss:0.047\n",
      "Checking accuracy on test set\n",
      "Got 782 / 1000 correct (78.20)\n",
      "312 epoch,  1000 iteration, loss:0.067\n",
      " num 311 epoch \n",
      "####### Training Loss #######\n",
      "[0.05138725]\n",
      "Checking accuracy on test set\n",
      "Got 777 / 1000 correct (77.70)\n",
      "313 epoch,   500 iteration, loss:0.041\n",
      "Checking accuracy on test set\n",
      "Got 788 / 1000 correct (78.80)\n",
      "313 epoch,  1000 iteration, loss:0.054\n",
      " num 312 epoch \n",
      "####### Training Loss #######\n",
      "[0.04490553]\n",
      "Checking accuracy on test set\n",
      "Got 784 / 1000 correct (78.40)\n",
      "314 epoch,   500 iteration, loss:0.071\n",
      "Checking accuracy on test set\n",
      "Got 784 / 1000 correct (78.40)\n",
      "314 epoch,  1000 iteration, loss:0.068\n",
      " num 313 epoch \n",
      "####### Training Loss #######\n",
      "[0.06237134]\n",
      "Checking accuracy on test set\n",
      "Got 781 / 1000 correct (78.10)\n",
      "315 epoch,   500 iteration, loss:0.071\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "315 epoch,  1000 iteration, loss:0.086\n",
      " num 314 epoch \n",
      "####### Training Loss #######\n",
      "[0.0759304]\n",
      "Checking accuracy on test set\n",
      "Got 753 / 1000 correct (75.30)\n",
      "316 epoch,   500 iteration, loss:0.050\n",
      "Checking accuracy on test set\n",
      "Got 773 / 1000 correct (77.30)\n",
      "316 epoch,  1000 iteration, loss:0.061\n",
      " num 315 epoch \n",
      "####### Training Loss #######\n",
      "[0.06316866]\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "317 epoch,   500 iteration, loss:0.060\n",
      "Checking accuracy on test set\n",
      "Got 761 / 1000 correct (76.10)\n",
      "317 epoch,  1000 iteration, loss:0.075\n",
      " num 316 epoch \n",
      "####### Training Loss #######\n",
      "[0.07302267]\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "318 epoch,   500 iteration, loss:0.055\n",
      "Checking accuracy on test set\n",
      "Got 766 / 1000 correct (76.60)\n",
      "318 epoch,  1000 iteration, loss:0.063\n",
      " num 317 epoch \n",
      "####### Training Loss #######\n",
      "[0.05690711]\n",
      "Checking accuracy on test set\n",
      "Got 766 / 1000 correct (76.60)\n",
      "319 epoch,   500 iteration, loss:0.055\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "319 epoch,  1000 iteration, loss:0.080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num 318 epoch \n",
      "####### Training Loss #######\n",
      "[0.06326061]\n",
      "Checking accuracy on test set\n",
      "Got 771 / 1000 correct (77.10)\n",
      "320 epoch,   500 iteration, loss:0.068\n",
      "Checking accuracy on test set\n",
      "Got 779 / 1000 correct (77.90)\n",
      "320 epoch,  1000 iteration, loss:0.044\n",
      " num 319 epoch \n",
      "####### Training Loss #######\n",
      "[0.05212913]\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "321 epoch,   500 iteration, loss:0.048\n",
      "Checking accuracy on test set\n",
      "Got 717 / 1000 correct (71.70)\n",
      "321 epoch,  1000 iteration, loss:0.072\n",
      " num 320 epoch \n",
      "####### Training Loss #######\n",
      "[0.06214204]\n",
      "Checking accuracy on test set\n",
      "Got 761 / 1000 correct (76.10)\n",
      "322 epoch,   500 iteration, loss:0.056\n",
      "Checking accuracy on test set\n",
      "Got 761 / 1000 correct (76.10)\n",
      "322 epoch,  1000 iteration, loss:0.054\n",
      " num 321 epoch \n",
      "####### Training Loss #######\n",
      "[0.05311508]\n",
      "Checking accuracy on test set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "323 epoch,   500 iteration, loss:0.032\n",
      "Checking accuracy on test set\n",
      "Got 766 / 1000 correct (76.60)\n",
      "323 epoch,  1000 iteration, loss:0.052\n",
      " num 322 epoch \n",
      "####### Training Loss #######\n",
      "[0.04487175]\n",
      "Checking accuracy on test set\n",
      "Got 765 / 1000 correct (76.50)\n",
      "324 epoch,   500 iteration, loss:0.044\n",
      "Checking accuracy on test set\n",
      "Got 762 / 1000 correct (76.20)\n",
      "324 epoch,  1000 iteration, loss:0.061\n",
      " num 323 epoch \n",
      "####### Training Loss #######\n",
      "[0.05640799]\n",
      "Checking accuracy on test set\n",
      "Got 772 / 1000 correct (77.20)\n",
      "325 epoch,   500 iteration, loss:0.050\n",
      "Checking accuracy on test set\n",
      "Got 706 / 1000 correct (70.60)\n",
      "325 epoch,  1000 iteration, loss:0.064\n",
      " num 324 epoch \n",
      "####### Training Loss #######\n",
      "[0.05995258]\n",
      "Checking accuracy on test set\n",
      "Got 767 / 1000 correct (76.70)\n",
      "326 epoch,   500 iteration, loss:0.060\n",
      "Checking accuracy on test set\n",
      "Got 784 / 1000 correct (78.40)\n",
      "326 epoch,  1000 iteration, loss:0.049\n",
      " num 325 epoch \n",
      "####### Training Loss #######\n",
      "[0.05610024]\n",
      "Checking accuracy on test set\n",
      "Got 768 / 1000 correct (76.80)\n",
      "327 epoch,   500 iteration, loss:0.084\n",
      "Checking accuracy on test set\n",
      "Got 779 / 1000 correct (77.90)\n",
      "327 epoch,  1000 iteration, loss:0.063\n",
      " num 326 epoch \n",
      "####### Training Loss #######\n",
      "[0.06869882]\n",
      "Checking accuracy on test set\n",
      "Got 787 / 1000 correct (78.70)\n",
      "328 epoch,   500 iteration, loss:0.056\n",
      "Checking accuracy on test set\n",
      "Got 791 / 1000 correct (79.10)\n",
      "328 epoch,  1000 iteration, loss:0.020\n",
      " num 327 epoch \n",
      "####### Training Loss #######\n",
      "[0.04331936]\n",
      "Checking accuracy on test set\n",
      "Got 778 / 1000 correct (77.80)\n",
      "329 epoch,   500 iteration, loss:0.064\n",
      "Checking accuracy on test set\n",
      "Got 766 / 1000 correct (76.60)\n",
      "329 epoch,  1000 iteration, loss:0.047\n",
      " num 328 epoch \n",
      "####### Training Loss #######\n",
      "[0.06131729]\n",
      "Checking accuracy on test set\n",
      "Got 769 / 1000 correct (76.90)\n",
      "330 epoch,   500 iteration, loss:0.060\n",
      "Checking accuracy on test set\n",
      "Got 795 / 1000 correct (79.50)\n",
      "330 epoch,  1000 iteration, loss:0.091\n",
      " num 329 epoch \n",
      "####### Training Loss #######\n",
      "[0.06707995]\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "331 epoch,   500 iteration, loss:0.064\n",
      "Checking accuracy on test set\n",
      "Got 728 / 1000 correct (72.80)\n",
      "331 epoch,  1000 iteration, loss:0.075\n",
      " num 330 epoch \n",
      "####### Training Loss #######\n",
      "[0.06699013]\n",
      "Checking accuracy on test set\n",
      "Got 776 / 1000 correct (77.60)\n",
      "332 epoch,   500 iteration, loss:0.094\n",
      "Checking accuracy on test set\n",
      "Got 787 / 1000 correct (78.70)\n",
      "332 epoch,  1000 iteration, loss:0.075\n",
      " num 331 epoch \n",
      "####### Training Loss #######\n",
      "[0.08275388]\n",
      "Checking accuracy on test set\n",
      "Got 769 / 1000 correct (76.90)\n",
      "333 epoch,   500 iteration, loss:0.049\n",
      "Checking accuracy on test set\n",
      "Got 776 / 1000 correct (77.60)\n",
      "333 epoch,  1000 iteration, loss:0.028\n",
      " num 332 epoch \n",
      "####### Training Loss #######\n",
      "[0.04121479]\n",
      "Checking accuracy on test set\n",
      "Got 776 / 1000 correct (77.60)\n",
      "334 epoch,   500 iteration, loss:0.044\n",
      "Checking accuracy on test set\n",
      "Got 767 / 1000 correct (76.70)\n",
      "334 epoch,  1000 iteration, loss:0.038\n",
      " num 333 epoch \n",
      "####### Training Loss #######\n",
      "[0.04214514]\n",
      "Checking accuracy on test set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "335 epoch,   500 iteration, loss:0.049\n",
      "Checking accuracy on test set\n",
      "Got 778 / 1000 correct (77.80)\n",
      "335 epoch,  1000 iteration, loss:0.065\n",
      " num 334 epoch \n",
      "####### Training Loss #######\n",
      "[0.05461868]\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "336 epoch,   500 iteration, loss:0.056\n",
      "Checking accuracy on test set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "336 epoch,  1000 iteration, loss:0.037\n",
      " num 335 epoch \n",
      "####### Training Loss #######\n",
      "[0.04612668]\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "337 epoch,   500 iteration, loss:0.026\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "337 epoch,  1000 iteration, loss:0.077\n",
      " num 336 epoch \n",
      "####### Training Loss #######\n",
      "[0.05243729]\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "338 epoch,   500 iteration, loss:0.063\n",
      "Checking accuracy on test set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "338 epoch,  1000 iteration, loss:0.066\n",
      " num 337 epoch \n",
      "####### Training Loss #######\n",
      "[0.07897365]\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "339 epoch,   500 iteration, loss:0.076\n",
      "Checking accuracy on test set\n",
      "Got 770 / 1000 correct (77.00)\n",
      "339 epoch,  1000 iteration, loss:0.083\n",
      " num 338 epoch \n",
      "####### Training Loss #######\n",
      "[0.07236573]\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "340 epoch,   500 iteration, loss:0.051\n",
      "Checking accuracy on test set\n",
      "Got 770 / 1000 correct (77.00)\n",
      "340 epoch,  1000 iteration, loss:0.036\n",
      " num 339 epoch \n",
      "####### Training Loss #######\n",
      "[0.04229725]\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "341 epoch,   500 iteration, loss:0.050\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "341 epoch,  1000 iteration, loss:0.080\n",
      " num 340 epoch \n",
      "####### Training Loss #######\n",
      "[0.06526542]\n",
      "Checking accuracy on test set\n",
      "Got 771 / 1000 correct (77.10)\n",
      "342 epoch,   500 iteration, loss:0.047\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "342 epoch,  1000 iteration, loss:0.058\n",
      " num 341 epoch \n",
      "####### Training Loss #######\n",
      "[0.05005472]\n",
      "Checking accuracy on test set\n",
      "Got 766 / 1000 correct (76.60)\n",
      "343 epoch,   500 iteration, loss:0.045\n",
      "Checking accuracy on test set\n",
      "Got 773 / 1000 correct (77.30)\n",
      "343 epoch,  1000 iteration, loss:0.039\n",
      " num 342 epoch \n",
      "####### Training Loss #######\n",
      "[0.04121982]\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "344 epoch,   500 iteration, loss:0.068\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "344 epoch,  1000 iteration, loss:0.062\n",
      " num 343 epoch \n",
      "####### Training Loss #######\n",
      "[0.06570851]\n",
      "Checking accuracy on test set\n",
      "Got 753 / 1000 correct (75.30)\n",
      "345 epoch,   500 iteration, loss:0.082\n",
      "Checking accuracy on test set\n",
      "Got 754 / 1000 correct (75.40)\n",
      "345 epoch,  1000 iteration, loss:0.061\n",
      " num 344 epoch \n",
      "####### Training Loss #######\n",
      "[0.06416981]\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "346 epoch,   500 iteration, loss:0.045\n",
      "Checking accuracy on test set\n",
      "Got 762 / 1000 correct (76.20)\n",
      "346 epoch,  1000 iteration, loss:0.074\n",
      " num 345 epoch \n",
      "####### Training Loss #######\n",
      "[0.07703992]\n",
      "Checking accuracy on test set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "347 epoch,   500 iteration, loss:0.082\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "347 epoch,  1000 iteration, loss:0.072\n",
      " num 346 epoch \n",
      "####### Training Loss #######\n",
      "[0.06964064]\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "348 epoch,   500 iteration, loss:0.054\n",
      "Checking accuracy on test set\n",
      "Got 768 / 1000 correct (76.80)\n",
      "348 epoch,  1000 iteration, loss:0.069\n",
      " num 347 epoch \n",
      "####### Training Loss #######\n",
      "[0.06035325]\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "349 epoch,   500 iteration, loss:0.082\n",
      "Checking accuracy on test set\n",
      "Got 761 / 1000 correct (76.10)\n",
      "349 epoch,  1000 iteration, loss:0.064\n",
      " num 348 epoch \n",
      "####### Training Loss #######\n",
      "[0.07107925]\n",
      "Checking accuracy on test set\n",
      "Got 782 / 1000 correct (78.20)\n",
      "350 epoch,   500 iteration, loss:0.073\n",
      "Checking accuracy on test set\n",
      "Got 754 / 1000 correct (75.40)\n",
      "350 epoch,  1000 iteration, loss:0.086\n",
      " num 349 epoch \n",
      "####### Training Loss #######\n",
      "[0.07436955]\n",
      "finish training \n",
      "\n",
      "now begin saving datum for next step plotting\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cPickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0f79be1e7f12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m convpool_cnn_c = running_model_B(run_num, convpool_cnn_c, net_name, lr, epoch, \n\u001b[0;32m---> 13\u001b[0;31m                         loaderA_train, loaderA_test)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-2e2d8c757fc0>\u001b[0m in \u001b[0;36mrunning_model_B\u001b[0;34m(run_num, net, net_name, lr_list, epoch_list, loader_train, loader_test)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/train_loss.save'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0mcPickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcPickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cPickle' is not defined"
     ]
    }
   ],
   "source": [
    "lr = [0.01, 0.005, 0.001, 0.0005]\n",
    "epoch = [200, 250, 300] # first20\n",
    "\n",
    "run_num = 10\n",
    "\n",
    "\n",
    "#torch.cuda.set_device(3)\n",
    "#import os\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\" ## GPU number= 0, 1, or 2 \n",
    "net_name1 = 'ConvPool_CNN_C_Class1'\n",
    "convpool_cnn_c_class1 = running_model_B(run_num, convpool_cnn_c_class1, net_name1, lr, epoch, \n",
    "                        loaderA_train, loaderA_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "convpool_cnn_c_class2 = new_ALL_Conv.ConvPool_CNN_C()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n",
      "begin training\n",
      "Checking accuracy on test set\n",
      "Got 314 / 1000 correct (31.40)\n",
      "1 epoch,   500 iteration, loss:2.103\n",
      "Checking accuracy on test set\n",
      "Got 385 / 1000 correct (38.50)\n",
      "1 epoch,  1000 iteration, loss:1.851\n",
      " num 0 epoch \n",
      "####### Training Loss #######\n",
      "[1.92732715]\n",
      "Checking accuracy on test set\n",
      "Got 397 / 1000 correct (39.70)\n",
      "2 epoch,   500 iteration, loss:1.673\n",
      "Checking accuracy on test set\n",
      "Got 495 / 1000 correct (49.50)\n",
      "2 epoch,  1000 iteration, loss:1.579\n",
      " num 1 epoch \n",
      "####### Training Loss #######\n",
      "[1.59569475]\n",
      "Checking accuracy on test set\n",
      "Got 532 / 1000 correct (53.20)\n",
      "3 epoch,   500 iteration, loss:1.481\n",
      "Checking accuracy on test set\n",
      "Got 535 / 1000 correct (53.50)\n",
      "3 epoch,  1000 iteration, loss:1.401\n",
      " num 2 epoch \n",
      "####### Training Loss #######\n",
      "[1.41575386]\n",
      "Checking accuracy on test set\n",
      "Got 555 / 1000 correct (55.50)\n",
      "4 epoch,   500 iteration, loss:1.328\n",
      "Checking accuracy on test set\n",
      "Got 583 / 1000 correct (58.30)\n",
      "4 epoch,  1000 iteration, loss:1.303\n",
      " num 3 epoch \n",
      "####### Training Loss #######\n",
      "[1.29791369]\n",
      "Checking accuracy on test set\n",
      "Got 584 / 1000 correct (58.40)\n",
      "5 epoch,   500 iteration, loss:1.231\n",
      "Checking accuracy on test set\n",
      "Got 590 / 1000 correct (59.00)\n",
      "5 epoch,  1000 iteration, loss:1.217\n",
      " num 4 epoch \n",
      "####### Training Loss #######\n",
      "[1.20899411]\n",
      "Checking accuracy on test set\n",
      "Got 592 / 1000 correct (59.20)\n",
      "6 epoch,   500 iteration, loss:1.194\n",
      "Checking accuracy on test set\n",
      "Got 589 / 1000 correct (58.90)\n",
      "6 epoch,  1000 iteration, loss:1.128\n",
      " num 5 epoch \n",
      "####### Training Loss #######\n",
      "[1.15211897]\n",
      "Checking accuracy on test set\n",
      "Got 634 / 1000 correct (63.40)\n",
      "7 epoch,   500 iteration, loss:1.130\n",
      "Checking accuracy on test set\n",
      "Got 623 / 1000 correct (62.30)\n",
      "7 epoch,  1000 iteration, loss:1.099\n",
      " num 6 epoch \n",
      "####### Training Loss #######\n",
      "[1.10054233]\n",
      "Checking accuracy on test set\n",
      "Got 632 / 1000 correct (63.20)\n",
      "8 epoch,   500 iteration, loss:1.089\n",
      "Checking accuracy on test set\n",
      "Got 634 / 1000 correct (63.40)\n",
      "8 epoch,  1000 iteration, loss:1.034\n",
      " num 7 epoch \n",
      "####### Training Loss #######\n",
      "[1.04716793]\n",
      "Checking accuracy on test set\n",
      "Got 659 / 1000 correct (65.90)\n",
      "9 epoch,   500 iteration, loss:1.030\n",
      "Checking accuracy on test set\n",
      "Got 637 / 1000 correct (63.70)\n",
      "9 epoch,  1000 iteration, loss:0.999\n",
      " num 8 epoch \n",
      "####### Training Loss #######\n",
      "[0.99862846]\n",
      "Checking accuracy on test set\n",
      "Got 665 / 1000 correct (66.50)\n",
      "10 epoch,   500 iteration, loss:1.004\n",
      "Checking accuracy on test set\n",
      "Got 627 / 1000 correct (62.70)\n",
      "10 epoch,  1000 iteration, loss:0.941\n",
      " num 9 epoch \n",
      "####### Training Loss #######\n",
      "[0.9576982]\n",
      "Checking accuracy on test set\n",
      "Got 651 / 1000 correct (65.10)\n",
      "11 epoch,   500 iteration, loss:0.939\n",
      "Checking accuracy on test set\n",
      "Got 645 / 1000 correct (64.50)\n",
      "11 epoch,  1000 iteration, loss:0.908\n",
      " num 10 epoch \n",
      "####### Training Loss #######\n",
      "[0.91514368]\n",
      "Checking accuracy on test set\n",
      "Got 678 / 1000 correct (67.80)\n",
      "12 epoch,   500 iteration, loss:0.912\n",
      "Checking accuracy on test set\n",
      "Got 640 / 1000 correct (64.00)\n",
      "12 epoch,  1000 iteration, loss:0.848\n",
      " num 11 epoch \n",
      "####### Training Loss #######\n",
      "[0.87672758]\n",
      "Checking accuracy on test set\n",
      "Got 671 / 1000 correct (67.10)\n",
      "13 epoch,   500 iteration, loss:0.895\n",
      "Checking accuracy on test set\n",
      "Got 680 / 1000 correct (68.00)\n",
      "13 epoch,  1000 iteration, loss:0.843\n",
      " num 12 epoch \n",
      "####### Training Loss #######\n",
      "[0.85617049]\n",
      "Checking accuracy on test set\n",
      "Got 670 / 1000 correct (67.00)\n",
      "14 epoch,   500 iteration, loss:0.849\n",
      "Checking accuracy on test set\n",
      "Got 634 / 1000 correct (63.40)\n",
      "14 epoch,  1000 iteration, loss:0.780\n",
      " num 13 epoch \n",
      "####### Training Loss #######\n",
      "[0.8083347]\n",
      "Checking accuracy on test set\n",
      "Got 691 / 1000 correct (69.10)\n",
      "15 epoch,   500 iteration, loss:0.833\n",
      "Checking accuracy on test set\n",
      "Got 686 / 1000 correct (68.60)\n",
      "15 epoch,  1000 iteration, loss:0.758\n",
      " num 14 epoch \n",
      "####### Training Loss #######\n",
      "[0.79209919]\n",
      "Checking accuracy on test set\n",
      "Got 693 / 1000 correct (69.30)\n",
      "16 epoch,   500 iteration, loss:0.784\n",
      "Checking accuracy on test set\n",
      "Got 681 / 1000 correct (68.10)\n",
      "16 epoch,  1000 iteration, loss:0.747\n",
      " num 15 epoch \n",
      "####### Training Loss #######\n",
      "[0.75593358]\n",
      "Checking accuracy on test set\n",
      "Got 708 / 1000 correct (70.80)\n",
      "17 epoch,   500 iteration, loss:0.753\n",
      "Checking accuracy on test set\n",
      "Got 671 / 1000 correct (67.10)\n",
      "17 epoch,  1000 iteration, loss:0.738\n",
      " num 16 epoch \n",
      "####### Training Loss #######\n",
      "[0.73109276]\n",
      "Checking accuracy on test set\n",
      "Got 693 / 1000 correct (69.30)\n",
      "18 epoch,   500 iteration, loss:0.734\n",
      "Checking accuracy on test set\n",
      "Got 690 / 1000 correct (69.00)\n",
      "18 epoch,  1000 iteration, loss:0.701\n",
      " num 17 epoch \n",
      "####### Training Loss #######\n",
      "[0.70897231]\n",
      "Checking accuracy on test set\n",
      "Got 695 / 1000 correct (69.50)\n",
      "19 epoch,   500 iteration, loss:0.697\n",
      "Checking accuracy on test set\n",
      "Got 680 / 1000 correct (68.00)\n",
      "19 epoch,  1000 iteration, loss:0.644\n",
      " num 18 epoch \n",
      "####### Training Loss #######\n",
      "[0.66781241]\n",
      "Checking accuracy on test set\n",
      "Got 699 / 1000 correct (69.90)\n",
      "20 epoch,   500 iteration, loss:0.673\n",
      "Checking accuracy on test set\n",
      "Got 692 / 1000 correct (69.20)\n",
      "20 epoch,  1000 iteration, loss:0.642\n",
      " num 19 epoch \n",
      "####### Training Loss #######\n",
      "[0.65390248]\n",
      "Checking accuracy on test set\n",
      "Got 710 / 1000 correct (71.00)\n",
      "21 epoch,   500 iteration, loss:0.665\n",
      "Checking accuracy on test set\n",
      "Got 695 / 1000 correct (69.50)\n",
      "21 epoch,  1000 iteration, loss:0.603\n",
      " num 20 epoch \n",
      "####### Training Loss #######\n",
      "[0.62465276]\n",
      "Checking accuracy on test set\n",
      "Got 690 / 1000 correct (69.00)\n",
      "22 epoch,   500 iteration, loss:0.625\n",
      "Checking accuracy on test set\n",
      "Got 686 / 1000 correct (68.60)\n",
      "22 epoch,  1000 iteration, loss:0.600\n",
      " num 21 epoch \n",
      "####### Training Loss #######\n",
      "[0.60782918]\n",
      "Checking accuracy on test set\n",
      "Got 680 / 1000 correct (68.00)\n",
      "23 epoch,   500 iteration, loss:0.609\n",
      "Checking accuracy on test set\n",
      "Got 693 / 1000 correct (69.30)\n",
      "23 epoch,  1000 iteration, loss:0.569\n",
      " num 22 epoch \n",
      "####### Training Loss #######\n",
      "[0.58655379]\n",
      "Checking accuracy on test set\n",
      "Got 705 / 1000 correct (70.50)\n",
      "24 epoch,   500 iteration, loss:0.582\n",
      "Checking accuracy on test set\n",
      "Got 703 / 1000 correct (70.30)\n",
      "24 epoch,  1000 iteration, loss:0.568\n",
      " num 23 epoch \n",
      "####### Training Loss #######\n",
      "[0.56940891]\n",
      "Checking accuracy on test set\n",
      "Got 721 / 1000 correct (72.10)\n",
      "25 epoch,   500 iteration, loss:0.556\n",
      "Checking accuracy on test set\n",
      "Got 700 / 1000 correct (70.00)\n",
      "25 epoch,  1000 iteration, loss:0.537\n",
      " num 24 epoch \n",
      "####### Training Loss #######\n",
      "[0.5423982]\n",
      "Checking accuracy on test set\n",
      "Got 709 / 1000 correct (70.90)\n",
      "26 epoch,   500 iteration, loss:0.540\n",
      "Checking accuracy on test set\n",
      "Got 732 / 1000 correct (73.20)\n",
      "26 epoch,  1000 iteration, loss:0.510\n",
      " num 25 epoch \n",
      "####### Training Loss #######\n",
      "[0.51439735]\n",
      "Checking accuracy on test set\n",
      "Got 714 / 1000 correct (71.40)\n",
      "27 epoch,   500 iteration, loss:0.511\n",
      "Checking accuracy on test set\n",
      "Got 692 / 1000 correct (69.20)\n",
      "27 epoch,  1000 iteration, loss:0.497\n",
      " num 26 epoch \n",
      "####### Training Loss #######\n",
      "[0.50066725]\n",
      "Checking accuracy on test set\n",
      "Got 694 / 1000 correct (69.40)\n",
      "28 epoch,   500 iteration, loss:0.490\n",
      "Checking accuracy on test set\n",
      "Got 720 / 1000 correct (72.00)\n",
      "28 epoch,  1000 iteration, loss:0.486\n",
      " num 27 epoch \n",
      "####### Training Loss #######\n",
      "[0.48514918]\n",
      "Checking accuracy on test set\n",
      "Got 701 / 1000 correct (70.10)\n",
      "29 epoch,   500 iteration, loss:0.491\n",
      "Checking accuracy on test set\n",
      "Got 714 / 1000 correct (71.40)\n",
      "29 epoch,  1000 iteration, loss:0.446\n",
      " num 28 epoch \n",
      "####### Training Loss #######\n",
      "[0.46602547]\n",
      "Checking accuracy on test set\n",
      "Got 717 / 1000 correct (71.70)\n",
      "30 epoch,   500 iteration, loss:0.442\n",
      "Checking accuracy on test set\n",
      "Got 701 / 1000 correct (70.10)\n",
      "30 epoch,  1000 iteration, loss:0.447\n",
      " num 29 epoch \n",
      "####### Training Loss #######\n",
      "[0.44496919]\n",
      "Checking accuracy on test set\n",
      "Got 701 / 1000 correct (70.10)\n",
      "31 epoch,   500 iteration, loss:0.439\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "31 epoch,  1000 iteration, loss:0.424\n",
      " num 30 epoch \n",
      "####### Training Loss #######\n",
      "[0.4303504]\n",
      "Checking accuracy on test set\n",
      "Got 697 / 1000 correct (69.70)\n",
      "32 epoch,   500 iteration, loss:0.450\n",
      "Checking accuracy on test set\n",
      "Got 725 / 1000 correct (72.50)\n",
      "32 epoch,  1000 iteration, loss:0.406\n",
      " num 31 epoch \n",
      "####### Training Loss #######\n",
      "[0.43209546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on test set\n",
      "Got 703 / 1000 correct (70.30)\n",
      "33 epoch,   500 iteration, loss:0.398\n",
      "Checking accuracy on test set\n",
      "Got 699 / 1000 correct (69.90)\n",
      "33 epoch,  1000 iteration, loss:0.406\n",
      " num 32 epoch \n",
      "####### Training Loss #######\n",
      "[0.39166199]\n",
      "Checking accuracy on test set\n",
      "Got 714 / 1000 correct (71.40)\n",
      "34 epoch,   500 iteration, loss:0.389\n",
      "Checking accuracy on test set\n",
      "Got 724 / 1000 correct (72.40)\n",
      "34 epoch,  1000 iteration, loss:0.371\n",
      " num 33 epoch \n",
      "####### Training Loss #######\n",
      "[0.37838244]\n",
      "Checking accuracy on test set\n",
      "Got 722 / 1000 correct (72.20)\n",
      "35 epoch,   500 iteration, loss:0.390\n",
      "Checking accuracy on test set\n",
      "Got 711 / 1000 correct (71.10)\n",
      "35 epoch,  1000 iteration, loss:0.358\n",
      " num 34 epoch \n",
      "####### Training Loss #######\n",
      "[0.36380899]\n",
      "Checking accuracy on test set\n",
      "Got 722 / 1000 correct (72.20)\n",
      "36 epoch,   500 iteration, loss:0.371\n",
      "Checking accuracy on test set\n",
      "Got 728 / 1000 correct (72.80)\n",
      "36 epoch,  1000 iteration, loss:0.359\n",
      " num 35 epoch \n",
      "####### Training Loss #######\n",
      "[0.36745459]\n",
      "Checking accuracy on test set\n",
      "Got 732 / 1000 correct (73.20)\n",
      "37 epoch,   500 iteration, loss:0.353\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "37 epoch,  1000 iteration, loss:0.354\n",
      " num 36 epoch \n",
      "####### Training Loss #######\n",
      "[0.34093817]\n",
      "Checking accuracy on test set\n",
      "Got 702 / 1000 correct (70.20)\n",
      "38 epoch,   500 iteration, loss:0.343\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "38 epoch,  1000 iteration, loss:0.355\n",
      " num 37 epoch \n",
      "####### Training Loss #######\n",
      "[0.34492166]\n",
      "Checking accuracy on test set\n",
      "Got 705 / 1000 correct (70.50)\n",
      "39 epoch,   500 iteration, loss:0.330\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "39 epoch,  1000 iteration, loss:0.348\n",
      " num 38 epoch \n",
      "####### Training Loss #######\n",
      "[0.34200454]\n",
      "Checking accuracy on test set\n",
      "Got 724 / 1000 correct (72.40)\n",
      "40 epoch,   500 iteration, loss:0.322\n",
      "Checking accuracy on test set\n",
      "Got 729 / 1000 correct (72.90)\n",
      "40 epoch,  1000 iteration, loss:0.311\n",
      " num 39 epoch \n",
      "####### Training Loss #######\n",
      "[0.31344251]\n",
      "Checking accuracy on test set\n",
      "Got 719 / 1000 correct (71.90)\n",
      "41 epoch,   500 iteration, loss:0.337\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "41 epoch,  1000 iteration, loss:0.312\n",
      " num 40 epoch \n",
      "####### Training Loss #######\n",
      "[0.32418877]\n",
      "Checking accuracy on test set\n",
      "Got 720 / 1000 correct (72.00)\n",
      "42 epoch,   500 iteration, loss:0.283\n",
      "Checking accuracy on test set\n",
      "Got 706 / 1000 correct (70.60)\n",
      "42 epoch,  1000 iteration, loss:0.294\n",
      " num 41 epoch \n",
      "####### Training Loss #######\n",
      "[0.28771395]\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "43 epoch,   500 iteration, loss:0.307\n",
      "Checking accuracy on test set\n",
      "Got 720 / 1000 correct (72.00)\n",
      "43 epoch,  1000 iteration, loss:0.261\n",
      " num 42 epoch \n",
      "####### Training Loss #######\n",
      "[0.28146843]\n",
      "Checking accuracy on test set\n",
      "Got 717 / 1000 correct (71.70)\n",
      "44 epoch,   500 iteration, loss:0.317\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "44 epoch,  1000 iteration, loss:0.281\n",
      " num 43 epoch \n",
      "####### Training Loss #######\n",
      "[0.30156602]\n",
      "Checking accuracy on test set\n",
      "Got 707 / 1000 correct (70.70)\n",
      "45 epoch,   500 iteration, loss:0.276\n",
      "Checking accuracy on test set\n",
      "Got 713 / 1000 correct (71.30)\n",
      "45 epoch,  1000 iteration, loss:0.267\n",
      " num 44 epoch \n",
      "####### Training Loss #######\n",
      "[0.26883776]\n",
      "Checking accuracy on test set\n",
      "Got 724 / 1000 correct (72.40)\n",
      "46 epoch,   500 iteration, loss:0.256\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "46 epoch,  1000 iteration, loss:0.251\n",
      " num 45 epoch \n",
      "####### Training Loss #######\n",
      "[0.25106847]\n",
      "Checking accuracy on test set\n",
      "Got 708 / 1000 correct (70.80)\n",
      "47 epoch,   500 iteration, loss:0.263\n",
      "Checking accuracy on test set\n",
      "Got 726 / 1000 correct (72.60)\n",
      "47 epoch,  1000 iteration, loss:0.291\n",
      " num 46 epoch \n",
      "####### Training Loss #######\n",
      "[0.27233085]\n",
      "Checking accuracy on test set\n",
      "Got 725 / 1000 correct (72.50)\n",
      "48 epoch,   500 iteration, loss:0.280\n",
      "Checking accuracy on test set\n",
      "Got 753 / 1000 correct (75.30)\n",
      "48 epoch,  1000 iteration, loss:0.240\n",
      " num 47 epoch \n",
      "####### Training Loss #######\n",
      "[0.25380615]\n",
      "Checking accuracy on test set\n",
      "Got 716 / 1000 correct (71.60)\n",
      "49 epoch,   500 iteration, loss:0.236\n",
      "Checking accuracy on test set\n",
      "Got 732 / 1000 correct (73.20)\n",
      "49 epoch,  1000 iteration, loss:0.219\n",
      " num 48 epoch \n",
      "####### Training Loss #######\n",
      "[0.22887911]\n",
      "Checking accuracy on test set\n",
      "Got 712 / 1000 correct (71.20)\n",
      "50 epoch,   500 iteration, loss:0.243\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "50 epoch,  1000 iteration, loss:0.226\n",
      " num 49 epoch \n",
      "####### Training Loss #######\n",
      "[0.23446917]\n",
      "Checking accuracy on test set\n",
      "Got 700 / 1000 correct (70.00)\n",
      "51 epoch,   500 iteration, loss:0.241\n",
      "Checking accuracy on test set\n",
      "Got 708 / 1000 correct (70.80)\n",
      "51 epoch,  1000 iteration, loss:0.217\n",
      " num 50 epoch \n",
      "####### Training Loss #######\n",
      "[0.22535505]\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "52 epoch,   500 iteration, loss:0.210\n",
      "Checking accuracy on test set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "52 epoch,  1000 iteration, loss:0.233\n",
      " num 51 epoch \n",
      "####### Training Loss #######\n",
      "[0.22284908]\n",
      "Checking accuracy on test set\n",
      "Got 716 / 1000 correct (71.60)\n",
      "53 epoch,   500 iteration, loss:0.229\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "53 epoch,  1000 iteration, loss:0.194\n",
      " num 52 epoch \n",
      "####### Training Loss #######\n",
      "[0.20113896]\n",
      "Checking accuracy on test set\n",
      "Got 705 / 1000 correct (70.50)\n",
      "54 epoch,   500 iteration, loss:0.221\n",
      "Checking accuracy on test set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "54 epoch,  1000 iteration, loss:0.188\n",
      " num 53 epoch \n",
      "####### Training Loss #######\n",
      "[0.20009425]\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "55 epoch,   500 iteration, loss:0.210\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "55 epoch,  1000 iteration, loss:0.215\n",
      " num 54 epoch \n",
      "####### Training Loss #######\n",
      "[0.20617011]\n",
      "Checking accuracy on test set\n",
      "Got 706 / 1000 correct (70.60)\n",
      "56 epoch,   500 iteration, loss:0.185\n",
      "Checking accuracy on test set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "56 epoch,  1000 iteration, loss:0.143\n",
      " num 55 epoch \n",
      "####### Training Loss #######\n",
      "[0.16737128]\n",
      "Checking accuracy on test set\n",
      "Got 713 / 1000 correct (71.30)\n",
      "57 epoch,   500 iteration, loss:0.201\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "57 epoch,  1000 iteration, loss:0.171\n",
      " num 56 epoch \n",
      "####### Training Loss #######\n",
      "[0.18673211]\n",
      "Checking accuracy on test set\n",
      "Got 716 / 1000 correct (71.60)\n",
      "58 epoch,   500 iteration, loss:0.193\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "58 epoch,  1000 iteration, loss:0.194\n",
      " num 57 epoch \n",
      "####### Training Loss #######\n",
      "[0.19252173]\n",
      "Checking accuracy on test set\n",
      "Got 724 / 1000 correct (72.40)\n",
      "59 epoch,   500 iteration, loss:0.211\n",
      "Checking accuracy on test set\n",
      "Got 729 / 1000 correct (72.90)\n",
      "59 epoch,  1000 iteration, loss:0.147\n",
      " num 58 epoch \n",
      "####### Training Loss #######\n",
      "[0.18195316]\n",
      "Checking accuracy on test set\n",
      "Got 713 / 1000 correct (71.30)\n",
      "60 epoch,   500 iteration, loss:0.191\n",
      "Checking accuracy on test set\n",
      "Got 719 / 1000 correct (71.90)\n",
      "60 epoch,  1000 iteration, loss:0.181\n",
      " num 59 epoch \n",
      "####### Training Loss #######\n",
      "[0.18120765]\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "61 epoch,   500 iteration, loss:0.167\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "61 epoch,  1000 iteration, loss:0.182\n",
      " num 60 epoch \n",
      "####### Training Loss #######\n",
      "[0.17449692]\n",
      "Checking accuracy on test set\n",
      "Got 704 / 1000 correct (70.40)\n",
      "62 epoch,   500 iteration, loss:0.190\n",
      "Checking accuracy on test set\n",
      "Got 711 / 1000 correct (71.10)\n",
      "62 epoch,  1000 iteration, loss:0.174\n",
      " num 61 epoch \n",
      "####### Training Loss #######\n",
      "[0.17935618]\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "63 epoch,   500 iteration, loss:0.149\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "63 epoch,  1000 iteration, loss:0.146\n",
      " num 62 epoch \n",
      "####### Training Loss #######\n",
      "[0.15852538]\n",
      "Checking accuracy on test set\n",
      "Got 711 / 1000 correct (71.10)\n",
      "64 epoch,   500 iteration, loss:0.190\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "64 epoch,  1000 iteration, loss:0.151\n",
      " num 63 epoch \n",
      "####### Training Loss #######\n",
      "[0.17358265]\n",
      "Checking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 718 / 1000 correct (71.80)\n",
      "65 epoch,   500 iteration, loss:0.152\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "65 epoch,  1000 iteration, loss:0.157\n",
      " num 64 epoch \n",
      "####### Training Loss #######\n",
      "[0.16708147]\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "66 epoch,   500 iteration, loss:0.137\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "66 epoch,  1000 iteration, loss:0.139\n",
      " num 65 epoch \n",
      "####### Training Loss #######\n",
      "[0.14168075]\n",
      "Checking accuracy on test set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "67 epoch,   500 iteration, loss:0.130\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "67 epoch,  1000 iteration, loss:0.151\n",
      " num 66 epoch \n",
      "####### Training Loss #######\n",
      "[0.15271061]\n",
      "Checking accuracy on test set\n",
      "Got 703 / 1000 correct (70.30)\n",
      "68 epoch,   500 iteration, loss:0.153\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "68 epoch,  1000 iteration, loss:0.153\n",
      " num 67 epoch \n",
      "####### Training Loss #######\n",
      "[0.16211497]\n",
      "Checking accuracy on test set\n",
      "Got 722 / 1000 correct (72.20)\n",
      "69 epoch,   500 iteration, loss:0.193\n",
      "Checking accuracy on test set\n",
      "Got 726 / 1000 correct (72.60)\n",
      "69 epoch,  1000 iteration, loss:0.146\n",
      " num 68 epoch \n",
      "####### Training Loss #######\n",
      "[0.15857881]\n",
      "Checking accuracy on test set\n",
      "Got 706 / 1000 correct (70.60)\n",
      "70 epoch,   500 iteration, loss:0.137\n",
      "Checking accuracy on test set\n",
      "Got 725 / 1000 correct (72.50)\n",
      "70 epoch,  1000 iteration, loss:0.128\n",
      " num 69 epoch \n",
      "####### Training Loss #######\n",
      "[0.12844731]\n",
      "Checking accuracy on test set\n",
      "Got 697 / 1000 correct (69.70)\n",
      "71 epoch,   500 iteration, loss:0.165\n",
      "Checking accuracy on test set\n",
      "Got 684 / 1000 correct (68.40)\n",
      "71 epoch,  1000 iteration, loss:0.165\n",
      " num 70 epoch \n",
      "####### Training Loss #######\n",
      "[0.16394841]\n",
      "Checking accuracy on test set\n",
      "Got 726 / 1000 correct (72.60)\n",
      "72 epoch,   500 iteration, loss:0.100\n",
      "Checking accuracy on test set\n",
      "Got 724 / 1000 correct (72.40)\n",
      "72 epoch,  1000 iteration, loss:0.169\n",
      " num 71 epoch \n",
      "####### Training Loss #######\n",
      "[0.13641464]\n",
      "Checking accuracy on test set\n",
      "Got 714 / 1000 correct (71.40)\n",
      "73 epoch,   500 iteration, loss:0.126\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "73 epoch,  1000 iteration, loss:0.126\n",
      " num 72 epoch \n",
      "####### Training Loss #######\n",
      "[0.13047222]\n",
      "Checking accuracy on test set\n",
      "Got 683 / 1000 correct (68.30)\n",
      "74 epoch,   500 iteration, loss:0.129\n",
      "Checking accuracy on test set\n",
      "Got 714 / 1000 correct (71.40)\n",
      "74 epoch,  1000 iteration, loss:0.140\n",
      " num 73 epoch \n",
      "####### Training Loss #######\n",
      "[0.13473408]\n",
      "Checking accuracy on test set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "75 epoch,   500 iteration, loss:0.146\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "75 epoch,  1000 iteration, loss:0.123\n",
      " num 74 epoch \n",
      "####### Training Loss #######\n",
      "[0.13205507]\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "76 epoch,   500 iteration, loss:0.141\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "76 epoch,  1000 iteration, loss:0.139\n",
      " num 75 epoch \n",
      "####### Training Loss #######\n",
      "[0.14065653]\n",
      "Checking accuracy on test set\n",
      "Got 716 / 1000 correct (71.60)\n",
      "77 epoch,   500 iteration, loss:0.115\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "77 epoch,  1000 iteration, loss:0.128\n",
      " num 76 epoch \n",
      "####### Training Loss #######\n",
      "[0.12667212]\n",
      "Checking accuracy on test set\n",
      "Got 705 / 1000 correct (70.50)\n",
      "78 epoch,   500 iteration, loss:0.125\n",
      "Checking accuracy on test set\n",
      "Got 713 / 1000 correct (71.30)\n",
      "78 epoch,  1000 iteration, loss:0.123\n",
      " num 77 epoch \n",
      "####### Training Loss #######\n",
      "[0.13056998]\n",
      "Checking accuracy on test set\n",
      "Got 728 / 1000 correct (72.80)\n",
      "79 epoch,   500 iteration, loss:0.115\n",
      "Checking accuracy on test set\n",
      "Got 729 / 1000 correct (72.90)\n",
      "79 epoch,  1000 iteration, loss:0.127\n",
      " num 78 epoch \n",
      "####### Training Loss #######\n",
      "[0.12625336]\n",
      "Checking accuracy on test set\n",
      "Got 706 / 1000 correct (70.60)\n",
      "80 epoch,   500 iteration, loss:0.118\n",
      "Checking accuracy on test set\n",
      "Got 721 / 1000 correct (72.10)\n",
      "80 epoch,  1000 iteration, loss:0.122\n",
      " num 79 epoch \n",
      "####### Training Loss #######\n",
      "[0.12512817]\n",
      "Checking accuracy on test set\n",
      "Got 714 / 1000 correct (71.40)\n",
      "81 epoch,   500 iteration, loss:0.128\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "81 epoch,  1000 iteration, loss:0.127\n",
      " num 80 epoch \n",
      "####### Training Loss #######\n",
      "[0.12527788]\n",
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "82 epoch,   500 iteration, loss:0.109\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "82 epoch,  1000 iteration, loss:0.087\n",
      " num 81 epoch \n",
      "####### Training Loss #######\n",
      "[0.09965387]\n",
      "Checking accuracy on test set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "83 epoch,   500 iteration, loss:0.073\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "83 epoch,  1000 iteration, loss:0.158\n",
      " num 82 epoch \n",
      "####### Training Loss #######\n",
      "[0.1061342]\n",
      "Checking accuracy on test set\n",
      "Got 709 / 1000 correct (70.90)\n",
      "84 epoch,   500 iteration, loss:0.098\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "84 epoch,  1000 iteration, loss:0.109\n",
      " num 83 epoch \n",
      "####### Training Loss #######\n",
      "[0.11848368]\n",
      "Checking accuracy on test set\n",
      "Got 720 / 1000 correct (72.00)\n",
      "85 epoch,   500 iteration, loss:0.148\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "85 epoch,  1000 iteration, loss:0.110\n",
      " num 84 epoch \n",
      "####### Training Loss #######\n",
      "[0.1268119]\n",
      "Checking accuracy on test set\n",
      "Got 725 / 1000 correct (72.50)\n",
      "86 epoch,   500 iteration, loss:0.103\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "86 epoch,  1000 iteration, loss:0.122\n",
      " num 85 epoch \n",
      "####### Training Loss #######\n",
      "[0.11816126]\n",
      "Checking accuracy on test set\n",
      "Got 703 / 1000 correct (70.30)\n",
      "87 epoch,   500 iteration, loss:0.090\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "87 epoch,  1000 iteration, loss:0.106\n",
      " num 86 epoch \n",
      "####### Training Loss #######\n",
      "[0.10257501]\n",
      "Checking accuracy on test set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "88 epoch,   500 iteration, loss:0.106\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "88 epoch,  1000 iteration, loss:0.110\n",
      " num 87 epoch \n",
      "####### Training Loss #######\n",
      "[0.1143558]\n",
      "Checking accuracy on test set\n",
      "Got 700 / 1000 correct (70.00)\n",
      "89 epoch,   500 iteration, loss:0.112\n",
      "Checking accuracy on test set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "89 epoch,  1000 iteration, loss:0.116\n",
      " num 88 epoch \n",
      "####### Training Loss #######\n",
      "[0.12329948]\n",
      "Checking accuracy on test set\n",
      "Got 726 / 1000 correct (72.60)\n",
      "90 epoch,   500 iteration, loss:0.106\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "90 epoch,  1000 iteration, loss:0.092\n",
      " num 89 epoch \n",
      "####### Training Loss #######\n",
      "[0.10022826]\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "91 epoch,   500 iteration, loss:0.145\n",
      "Checking accuracy on test set\n",
      "Got 709 / 1000 correct (70.90)\n",
      "91 epoch,  1000 iteration, loss:0.086\n",
      " num 90 epoch \n",
      "####### Training Loss #######\n",
      "[0.11249015]\n",
      "Checking accuracy on test set\n",
      "Got 728 / 1000 correct (72.80)\n",
      "92 epoch,   500 iteration, loss:0.128\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "92 epoch,  1000 iteration, loss:0.119\n",
      " num 91 epoch \n",
      "####### Training Loss #######\n",
      "[0.12286577]\n",
      "Checking accuracy on test set\n",
      "Got 711 / 1000 correct (71.10)\n",
      "93 epoch,   500 iteration, loss:0.095\n",
      "Checking accuracy on test set\n",
      "Got 720 / 1000 correct (72.00)\n",
      "93 epoch,  1000 iteration, loss:0.085\n",
      " num 92 epoch \n",
      "####### Training Loss #######\n",
      "[0.09909896]\n",
      "Checking accuracy on test set\n",
      "Got 675 / 1000 correct (67.50)\n",
      "94 epoch,   500 iteration, loss:0.122\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "94 epoch,  1000 iteration, loss:0.100\n",
      " num 93 epoch \n",
      "####### Training Loss #######\n",
      "[0.10105622]\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "95 epoch,   500 iteration, loss:0.121\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "95 epoch,  1000 iteration, loss:0.118\n",
      " num 94 epoch \n",
      "####### Training Loss #######\n",
      "[0.10998159]\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "96 epoch,   500 iteration, loss:0.118\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "96 epoch,  1000 iteration, loss:0.099\n",
      " num 95 epoch \n",
      "####### Training Loss #######\n",
      "[0.10998035]\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "97 epoch,   500 iteration, loss:0.085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "97 epoch,  1000 iteration, loss:0.116\n",
      " num 96 epoch \n",
      "####### Training Loss #######\n",
      "[0.1049616]\n",
      "Checking accuracy on test set\n",
      "Got 710 / 1000 correct (71.00)\n",
      "98 epoch,   500 iteration, loss:0.093\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "98 epoch,  1000 iteration, loss:0.085\n",
      " num 97 epoch \n",
      "####### Training Loss #######\n",
      "[0.09674953]\n",
      "Checking accuracy on test set\n",
      "Got 725 / 1000 correct (72.50)\n",
      "99 epoch,   500 iteration, loss:0.119\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "99 epoch,  1000 iteration, loss:0.116\n",
      " num 98 epoch \n",
      "####### Training Loss #######\n",
      "[0.11503342]\n",
      "Checking accuracy on test set\n",
      "Got 728 / 1000 correct (72.80)\n",
      "100 epoch,   500 iteration, loss:0.132\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "100 epoch,  1000 iteration, loss:0.079\n",
      " num 99 epoch \n",
      "####### Training Loss #######\n",
      "[0.10011977]\n",
      "Checking accuracy on test set\n",
      "Got 725 / 1000 correct (72.50)\n",
      "101 epoch,   500 iteration, loss:0.097\n",
      "Checking accuracy on test set\n",
      "Got 753 / 1000 correct (75.30)\n",
      "101 epoch,  1000 iteration, loss:0.067\n",
      " num 100 epoch \n",
      "####### Training Loss #######\n",
      "[0.08352164]\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "102 epoch,   500 iteration, loss:0.113\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "102 epoch,  1000 iteration, loss:0.091\n",
      " num 101 epoch \n",
      "####### Training Loss #######\n",
      "[0.10642932]\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "103 epoch,   500 iteration, loss:0.073\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "103 epoch,  1000 iteration, loss:0.112\n",
      " num 102 epoch \n",
      "####### Training Loss #######\n",
      "[0.09045832]\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "104 epoch,   500 iteration, loss:0.117\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "104 epoch,  1000 iteration, loss:0.104\n",
      " num 103 epoch \n",
      "####### Training Loss #######\n",
      "[0.10683116]\n",
      "Checking accuracy on test set\n",
      "Got 718 / 1000 correct (71.80)\n",
      "105 epoch,   500 iteration, loss:0.085\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "105 epoch,  1000 iteration, loss:0.101\n",
      " num 104 epoch \n",
      "####### Training Loss #######\n",
      "[0.09852142]\n",
      "Checking accuracy on test set\n",
      "Got 708 / 1000 correct (70.80)\n",
      "106 epoch,   500 iteration, loss:0.070\n",
      "Checking accuracy on test set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "106 epoch,  1000 iteration, loss:0.108\n",
      " num 105 epoch \n",
      "####### Training Loss #######\n",
      "[0.08743398]\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "107 epoch,   500 iteration, loss:0.074\n",
      "Checking accuracy on test set\n",
      "Got 753 / 1000 correct (75.30)\n",
      "107 epoch,  1000 iteration, loss:0.088\n",
      " num 106 epoch \n",
      "####### Training Loss #######\n",
      "[0.07776241]\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "108 epoch,   500 iteration, loss:0.076\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "108 epoch,  1000 iteration, loss:0.093\n",
      " num 107 epoch \n",
      "####### Training Loss #######\n",
      "[0.08255062]\n",
      "Checking accuracy on test set\n",
      "Got 718 / 1000 correct (71.80)\n",
      "109 epoch,   500 iteration, loss:0.103\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "109 epoch,  1000 iteration, loss:0.081\n",
      " num 108 epoch \n",
      "####### Training Loss #######\n",
      "[0.08694255]\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "110 epoch,   500 iteration, loss:0.100\n",
      "Checking accuracy on test set\n",
      "Got 729 / 1000 correct (72.90)\n",
      "110 epoch,  1000 iteration, loss:0.092\n",
      " num 109 epoch \n",
      "####### Training Loss #######\n",
      "[0.10156068]\n",
      "Checking accuracy on test set\n",
      "Got 711 / 1000 correct (71.10)\n",
      "111 epoch,   500 iteration, loss:0.099\n",
      "Checking accuracy on test set\n",
      "Got 732 / 1000 correct (73.20)\n",
      "111 epoch,  1000 iteration, loss:0.099\n",
      " num 110 epoch \n",
      "####### Training Loss #######\n",
      "[0.09852999]\n",
      "Checking accuracy on test set\n",
      "Got 707 / 1000 correct (70.70)\n",
      "112 epoch,   500 iteration, loss:0.114\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "112 epoch,  1000 iteration, loss:0.085\n",
      " num 111 epoch \n",
      "####### Training Loss #######\n",
      "[0.09684712]\n",
      "Checking accuracy on test set\n",
      "Got 729 / 1000 correct (72.90)\n",
      "113 epoch,   500 iteration, loss:0.093\n",
      "Checking accuracy on test set\n",
      "Got 728 / 1000 correct (72.80)\n",
      "113 epoch,  1000 iteration, loss:0.076\n",
      " num 112 epoch \n",
      "####### Training Loss #######\n",
      "[0.09218854]\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "114 epoch,   500 iteration, loss:0.095\n",
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "114 epoch,  1000 iteration, loss:0.090\n",
      " num 113 epoch \n",
      "####### Training Loss #######\n",
      "[0.09310603]\n",
      "Checking accuracy on test set\n",
      "Got 716 / 1000 correct (71.60)\n",
      "115 epoch,   500 iteration, loss:0.073\n",
      "Checking accuracy on test set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "115 epoch,  1000 iteration, loss:0.099\n",
      " num 114 epoch \n",
      "####### Training Loss #######\n",
      "[0.08624238]\n",
      "Checking accuracy on test set\n",
      "Got 753 / 1000 correct (75.30)\n",
      "116 epoch,   500 iteration, loss:0.088\n",
      "Checking accuracy on test set\n",
      "Got 728 / 1000 correct (72.80)\n",
      "116 epoch,  1000 iteration, loss:0.089\n",
      " num 115 epoch \n",
      "####### Training Loss #######\n",
      "[0.0921491]\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "117 epoch,   500 iteration, loss:0.100\n",
      "Checking accuracy on test set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "117 epoch,  1000 iteration, loss:0.103\n",
      " num 116 epoch \n",
      "####### Training Loss #######\n",
      "[0.09371346]\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "118 epoch,   500 iteration, loss:0.088\n",
      "Checking accuracy on test set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "118 epoch,  1000 iteration, loss:0.094\n",
      " num 117 epoch \n",
      "####### Training Loss #######\n",
      "[0.0941314]\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "119 epoch,   500 iteration, loss:0.082\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "119 epoch,  1000 iteration, loss:0.057\n",
      " num 118 epoch \n",
      "####### Training Loss #######\n",
      "[0.07209944]\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "120 epoch,   500 iteration, loss:0.090\n",
      "Checking accuracy on test set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "120 epoch,  1000 iteration, loss:0.095\n",
      " num 119 epoch \n",
      "####### Training Loss #######\n",
      "[0.08926521]\n",
      "Checking accuracy on test set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "121 epoch,   500 iteration, loss:0.072\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "121 epoch,  1000 iteration, loss:0.120\n",
      " num 120 epoch \n",
      "####### Training Loss #######\n",
      "[0.08838313]\n",
      "Checking accuracy on test set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "122 epoch,   500 iteration, loss:0.099\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "122 epoch,  1000 iteration, loss:0.077\n",
      " num 121 epoch \n",
      "####### Training Loss #######\n",
      "[0.08349182]\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "123 epoch,   500 iteration, loss:0.065\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "123 epoch,  1000 iteration, loss:0.098\n",
      " num 122 epoch \n",
      "####### Training Loss #######\n",
      "[0.08855584]\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "124 epoch,   500 iteration, loss:0.081\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "124 epoch,  1000 iteration, loss:0.052\n",
      " num 123 epoch \n",
      "####### Training Loss #######\n",
      "[0.06721215]\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "125 epoch,   500 iteration, loss:0.085\n",
      "Checking accuracy on test set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "125 epoch,  1000 iteration, loss:0.095\n",
      " num 124 epoch \n",
      "####### Training Loss #######\n",
      "[0.08434125]\n",
      "Checking accuracy on test set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "126 epoch,   500 iteration, loss:0.102\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "126 epoch,  1000 iteration, loss:0.089\n",
      " num 125 epoch \n",
      "####### Training Loss #######\n",
      "[0.10447516]\n",
      "Checking accuracy on test set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "127 epoch,   500 iteration, loss:0.106\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "127 epoch,  1000 iteration, loss:0.078\n",
      " num 126 epoch \n",
      "####### Training Loss #######\n",
      "[0.09534022]\n",
      "Checking accuracy on test set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "128 epoch,   500 iteration, loss:0.082\n",
      "Checking accuracy on test set\n",
      "Got 720 / 1000 correct (72.00)\n",
      "128 epoch,  1000 iteration, loss:0.095\n",
      " num 127 epoch \n",
      "####### Training Loss #######\n",
      "[0.08983198]\n",
      "Checking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 745 / 1000 correct (74.50)\n",
      "129 epoch,   500 iteration, loss:0.090\n",
      "Checking accuracy on test set\n",
      "Got 721 / 1000 correct (72.10)\n",
      "129 epoch,  1000 iteration, loss:0.072\n",
      " num 128 epoch \n",
      "####### Training Loss #######\n",
      "[0.09556474]\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "130 epoch,   500 iteration, loss:0.068\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "130 epoch,  1000 iteration, loss:0.070\n",
      " num 129 epoch \n",
      "####### Training Loss #######\n",
      "[0.07683299]\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "131 epoch,   500 iteration, loss:0.070\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "131 epoch,  1000 iteration, loss:0.076\n",
      " num 130 epoch \n",
      "####### Training Loss #######\n",
      "[0.07436359]\n",
      "Checking accuracy on test set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "132 epoch,   500 iteration, loss:0.071\n",
      "Checking accuracy on test set\n",
      "Got 711 / 1000 correct (71.10)\n",
      "132 epoch,  1000 iteration, loss:0.071\n",
      " num 131 epoch \n",
      "####### Training Loss #######\n",
      "[0.08044435]\n",
      "Checking accuracy on test set\n",
      "Got 710 / 1000 correct (71.00)\n",
      "133 epoch,   500 iteration, loss:0.090\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "133 epoch,  1000 iteration, loss:0.101\n",
      " num 132 epoch \n",
      "####### Training Loss #######\n",
      "[0.09410577]\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "134 epoch,   500 iteration, loss:0.047\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "134 epoch,  1000 iteration, loss:0.092\n",
      " num 133 epoch \n",
      "####### Training Loss #######\n",
      "[0.07132712]\n",
      "Checking accuracy on test set\n",
      "Got 710 / 1000 correct (71.00)\n",
      "135 epoch,   500 iteration, loss:0.084\n",
      "Checking accuracy on test set\n",
      "Got 724 / 1000 correct (72.40)\n",
      "135 epoch,  1000 iteration, loss:0.064\n",
      " num 134 epoch \n",
      "####### Training Loss #######\n",
      "[0.0724637]\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "136 epoch,   500 iteration, loss:0.042\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "136 epoch,  1000 iteration, loss:0.062\n",
      " num 135 epoch \n",
      "####### Training Loss #######\n",
      "[0.0640629]\n",
      "Checking accuracy on test set\n",
      "Got 726 / 1000 correct (72.60)\n",
      "137 epoch,   500 iteration, loss:0.099\n",
      "Checking accuracy on test set\n",
      "Got 709 / 1000 correct (70.90)\n",
      "137 epoch,  1000 iteration, loss:0.096\n",
      " num 136 epoch \n",
      "####### Training Loss #######\n",
      "[0.10103572]\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "138 epoch,   500 iteration, loss:0.046\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "138 epoch,  1000 iteration, loss:0.070\n",
      " num 137 epoch \n",
      "####### Training Loss #######\n",
      "[0.06552935]\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "139 epoch,   500 iteration, loss:0.074\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "139 epoch,  1000 iteration, loss:0.060\n",
      " num 138 epoch \n",
      "####### Training Loss #######\n",
      "[0.07085229]\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "140 epoch,   500 iteration, loss:0.108\n",
      "Checking accuracy on test set\n",
      "Got 715 / 1000 correct (71.50)\n",
      "140 epoch,  1000 iteration, loss:0.086\n",
      " num 139 epoch \n",
      "####### Training Loss #######\n",
      "[0.09090647]\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "141 epoch,   500 iteration, loss:0.064\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "141 epoch,  1000 iteration, loss:0.086\n",
      " num 140 epoch \n",
      "####### Training Loss #######\n",
      "[0.0743458]\n",
      "Checking accuracy on test set\n",
      "Got 705 / 1000 correct (70.50)\n",
      "142 epoch,   500 iteration, loss:0.072\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "142 epoch,  1000 iteration, loss:0.089\n",
      " num 141 epoch \n",
      "####### Training Loss #######\n",
      "[0.07715732]\n",
      "Checking accuracy on test set\n",
      "Got 675 / 1000 correct (67.50)\n",
      "143 epoch,   500 iteration, loss:0.091\n",
      "Checking accuracy on test set\n",
      "Got 754 / 1000 correct (75.40)\n",
      "143 epoch,  1000 iteration, loss:0.121\n",
      " num 142 epoch \n",
      "####### Training Loss #######\n",
      "[0.09796202]\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "144 epoch,   500 iteration, loss:0.069\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "144 epoch,  1000 iteration, loss:0.060\n",
      " num 143 epoch \n",
      "####### Training Loss #######\n",
      "[0.06287359]\n",
      "Checking accuracy on test set\n",
      "Got 725 / 1000 correct (72.50)\n",
      "145 epoch,   500 iteration, loss:0.105\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "145 epoch,  1000 iteration, loss:0.090\n",
      " num 144 epoch \n",
      "####### Training Loss #######\n",
      "[0.09112899]\n",
      "Checking accuracy on test set\n",
      "Got 717 / 1000 correct (71.70)\n",
      "146 epoch,   500 iteration, loss:0.059\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "146 epoch,  1000 iteration, loss:0.082\n",
      " num 145 epoch \n",
      "####### Training Loss #######\n",
      "[0.06774373]\n",
      "Checking accuracy on test set\n",
      "Got 718 / 1000 correct (71.80)\n",
      "147 epoch,   500 iteration, loss:0.099\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "147 epoch,  1000 iteration, loss:0.077\n",
      " num 146 epoch \n",
      "####### Training Loss #######\n",
      "[0.08844285]\n",
      "Checking accuracy on test set\n",
      "Got 728 / 1000 correct (72.80)\n",
      "148 epoch,   500 iteration, loss:0.082\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "148 epoch,  1000 iteration, loss:0.040\n",
      " num 147 epoch \n",
      "####### Training Loss #######\n",
      "[0.07117918]\n",
      "Checking accuracy on test set\n",
      "Got 725 / 1000 correct (72.50)\n",
      "149 epoch,   500 iteration, loss:0.065\n",
      "Checking accuracy on test set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "149 epoch,  1000 iteration, loss:0.095\n",
      " num 148 epoch \n",
      "####### Training Loss #######\n",
      "[0.07436602]\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "150 epoch,   500 iteration, loss:0.066\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "150 epoch,  1000 iteration, loss:0.079\n",
      " num 149 epoch \n",
      "####### Training Loss #######\n",
      "[0.07453835]\n",
      "Checking accuracy on test set\n",
      "Got 719 / 1000 correct (71.90)\n",
      "151 epoch,   500 iteration, loss:0.086\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "151 epoch,  1000 iteration, loss:0.081\n",
      " num 150 epoch \n",
      "####### Training Loss #######\n",
      "[0.08161341]\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "152 epoch,   500 iteration, loss:0.061\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "152 epoch,  1000 iteration, loss:0.084\n",
      " num 151 epoch \n",
      "####### Training Loss #######\n",
      "[0.07893311]\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "153 epoch,   500 iteration, loss:0.089\n",
      "Checking accuracy on test set\n",
      "Got 725 / 1000 correct (72.50)\n",
      "153 epoch,  1000 iteration, loss:0.062\n",
      " num 152 epoch \n",
      "####### Training Loss #######\n",
      "[0.07106595]\n",
      "Checking accuracy on test set\n",
      "Got 725 / 1000 correct (72.50)\n",
      "154 epoch,   500 iteration, loss:0.094\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "154 epoch,  1000 iteration, loss:0.064\n",
      " num 153 epoch \n",
      "####### Training Loss #######\n",
      "[0.08117035]\n",
      "Checking accuracy on test set\n",
      "Got 721 / 1000 correct (72.10)\n",
      "155 epoch,   500 iteration, loss:0.086\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "155 epoch,  1000 iteration, loss:0.119\n",
      " num 154 epoch \n",
      "####### Training Loss #######\n",
      "[0.09450109]\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "156 epoch,   500 iteration, loss:0.086\n",
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "156 epoch,  1000 iteration, loss:0.042\n",
      " num 155 epoch \n",
      "####### Training Loss #######\n",
      "[0.06501061]\n",
      "Checking accuracy on test set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "157 epoch,   500 iteration, loss:0.028\n",
      "Checking accuracy on test set\n",
      "Got 755 / 1000 correct (75.50)\n",
      "157 epoch,  1000 iteration, loss:0.050\n",
      " num 156 epoch \n",
      "####### Training Loss #######\n",
      "[0.04540016]\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "158 epoch,   500 iteration, loss:0.086\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "158 epoch,  1000 iteration, loss:0.036\n",
      " num 157 epoch \n",
      "####### Training Loss #######\n",
      "[0.05787535]\n",
      "Checking accuracy on test set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "159 epoch,   500 iteration, loss:0.073\n",
      "Checking accuracy on test set\n",
      "Got 710 / 1000 correct (71.00)\n",
      "159 epoch,  1000 iteration, loss:0.087\n",
      " num 158 epoch \n",
      "####### Training Loss #######\n",
      "[0.07614629]\n",
      "Checking accuracy on test set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "160 epoch,   500 iteration, loss:0.061\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "160 epoch,  1000 iteration, loss:0.069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num 159 epoch \n",
      "####### Training Loss #######\n",
      "[0.06208876]\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "161 epoch,   500 iteration, loss:0.075\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "161 epoch,  1000 iteration, loss:0.053\n",
      " num 160 epoch \n",
      "####### Training Loss #######\n",
      "[0.06906576]\n",
      "Checking accuracy on test set\n",
      "Got 755 / 1000 correct (75.50)\n",
      "162 epoch,   500 iteration, loss:0.056\n",
      "Checking accuracy on test set\n",
      "Got 755 / 1000 correct (75.50)\n",
      "162 epoch,  1000 iteration, loss:0.056\n",
      " num 161 epoch \n",
      "####### Training Loss #######\n",
      "[0.05870985]\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "163 epoch,   500 iteration, loss:0.060\n",
      "Checking accuracy on test set\n",
      "Got 720 / 1000 correct (72.00)\n",
      "163 epoch,  1000 iteration, loss:0.057\n",
      " num 162 epoch \n",
      "####### Training Loss #######\n",
      "[0.06613108]\n",
      "Checking accuracy on test set\n",
      "Got 725 / 1000 correct (72.50)\n",
      "164 epoch,   500 iteration, loss:0.066\n",
      "Checking accuracy on test set\n",
      "Got 722 / 1000 correct (72.20)\n",
      "164 epoch,  1000 iteration, loss:0.050\n",
      " num 163 epoch \n",
      "####### Training Loss #######\n",
      "[0.07427261]\n",
      "Checking accuracy on test set\n",
      "Got 725 / 1000 correct (72.50)\n",
      "165 epoch,   500 iteration, loss:0.068\n",
      "Checking accuracy on test set\n",
      "Got 728 / 1000 correct (72.80)\n",
      "165 epoch,  1000 iteration, loss:0.081\n",
      " num 164 epoch \n",
      "####### Training Loss #######\n",
      "[0.08328397]\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "166 epoch,   500 iteration, loss:0.088\n",
      "Checking accuracy on test set\n",
      "Got 767 / 1000 correct (76.70)\n",
      "166 epoch,  1000 iteration, loss:0.061\n",
      " num 165 epoch \n",
      "####### Training Loss #######\n",
      "[0.0730099]\n",
      "Checking accuracy on test set\n",
      "Got 728 / 1000 correct (72.80)\n",
      "167 epoch,   500 iteration, loss:0.061\n",
      "Checking accuracy on test set\n",
      "Got 753 / 1000 correct (75.30)\n",
      "167 epoch,  1000 iteration, loss:0.069\n",
      " num 166 epoch \n",
      "####### Training Loss #######\n",
      "[0.06346877]\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "168 epoch,   500 iteration, loss:0.059\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "168 epoch,  1000 iteration, loss:0.095\n",
      " num 167 epoch \n",
      "####### Training Loss #######\n",
      "[0.07754822]\n",
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "169 epoch,   500 iteration, loss:0.048\n",
      "Checking accuracy on test set\n",
      "Got 718 / 1000 correct (71.80)\n",
      "169 epoch,  1000 iteration, loss:0.063\n",
      " num 168 epoch \n",
      "####### Training Loss #######\n",
      "[0.05112139]\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "170 epoch,   500 iteration, loss:0.075\n",
      "Checking accuracy on test set\n",
      "Got 726 / 1000 correct (72.60)\n",
      "170 epoch,  1000 iteration, loss:0.079\n",
      " num 169 epoch \n",
      "####### Training Loss #######\n",
      "[0.074159]\n",
      "Checking accuracy on test set\n",
      "Got 754 / 1000 correct (75.40)\n",
      "171 epoch,   500 iteration, loss:0.065\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "171 epoch,  1000 iteration, loss:0.063\n",
      " num 170 epoch \n",
      "####### Training Loss #######\n",
      "[0.06899504]\n",
      "Checking accuracy on test set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "172 epoch,   500 iteration, loss:0.070\n",
      "Checking accuracy on test set\n",
      "Got 732 / 1000 correct (73.20)\n",
      "172 epoch,  1000 iteration, loss:0.089\n",
      " num 171 epoch \n",
      "####### Training Loss #######\n",
      "[0.07406042]\n",
      "Checking accuracy on test set\n",
      "Got 720 / 1000 correct (72.00)\n",
      "173 epoch,   500 iteration, loss:0.067\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "173 epoch,  1000 iteration, loss:0.058\n",
      " num 172 epoch \n",
      "####### Training Loss #######\n",
      "[0.0669121]\n",
      "Checking accuracy on test set\n",
      "Got 709 / 1000 correct (70.90)\n",
      "174 epoch,   500 iteration, loss:0.061\n",
      "Checking accuracy on test set\n",
      "Got 725 / 1000 correct (72.50)\n",
      "174 epoch,  1000 iteration, loss:0.063\n",
      " num 173 epoch \n",
      "####### Training Loss #######\n",
      "[0.0598664]\n",
      "Checking accuracy on test set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "175 epoch,   500 iteration, loss:0.066\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "175 epoch,  1000 iteration, loss:0.077\n",
      " num 174 epoch \n",
      "####### Training Loss #######\n",
      "[0.07650113]\n",
      "Checking accuracy on test set\n",
      "Got 724 / 1000 correct (72.40)\n",
      "176 epoch,   500 iteration, loss:0.087\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "176 epoch,  1000 iteration, loss:0.108\n",
      " num 175 epoch \n",
      "####### Training Loss #######\n",
      "[0.09030164]\n",
      "Checking accuracy on test set\n",
      "Got 726 / 1000 correct (72.60)\n",
      "177 epoch,   500 iteration, loss:0.106\n",
      "Checking accuracy on test set\n",
      "Got 702 / 1000 correct (70.20)\n",
      "177 epoch,  1000 iteration, loss:0.086\n",
      " num 176 epoch \n",
      "####### Training Loss #######\n",
      "[0.09395099]\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "178 epoch,   500 iteration, loss:0.077\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "178 epoch,  1000 iteration, loss:0.066\n",
      " num 177 epoch \n",
      "####### Training Loss #######\n",
      "[0.08007735]\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "179 epoch,   500 iteration, loss:0.063\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "179 epoch,  1000 iteration, loss:0.071\n",
      " num 178 epoch \n",
      "####### Training Loss #######\n",
      "[0.06921495]\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "180 epoch,   500 iteration, loss:0.076\n",
      "Checking accuracy on test set\n",
      "Got 722 / 1000 correct (72.20)\n",
      "180 epoch,  1000 iteration, loss:0.053\n",
      " num 179 epoch \n",
      "####### Training Loss #######\n",
      "[0.07469337]\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "181 epoch,   500 iteration, loss:0.070\n",
      "Checking accuracy on test set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "181 epoch,  1000 iteration, loss:0.089\n",
      " num 180 epoch \n",
      "####### Training Loss #######\n",
      "[0.08005928]\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "182 epoch,   500 iteration, loss:0.065\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "182 epoch,  1000 iteration, loss:0.052\n",
      " num 181 epoch \n",
      "####### Training Loss #######\n",
      "[0.05590418]\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "183 epoch,   500 iteration, loss:0.058\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "183 epoch,  1000 iteration, loss:0.055\n",
      " num 182 epoch \n",
      "####### Training Loss #######\n",
      "[0.05575924]\n",
      "Checking accuracy on test set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "184 epoch,   500 iteration, loss:0.072\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "184 epoch,  1000 iteration, loss:0.031\n",
      " num 183 epoch \n",
      "####### Training Loss #######\n",
      "[0.05853406]\n",
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "185 epoch,   500 iteration, loss:0.099\n",
      "Checking accuracy on test set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "185 epoch,  1000 iteration, loss:0.054\n",
      " num 184 epoch \n",
      "####### Training Loss #######\n",
      "[0.08000651]\n",
      "Checking accuracy on test set\n",
      "Got 725 / 1000 correct (72.50)\n",
      "186 epoch,   500 iteration, loss:0.059\n",
      "Checking accuracy on test set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "186 epoch,  1000 iteration, loss:0.079\n",
      " num 185 epoch \n",
      "####### Training Loss #######\n",
      "[0.06755654]\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "187 epoch,   500 iteration, loss:0.091\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "187 epoch,  1000 iteration, loss:0.071\n",
      " num 186 epoch \n",
      "####### Training Loss #######\n",
      "[0.08134022]\n",
      "Checking accuracy on test set\n",
      "Got 704 / 1000 correct (70.40)\n",
      "188 epoch,   500 iteration, loss:0.053\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "188 epoch,  1000 iteration, loss:0.068\n",
      " num 187 epoch \n",
      "####### Training Loss #######\n",
      "[0.07576151]\n",
      "Checking accuracy on test set\n",
      "Got 712 / 1000 correct (71.20)\n",
      "189 epoch,   500 iteration, loss:0.090\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "189 epoch,  1000 iteration, loss:0.072\n",
      " num 188 epoch \n",
      "####### Training Loss #######\n",
      "[0.07861477]\n",
      "Checking accuracy on test set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "190 epoch,   500 iteration, loss:0.067\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "190 epoch,  1000 iteration, loss:0.099\n",
      " num 189 epoch \n",
      "####### Training Loss #######\n",
      "[0.08194816]\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "191 epoch,   500 iteration, loss:0.084\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "191 epoch,  1000 iteration, loss:0.045\n",
      " num 190 epoch \n",
      "####### Training Loss #######\n",
      "[0.0638691]\n",
      "Checking accuracy on test set\n",
      "Got 700 / 1000 correct (70.00)\n",
      "192 epoch,   500 iteration, loss:0.104\n",
      "Checking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 726 / 1000 correct (72.60)\n",
      "192 epoch,  1000 iteration, loss:0.096\n",
      " num 191 epoch \n",
      "####### Training Loss #######\n",
      "[0.09674083]\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "193 epoch,   500 iteration, loss:0.083\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "193 epoch,  1000 iteration, loss:0.052\n",
      " num 192 epoch \n",
      "####### Training Loss #######\n",
      "[0.06585989]\n",
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "194 epoch,   500 iteration, loss:0.064\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "194 epoch,  1000 iteration, loss:0.079\n",
      " num 193 epoch \n",
      "####### Training Loss #######\n",
      "[0.06524484]\n",
      "Checking accuracy on test set\n",
      "Got 668 / 1000 correct (66.80)\n",
      "195 epoch,   500 iteration, loss:0.066\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "195 epoch,  1000 iteration, loss:0.063\n",
      " num 194 epoch \n",
      "####### Training Loss #######\n",
      "[0.06775813]\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "196 epoch,   500 iteration, loss:0.100\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "196 epoch,  1000 iteration, loss:0.061\n",
      " num 195 epoch \n",
      "####### Training Loss #######\n",
      "[0.07872865]\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "197 epoch,   500 iteration, loss:0.050\n",
      "Checking accuracy on test set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "197 epoch,  1000 iteration, loss:0.056\n",
      " num 196 epoch \n",
      "####### Training Loss #######\n",
      "[0.05699068]\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "198 epoch,   500 iteration, loss:0.037\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "198 epoch,  1000 iteration, loss:0.063\n",
      " num 197 epoch \n",
      "####### Training Loss #######\n",
      "[0.05042692]\n",
      "Checking accuracy on test set\n",
      "Got 754 / 1000 correct (75.40)\n",
      "199 epoch,   500 iteration, loss:0.066\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "199 epoch,  1000 iteration, loss:0.044\n",
      " num 198 epoch \n",
      "####### Training Loss #######\n",
      "[0.05551505]\n",
      "Checking accuracy on test set\n",
      "Got 732 / 1000 correct (73.20)\n",
      "200 epoch,   500 iteration, loss:0.070\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "200 epoch,  1000 iteration, loss:0.086\n",
      " num 199 epoch \n",
      "####### Training Loss #######\n",
      "[0.069224]\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "201 epoch,   500 iteration, loss:0.052\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "201 epoch,  1000 iteration, loss:0.049\n",
      " num 200 epoch \n",
      "####### Training Loss #######\n",
      "[0.05407596]\n",
      "Checking accuracy on test set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "202 epoch,   500 iteration, loss:0.073\n",
      "Checking accuracy on test set\n",
      "Got 720 / 1000 correct (72.00)\n",
      "202 epoch,  1000 iteration, loss:0.095\n",
      " num 201 epoch \n",
      "####### Training Loss #######\n",
      "[0.08194968]\n",
      "Checking accuracy on test set\n",
      "Got 729 / 1000 correct (72.90)\n",
      "203 epoch,   500 iteration, loss:0.059\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "203 epoch,  1000 iteration, loss:0.092\n",
      " num 202 epoch \n",
      "####### Training Loss #######\n",
      "[0.07141038]\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "204 epoch,   500 iteration, loss:0.040\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "204 epoch,  1000 iteration, loss:0.085\n",
      " num 203 epoch \n",
      "####### Training Loss #######\n",
      "[0.06321728]\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "205 epoch,   500 iteration, loss:0.061\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "205 epoch,  1000 iteration, loss:0.087\n",
      " num 204 epoch \n",
      "####### Training Loss #######\n",
      "[0.06604055]\n",
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "206 epoch,   500 iteration, loss:0.049\n",
      "Checking accuracy on test set\n",
      "Got 701 / 1000 correct (70.10)\n",
      "206 epoch,  1000 iteration, loss:0.054\n",
      " num 205 epoch \n",
      "####### Training Loss #######\n",
      "[0.05593442]\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "207 epoch,   500 iteration, loss:0.091\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "207 epoch,  1000 iteration, loss:0.065\n",
      " num 206 epoch \n",
      "####### Training Loss #######\n",
      "[0.08711053]\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "208 epoch,   500 iteration, loss:0.082\n",
      "Checking accuracy on test set\n",
      "Got 759 / 1000 correct (75.90)\n",
      "208 epoch,  1000 iteration, loss:0.042\n",
      " num 207 epoch \n",
      "####### Training Loss #######\n",
      "[0.05448627]\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "209 epoch,   500 iteration, loss:0.079\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "209 epoch,  1000 iteration, loss:0.082\n",
      " num 208 epoch \n",
      "####### Training Loss #######\n",
      "[0.07826205]\n",
      "Checking accuracy on test set\n",
      "Got 767 / 1000 correct (76.70)\n",
      "210 epoch,   500 iteration, loss:0.081\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "210 epoch,  1000 iteration, loss:0.082\n",
      " num 209 epoch \n",
      "####### Training Loss #######\n",
      "[0.08218181]\n",
      "Checking accuracy on test set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "211 epoch,   500 iteration, loss:0.083\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "211 epoch,  1000 iteration, loss:0.065\n",
      " num 210 epoch \n",
      "####### Training Loss #######\n",
      "[0.07168669]\n",
      "Checking accuracy on test set\n",
      "Got 722 / 1000 correct (72.20)\n",
      "212 epoch,   500 iteration, loss:0.077\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "212 epoch,  1000 iteration, loss:0.058\n",
      " num 211 epoch \n",
      "####### Training Loss #######\n",
      "[0.06978058]\n",
      "Checking accuracy on test set\n",
      "Got 754 / 1000 correct (75.40)\n",
      "213 epoch,   500 iteration, loss:0.048\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "213 epoch,  1000 iteration, loss:0.052\n",
      " num 212 epoch \n",
      "####### Training Loss #######\n",
      "[0.05474265]\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "214 epoch,   500 iteration, loss:0.071\n",
      "Checking accuracy on test set\n",
      "Got 765 / 1000 correct (76.50)\n",
      "214 epoch,  1000 iteration, loss:0.034\n",
      " num 213 epoch \n",
      "####### Training Loss #######\n",
      "[0.05448621]\n",
      "Checking accuracy on test set\n",
      "Got 769 / 1000 correct (76.90)\n",
      "215 epoch,   500 iteration, loss:0.072\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "215 epoch,  1000 iteration, loss:0.043\n",
      " num 214 epoch \n",
      "####### Training Loss #######\n",
      "[0.06267907]\n",
      "Checking accuracy on test set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "216 epoch,   500 iteration, loss:0.052\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "216 epoch,  1000 iteration, loss:0.086\n",
      " num 215 epoch \n",
      "####### Training Loss #######\n",
      "[0.07421457]\n",
      "Checking accuracy on test set\n",
      "Got 728 / 1000 correct (72.80)\n",
      "217 epoch,   500 iteration, loss:0.077\n",
      "Checking accuracy on test set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "217 epoch,  1000 iteration, loss:0.057\n",
      " num 216 epoch \n",
      "####### Training Loss #######\n",
      "[0.06571986]\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "218 epoch,   500 iteration, loss:0.067\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "218 epoch,  1000 iteration, loss:0.051\n",
      " num 217 epoch \n",
      "####### Training Loss #######\n",
      "[0.05891516]\n",
      "Checking accuracy on test set\n",
      "Got 682 / 1000 correct (68.20)\n",
      "219 epoch,   500 iteration, loss:0.080\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "219 epoch,  1000 iteration, loss:0.098\n",
      " num 218 epoch \n",
      "####### Training Loss #######\n",
      "[0.08166085]\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "220 epoch,   500 iteration, loss:0.084\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "220 epoch,  1000 iteration, loss:0.043\n",
      " num 219 epoch \n",
      "####### Training Loss #######\n",
      "[0.06673862]\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "221 epoch,   500 iteration, loss:0.045\n",
      "Checking accuracy on test set\n",
      "Got 724 / 1000 correct (72.40)\n",
      "221 epoch,  1000 iteration, loss:0.065\n",
      " num 220 epoch \n",
      "####### Training Loss #######\n",
      "[0.067458]\n",
      "Checking accuracy on test set\n",
      "Got 726 / 1000 correct (72.60)\n",
      "222 epoch,   500 iteration, loss:0.060\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "222 epoch,  1000 iteration, loss:0.070\n",
      " num 221 epoch \n",
      "####### Training Loss #######\n",
      "[0.06433191]\n",
      "Checking accuracy on test set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "223 epoch,   500 iteration, loss:0.084\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "223 epoch,  1000 iteration, loss:0.040\n",
      " num 222 epoch \n",
      "####### Training Loss #######\n",
      "[0.06598137]\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "224 epoch,   500 iteration, loss:0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "224 epoch,  1000 iteration, loss:0.041\n",
      " num 223 epoch \n",
      "####### Training Loss #######\n",
      "[0.05096554]\n",
      "Checking accuracy on test set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "225 epoch,   500 iteration, loss:0.050\n",
      "Checking accuracy on test set\n",
      "Got 720 / 1000 correct (72.00)\n",
      "225 epoch,  1000 iteration, loss:0.072\n",
      " num 224 epoch \n",
      "####### Training Loss #######\n",
      "[0.06399252]\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "226 epoch,   500 iteration, loss:0.060\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "226 epoch,  1000 iteration, loss:0.094\n",
      " num 225 epoch \n",
      "####### Training Loss #######\n",
      "[0.07325612]\n",
      "Checking accuracy on test set\n",
      "Got 700 / 1000 correct (70.00)\n",
      "227 epoch,   500 iteration, loss:0.077\n",
      "Checking accuracy on test set\n",
      "Got 726 / 1000 correct (72.60)\n",
      "227 epoch,  1000 iteration, loss:0.089\n",
      " num 226 epoch \n",
      "####### Training Loss #######\n",
      "[0.07127344]\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "228 epoch,   500 iteration, loss:0.050\n",
      "Checking accuracy on test set\n",
      "Got 720 / 1000 correct (72.00)\n",
      "228 epoch,  1000 iteration, loss:0.075\n",
      " num 227 epoch \n",
      "####### Training Loss #######\n",
      "[0.06335576]\n",
      "Checking accuracy on test set\n",
      "Got 713 / 1000 correct (71.30)\n",
      "229 epoch,   500 iteration, loss:0.062\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "229 epoch,  1000 iteration, loss:0.068\n",
      " num 228 epoch \n",
      "####### Training Loss #######\n",
      "[0.0660778]\n",
      "Checking accuracy on test set\n",
      "Got 726 / 1000 correct (72.60)\n",
      "230 epoch,   500 iteration, loss:0.046\n",
      "Checking accuracy on test set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "230 epoch,  1000 iteration, loss:0.065\n",
      " num 229 epoch \n",
      "####### Training Loss #######\n",
      "[0.05628294]\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "231 epoch,   500 iteration, loss:0.049\n",
      "Checking accuracy on test set\n",
      "Got 725 / 1000 correct (72.50)\n",
      "231 epoch,  1000 iteration, loss:0.075\n",
      " num 230 epoch \n",
      "####### Training Loss #######\n",
      "[0.06062448]\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "232 epoch,   500 iteration, loss:0.076\n",
      "Checking accuracy on test set\n",
      "Got 705 / 1000 correct (70.50)\n",
      "232 epoch,  1000 iteration, loss:0.075\n",
      " num 231 epoch \n",
      "####### Training Loss #######\n",
      "[0.07569666]\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "233 epoch,   500 iteration, loss:0.084\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "233 epoch,  1000 iteration, loss:0.055\n",
      " num 232 epoch \n",
      "####### Training Loss #######\n",
      "[0.06617769]\n",
      "Checking accuracy on test set\n",
      "Got 754 / 1000 correct (75.40)\n",
      "234 epoch,   500 iteration, loss:0.060\n",
      "Checking accuracy on test set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "234 epoch,  1000 iteration, loss:0.063\n",
      " num 233 epoch \n",
      "####### Training Loss #######\n",
      "[0.06136673]\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "235 epoch,   500 iteration, loss:0.045\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "235 epoch,  1000 iteration, loss:0.036\n",
      " num 234 epoch \n",
      "####### Training Loss #######\n",
      "[0.04513663]\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "236 epoch,   500 iteration, loss:0.076\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "236 epoch,  1000 iteration, loss:0.044\n",
      " num 235 epoch \n",
      "####### Training Loss #######\n",
      "[0.06753911]\n",
      "Checking accuracy on test set\n",
      "Got 703 / 1000 correct (70.30)\n",
      "237 epoch,   500 iteration, loss:0.062\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "237 epoch,  1000 iteration, loss:0.045\n",
      " num 236 epoch \n",
      "####### Training Loss #######\n",
      "[0.05411569]\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "238 epoch,   500 iteration, loss:0.085\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "238 epoch,  1000 iteration, loss:0.059\n",
      " num 237 epoch \n",
      "####### Training Loss #######\n",
      "[0.07172559]\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "239 epoch,   500 iteration, loss:0.029\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "239 epoch,  1000 iteration, loss:0.047\n",
      " num 238 epoch \n",
      "####### Training Loss #######\n",
      "[0.03489683]\n",
      "Checking accuracy on test set\n",
      "Got 726 / 1000 correct (72.60)\n",
      "240 epoch,   500 iteration, loss:0.108\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "240 epoch,  1000 iteration, loss:0.070\n",
      " num 239 epoch \n",
      "####### Training Loss #######\n",
      "[0.08054938]\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "241 epoch,   500 iteration, loss:0.047\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "241 epoch,  1000 iteration, loss:0.050\n",
      " num 240 epoch \n",
      "####### Training Loss #######\n",
      "[0.05364857]\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "242 epoch,   500 iteration, loss:0.055\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "242 epoch,  1000 iteration, loss:0.069\n",
      " num 241 epoch \n",
      "####### Training Loss #######\n",
      "[0.05855138]\n",
      "Checking accuracy on test set\n",
      "Got 717 / 1000 correct (71.70)\n",
      "243 epoch,   500 iteration, loss:0.077\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "243 epoch,  1000 iteration, loss:0.059\n",
      " num 242 epoch \n",
      "####### Training Loss #######\n",
      "[0.06247667]\n",
      "Checking accuracy on test set\n",
      "Got 724 / 1000 correct (72.40)\n",
      "244 epoch,   500 iteration, loss:0.042\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "244 epoch,  1000 iteration, loss:0.037\n",
      " num 243 epoch \n",
      "####### Training Loss #######\n",
      "[0.0453534]\n",
      "Checking accuracy on test set\n",
      "Got 753 / 1000 correct (75.30)\n",
      "245 epoch,   500 iteration, loss:0.077\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "245 epoch,  1000 iteration, loss:0.097\n",
      " num 244 epoch \n",
      "####### Training Loss #######\n",
      "[0.08194372]\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "246 epoch,   500 iteration, loss:0.073\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "246 epoch,  1000 iteration, loss:0.054\n",
      " num 245 epoch \n",
      "####### Training Loss #######\n",
      "[0.06472746]\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "247 epoch,   500 iteration, loss:0.064\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "247 epoch,  1000 iteration, loss:0.055\n",
      " num 246 epoch \n",
      "####### Training Loss #######\n",
      "[0.06050048]\n",
      "Checking accuracy on test set\n",
      "Got 732 / 1000 correct (73.20)\n",
      "248 epoch,   500 iteration, loss:0.051\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "248 epoch,  1000 iteration, loss:0.061\n",
      " num 247 epoch \n",
      "####### Training Loss #######\n",
      "[0.05716776]\n",
      "Checking accuracy on test set\n",
      "Got 724 / 1000 correct (72.40)\n",
      "249 epoch,   500 iteration, loss:0.064\n",
      "Checking accuracy on test set\n",
      "Got 761 / 1000 correct (76.10)\n",
      "249 epoch,  1000 iteration, loss:0.078\n",
      " num 248 epoch \n",
      "####### Training Loss #######\n",
      "[0.06681871]\n",
      "Checking accuracy on test set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "250 epoch,   500 iteration, loss:0.077\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "250 epoch,  1000 iteration, loss:0.047\n",
      " num 249 epoch \n",
      "####### Training Loss #######\n",
      "[0.06310072]\n",
      "Checking accuracy on test set\n",
      "Got 729 / 1000 correct (72.90)\n",
      "251 epoch,   500 iteration, loss:0.078\n",
      "Checking accuracy on test set\n",
      "Got 754 / 1000 correct (75.40)\n",
      "251 epoch,  1000 iteration, loss:0.052\n",
      " num 250 epoch \n",
      "####### Training Loss #######\n",
      "[0.06861968]\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "252 epoch,   500 iteration, loss:0.054\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "252 epoch,  1000 iteration, loss:0.061\n",
      " num 251 epoch \n",
      "####### Training Loss #######\n",
      "[0.05525229]\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "253 epoch,   500 iteration, loss:0.039\n",
      "Checking accuracy on test set\n",
      "Got 728 / 1000 correct (72.80)\n",
      "253 epoch,  1000 iteration, loss:0.067\n",
      " num 252 epoch \n",
      "####### Training Loss #######\n",
      "[0.05380384]\n",
      "Checking accuracy on test set\n",
      "Got 724 / 1000 correct (72.40)\n",
      "254 epoch,   500 iteration, loss:0.035\n",
      "Checking accuracy on test set\n",
      "Got 753 / 1000 correct (75.30)\n",
      "254 epoch,  1000 iteration, loss:0.081\n",
      " num 253 epoch \n",
      "####### Training Loss #######\n",
      "[0.0528541]\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "255 epoch,   500 iteration, loss:0.075\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "255 epoch,  1000 iteration, loss:0.060\n",
      " num 254 epoch \n",
      "####### Training Loss #######\n",
      "[0.06875889]\n",
      "Checking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 753 / 1000 correct (75.30)\n",
      "256 epoch,   500 iteration, loss:0.039\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "256 epoch,  1000 iteration, loss:0.042\n",
      " num 255 epoch \n",
      "####### Training Loss #######\n",
      "[0.04809539]\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "257 epoch,   500 iteration, loss:0.086\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "257 epoch,  1000 iteration, loss:0.038\n",
      " num 256 epoch \n",
      "####### Training Loss #######\n",
      "[0.05872137]\n",
      "Checking accuracy on test set\n",
      "Got 719 / 1000 correct (71.90)\n",
      "258 epoch,   500 iteration, loss:0.084\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "258 epoch,  1000 iteration, loss:0.060\n",
      " num 257 epoch \n",
      "####### Training Loss #######\n",
      "[0.07574531]\n",
      "Checking accuracy on test set\n",
      "Got 715 / 1000 correct (71.50)\n",
      "259 epoch,   500 iteration, loss:0.078\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "259 epoch,  1000 iteration, loss:0.057\n",
      " num 258 epoch \n",
      "####### Training Loss #######\n",
      "[0.06430421]\n",
      "Checking accuracy on test set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "260 epoch,   500 iteration, loss:0.054\n",
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "260 epoch,  1000 iteration, loss:0.062\n",
      " num 259 epoch \n",
      "####### Training Loss #######\n",
      "[0.06039302]\n",
      "Checking accuracy on test set\n",
      "Got 705 / 1000 correct (70.50)\n",
      "261 epoch,   500 iteration, loss:0.058\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "261 epoch,  1000 iteration, loss:0.107\n",
      " num 260 epoch \n",
      "####### Training Loss #######\n",
      "[0.07804642]\n",
      "Checking accuracy on test set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "262 epoch,   500 iteration, loss:0.050\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "262 epoch,  1000 iteration, loss:0.098\n",
      " num 261 epoch \n",
      "####### Training Loss #######\n",
      "[0.07388039]\n",
      "Checking accuracy on test set\n",
      "Got 713 / 1000 correct (71.30)\n",
      "263 epoch,   500 iteration, loss:0.057\n",
      "Checking accuracy on test set\n",
      "Got 716 / 1000 correct (71.60)\n",
      "263 epoch,  1000 iteration, loss:0.067\n",
      " num 262 epoch \n",
      "####### Training Loss #######\n",
      "[0.06714304]\n",
      "Checking accuracy on test set\n",
      "Got 718 / 1000 correct (71.80)\n",
      "264 epoch,   500 iteration, loss:0.064\n",
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "264 epoch,  1000 iteration, loss:0.067\n",
      " num 263 epoch \n",
      "####### Training Loss #######\n",
      "[0.06934957]\n",
      "Checking accuracy on test set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "265 epoch,   500 iteration, loss:0.047\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "265 epoch,  1000 iteration, loss:0.053\n",
      " num 264 epoch \n",
      "####### Training Loss #######\n",
      "[0.05285165]\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "266 epoch,   500 iteration, loss:0.065\n",
      "Checking accuracy on test set\n",
      "Got 720 / 1000 correct (72.00)\n",
      "266 epoch,  1000 iteration, loss:0.079\n",
      " num 265 epoch \n",
      "####### Training Loss #######\n",
      "[0.07367793]\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "267 epoch,   500 iteration, loss:0.055\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "267 epoch,  1000 iteration, loss:0.074\n",
      " num 266 epoch \n",
      "####### Training Loss #######\n",
      "[0.06792617]\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "268 epoch,   500 iteration, loss:0.056\n",
      "Checking accuracy on test set\n",
      "Got 754 / 1000 correct (75.40)\n",
      "268 epoch,  1000 iteration, loss:0.058\n",
      " num 267 epoch \n",
      "####### Training Loss #######\n",
      "[0.06972756]\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "269 epoch,   500 iteration, loss:0.081\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "269 epoch,  1000 iteration, loss:0.060\n",
      " num 268 epoch \n",
      "####### Training Loss #######\n",
      "[0.06740159]\n",
      "Checking accuracy on test set\n",
      "Got 725 / 1000 correct (72.50)\n",
      "270 epoch,   500 iteration, loss:0.074\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "270 epoch,  1000 iteration, loss:0.063\n",
      " num 269 epoch \n",
      "####### Training Loss #######\n",
      "[0.06970082]\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "271 epoch,   500 iteration, loss:0.040\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "271 epoch,  1000 iteration, loss:0.057\n",
      " num 270 epoch \n",
      "####### Training Loss #######\n",
      "[0.04964139]\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "272 epoch,   500 iteration, loss:0.085\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "272 epoch,  1000 iteration, loss:0.063\n",
      " num 271 epoch \n",
      "####### Training Loss #######\n",
      "[0.06945316]\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "273 epoch,   500 iteration, loss:0.040\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "273 epoch,  1000 iteration, loss:0.026\n",
      " num 272 epoch \n",
      "####### Training Loss #######\n",
      "[0.03059015]\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "274 epoch,   500 iteration, loss:0.035\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "274 epoch,  1000 iteration, loss:0.075\n",
      " num 273 epoch \n",
      "####### Training Loss #######\n",
      "[0.06347498]\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "275 epoch,   500 iteration, loss:0.036\n",
      "Checking accuracy on test set\n",
      "Got 711 / 1000 correct (71.10)\n",
      "275 epoch,  1000 iteration, loss:0.084\n",
      " num 274 epoch \n",
      "####### Training Loss #######\n",
      "[0.0606338]\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "276 epoch,   500 iteration, loss:0.051\n",
      "Checking accuracy on test set\n",
      "Got 729 / 1000 correct (72.90)\n",
      "276 epoch,  1000 iteration, loss:0.049\n",
      " num 275 epoch \n",
      "####### Training Loss #######\n",
      "[0.05127193]\n",
      "Checking accuracy on test set\n",
      "Got 726 / 1000 correct (72.60)\n",
      "277 epoch,   500 iteration, loss:0.067\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "277 epoch,  1000 iteration, loss:0.081\n",
      " num 276 epoch \n",
      "####### Training Loss #######\n",
      "[0.07294601]\n",
      "Checking accuracy on test set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "278 epoch,   500 iteration, loss:0.056\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "278 epoch,  1000 iteration, loss:0.060\n",
      " num 277 epoch \n",
      "####### Training Loss #######\n",
      "[0.05914593]\n",
      "Checking accuracy on test set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "279 epoch,   500 iteration, loss:0.066\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "279 epoch,  1000 iteration, loss:0.098\n",
      " num 278 epoch \n",
      "####### Training Loss #######\n",
      "[0.07763353]\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "280 epoch,   500 iteration, loss:0.049\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "280 epoch,  1000 iteration, loss:0.057\n",
      " num 279 epoch \n",
      "####### Training Loss #######\n",
      "[0.04899624]\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "281 epoch,   500 iteration, loss:0.069\n",
      "Checking accuracy on test set\n",
      "Got 729 / 1000 correct (72.90)\n",
      "281 epoch,  1000 iteration, loss:0.052\n",
      " num 280 epoch \n",
      "####### Training Loss #######\n",
      "[0.06047764]\n",
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "282 epoch,   500 iteration, loss:0.085\n",
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "282 epoch,  1000 iteration, loss:0.068\n",
      " num 281 epoch \n",
      "####### Training Loss #######\n",
      "[0.07363373]\n",
      "Checking accuracy on test set\n",
      "Got 717 / 1000 correct (71.70)\n",
      "283 epoch,   500 iteration, loss:0.081\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "283 epoch,  1000 iteration, loss:0.040\n",
      " num 282 epoch \n",
      "####### Training Loss #######\n",
      "[0.05902269]\n",
      "Checking accuracy on test set\n",
      "Got 753 / 1000 correct (75.30)\n",
      "284 epoch,   500 iteration, loss:0.050\n",
      "Checking accuracy on test set\n",
      "Got 732 / 1000 correct (73.20)\n",
      "284 epoch,  1000 iteration, loss:0.067\n",
      " num 283 epoch \n",
      "####### Training Loss #######\n",
      "[0.05579803]\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "285 epoch,   500 iteration, loss:0.054\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "285 epoch,  1000 iteration, loss:0.029\n",
      " num 284 epoch \n",
      "####### Training Loss #######\n",
      "[0.05206713]\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "286 epoch,   500 iteration, loss:0.045\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "286 epoch,  1000 iteration, loss:0.068\n",
      " num 285 epoch \n",
      "####### Training Loss #######\n",
      "[0.05478967]\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "287 epoch,   500 iteration, loss:0.056\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "287 epoch,  1000 iteration, loss:0.019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num 286 epoch \n",
      "####### Training Loss #######\n",
      "[0.04797518]\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "288 epoch,   500 iteration, loss:0.065\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "288 epoch,  1000 iteration, loss:0.067\n",
      " num 287 epoch \n",
      "####### Training Loss #######\n",
      "[0.05876497]\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "289 epoch,   500 iteration, loss:0.059\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "289 epoch,  1000 iteration, loss:0.082\n",
      " num 288 epoch \n",
      "####### Training Loss #######\n",
      "[0.06843176]\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "290 epoch,   500 iteration, loss:0.049\n",
      "Checking accuracy on test set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "290 epoch,  1000 iteration, loss:0.041\n",
      " num 289 epoch \n",
      "####### Training Loss #######\n",
      "[0.05907758]\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "291 epoch,   500 iteration, loss:0.034\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "291 epoch,  1000 iteration, loss:0.059\n",
      " num 290 epoch \n",
      "####### Training Loss #######\n",
      "[0.04449613]\n",
      "Checking accuracy on test set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "292 epoch,   500 iteration, loss:0.072\n",
      "Checking accuracy on test set\n",
      "Got 728 / 1000 correct (72.80)\n",
      "292 epoch,  1000 iteration, loss:0.056\n",
      " num 291 epoch \n",
      "####### Training Loss #######\n",
      "[0.06546132]\n",
      "Checking accuracy on test set\n",
      "Got 715 / 1000 correct (71.50)\n",
      "293 epoch,   500 iteration, loss:0.052\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "293 epoch,  1000 iteration, loss:0.049\n",
      " num 292 epoch \n",
      "####### Training Loss #######\n",
      "[0.04800997]\n",
      "Checking accuracy on test set\n",
      "Got 709 / 1000 correct (70.90)\n",
      "294 epoch,   500 iteration, loss:0.072\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "294 epoch,  1000 iteration, loss:0.056\n",
      " num 293 epoch \n",
      "####### Training Loss #######\n",
      "[0.06143429]\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "295 epoch,   500 iteration, loss:0.078\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "295 epoch,  1000 iteration, loss:0.051\n",
      " num 294 epoch \n",
      "####### Training Loss #######\n",
      "[0.05875695]\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "296 epoch,   500 iteration, loss:0.038\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "296 epoch,  1000 iteration, loss:0.047\n",
      " num 295 epoch \n",
      "####### Training Loss #######\n",
      "[0.05421821]\n",
      "Checking accuracy on test set\n",
      "Got 726 / 1000 correct (72.60)\n",
      "297 epoch,   500 iteration, loss:0.076\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "297 epoch,  1000 iteration, loss:0.067\n",
      " num 296 epoch \n",
      "####### Training Loss #######\n",
      "[0.07151371]\n",
      "Checking accuracy on test set\n",
      "Got 729 / 1000 correct (72.90)\n",
      "298 epoch,   500 iteration, loss:0.070\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "298 epoch,  1000 iteration, loss:0.058\n",
      " num 297 epoch \n",
      "####### Training Loss #######\n",
      "[0.0626762]\n",
      "Checking accuracy on test set\n",
      "Got 708 / 1000 correct (70.80)\n",
      "299 epoch,   500 iteration, loss:0.061\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "299 epoch,  1000 iteration, loss:0.044\n",
      " num 298 epoch \n",
      "####### Training Loss #######\n",
      "[0.05647881]\n",
      "Checking accuracy on test set\n",
      "Got 729 / 1000 correct (72.90)\n",
      "300 epoch,   500 iteration, loss:0.061\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "300 epoch,  1000 iteration, loss:0.048\n",
      " num 299 epoch \n",
      "####### Training Loss #######\n",
      "[0.05178374]\n",
      "Checking accuracy on test set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "301 epoch,   500 iteration, loss:0.065\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "301 epoch,  1000 iteration, loss:0.088\n",
      " num 300 epoch \n",
      "####### Training Loss #######\n",
      "[0.07022059]\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "302 epoch,   500 iteration, loss:0.062\n",
      "Checking accuracy on test set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "302 epoch,  1000 iteration, loss:0.066\n",
      " num 301 epoch \n",
      "####### Training Loss #######\n",
      "[0.05980843]\n",
      "Checking accuracy on test set\n",
      "Got 690 / 1000 correct (69.00)\n",
      "303 epoch,   500 iteration, loss:0.053\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "303 epoch,  1000 iteration, loss:0.076\n",
      " num 302 epoch \n",
      "####### Training Loss #######\n",
      "[0.07127033]\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "304 epoch,   500 iteration, loss:0.068\n",
      "Checking accuracy on test set\n",
      "Got 719 / 1000 correct (71.90)\n",
      "304 epoch,  1000 iteration, loss:0.061\n",
      " num 303 epoch \n",
      "####### Training Loss #######\n",
      "[0.06100776]\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "305 epoch,   500 iteration, loss:0.066\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "305 epoch,  1000 iteration, loss:0.061\n",
      " num 304 epoch \n",
      "####### Training Loss #######\n",
      "[0.06001554]\n",
      "Checking accuracy on test set\n",
      "Got 716 / 1000 correct (71.60)\n",
      "306 epoch,   500 iteration, loss:0.036\n",
      "Checking accuracy on test set\n",
      "Got 711 / 1000 correct (71.10)\n",
      "306 epoch,  1000 iteration, loss:0.091\n",
      " num 305 epoch \n",
      "####### Training Loss #######\n",
      "[0.06375754]\n",
      "Checking accuracy on test set\n",
      "Got 699 / 1000 correct (69.90)\n",
      "307 epoch,   500 iteration, loss:0.065\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "307 epoch,  1000 iteration, loss:0.048\n",
      " num 306 epoch \n",
      "####### Training Loss #######\n",
      "[0.05243514]\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "308 epoch,   500 iteration, loss:0.047\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "308 epoch,  1000 iteration, loss:0.072\n",
      " num 307 epoch \n",
      "####### Training Loss #######\n",
      "[0.06299194]\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "309 epoch,   500 iteration, loss:0.069\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "309 epoch,  1000 iteration, loss:0.078\n",
      " num 308 epoch \n",
      "####### Training Loss #######\n",
      "[0.07296202]\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "310 epoch,   500 iteration, loss:0.037\n",
      "Checking accuracy on test set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "310 epoch,  1000 iteration, loss:0.049\n",
      " num 309 epoch \n",
      "####### Training Loss #######\n",
      "[0.05417257]\n",
      "Checking accuracy on test set\n",
      "Got 732 / 1000 correct (73.20)\n",
      "311 epoch,   500 iteration, loss:0.066\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "311 epoch,  1000 iteration, loss:0.040\n",
      " num 310 epoch \n",
      "####### Training Loss #######\n",
      "[0.05145448]\n",
      "Checking accuracy on test set\n",
      "Got 688 / 1000 correct (68.80)\n",
      "312 epoch,   500 iteration, loss:0.056\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "312 epoch,  1000 iteration, loss:0.070\n",
      " num 311 epoch \n",
      "####### Training Loss #######\n",
      "[0.06154462]\n",
      "Checking accuracy on test set\n",
      "Got 718 / 1000 correct (71.80)\n",
      "313 epoch,   500 iteration, loss:0.078\n",
      "Checking accuracy on test set\n",
      "Got 732 / 1000 correct (73.20)\n",
      "313 epoch,  1000 iteration, loss:0.053\n",
      " num 312 epoch \n",
      "####### Training Loss #######\n",
      "[0.06445106]\n",
      "Checking accuracy on test set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "314 epoch,   500 iteration, loss:0.041\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "314 epoch,  1000 iteration, loss:0.086\n",
      " num 313 epoch \n",
      "####### Training Loss #######\n",
      "[0.06271912]\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "315 epoch,   500 iteration, loss:0.061\n",
      "Checking accuracy on test set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "315 epoch,  1000 iteration, loss:0.078\n",
      " num 314 epoch \n",
      "####### Training Loss #######\n",
      "[0.06643137]\n",
      "Checking accuracy on test set\n",
      "Got 717 / 1000 correct (71.70)\n",
      "316 epoch,   500 iteration, loss:0.082\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "316 epoch,  1000 iteration, loss:0.076\n",
      " num 315 epoch \n",
      "####### Training Loss #######\n",
      "[0.07202378]\n",
      "Checking accuracy on test set\n",
      "Got 693 / 1000 correct (69.30)\n",
      "317 epoch,   500 iteration, loss:0.071\n",
      "Checking accuracy on test set\n",
      "Got 761 / 1000 correct (76.10)\n",
      "317 epoch,  1000 iteration, loss:0.040\n",
      " num 316 epoch \n",
      "####### Training Loss #######\n",
      "[0.05254975]\n",
      "Checking accuracy on test set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "318 epoch,   500 iteration, loss:0.053\n",
      "Checking accuracy on test set\n",
      "Got 709 / 1000 correct (70.90)\n",
      "318 epoch,  1000 iteration, loss:0.068\n",
      " num 317 epoch \n",
      "####### Training Loss #######\n",
      "[0.05886013]\n",
      "Checking accuracy on test set\n",
      "Got 696 / 1000 correct (69.60)\n",
      "319 epoch,   500 iteration, loss:0.091\n",
      "Checking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 743 / 1000 correct (74.30)\n",
      "319 epoch,  1000 iteration, loss:0.044\n",
      " num 318 epoch \n",
      "####### Training Loss #######\n",
      "[0.06770256]\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "320 epoch,   500 iteration, loss:0.057\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "320 epoch,  1000 iteration, loss:0.052\n",
      " num 319 epoch \n",
      "####### Training Loss #######\n",
      "[0.05856353]\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "321 epoch,   500 iteration, loss:0.039\n",
      "Checking accuracy on test set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "321 epoch,  1000 iteration, loss:0.084\n",
      " num 320 epoch \n",
      "####### Training Loss #######\n",
      "[0.06458165]\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "322 epoch,   500 iteration, loss:0.037\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "322 epoch,  1000 iteration, loss:0.041\n",
      " num 321 epoch \n",
      "####### Training Loss #######\n",
      "[0.041776]\n",
      "Checking accuracy on test set\n",
      "Got 687 / 1000 correct (68.70)\n",
      "323 epoch,   500 iteration, loss:0.052\n",
      "Checking accuracy on test set\n",
      "Got 715 / 1000 correct (71.50)\n",
      "323 epoch,  1000 iteration, loss:0.060\n",
      " num 322 epoch \n",
      "####### Training Loss #######\n",
      "[0.05805058]\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "324 epoch,   500 iteration, loss:0.037\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "324 epoch,  1000 iteration, loss:0.057\n",
      " num 323 epoch \n",
      "####### Training Loss #######\n",
      "[0.04767214]\n",
      "Checking accuracy on test set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "325 epoch,   500 iteration, loss:0.056\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "325 epoch,  1000 iteration, loss:0.057\n",
      " num 324 epoch \n",
      "####### Training Loss #######\n",
      "[0.05082552]\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "326 epoch,   500 iteration, loss:0.056\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "326 epoch,  1000 iteration, loss:0.043\n",
      " num 325 epoch \n",
      "####### Training Loss #######\n",
      "[0.05682071]\n",
      "Checking accuracy on test set\n",
      "Got 716 / 1000 correct (71.60)\n",
      "327 epoch,   500 iteration, loss:0.067\n",
      "Checking accuracy on test set\n",
      "Got 722 / 1000 correct (72.20)\n",
      "327 epoch,  1000 iteration, loss:0.061\n",
      " num 326 epoch \n",
      "####### Training Loss #######\n",
      "[0.06427786]\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "328 epoch,   500 iteration, loss:0.027\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "328 epoch,  1000 iteration, loss:0.060\n",
      " num 327 epoch \n",
      "####### Training Loss #######\n",
      "[0.04723669]\n",
      "Checking accuracy on test set\n",
      "Got 716 / 1000 correct (71.60)\n",
      "329 epoch,   500 iteration, loss:0.080\n",
      "Checking accuracy on test set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "329 epoch,  1000 iteration, loss:0.045\n",
      " num 328 epoch \n",
      "####### Training Loss #######\n",
      "[0.06530783]\n",
      "Checking accuracy on test set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "330 epoch,   500 iteration, loss:0.070\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "330 epoch,  1000 iteration, loss:0.037\n",
      " num 329 epoch \n",
      "####### Training Loss #######\n",
      "[0.05597155]\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "331 epoch,   500 iteration, loss:0.063\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "331 epoch,  1000 iteration, loss:0.037\n",
      " num 330 epoch \n",
      "####### Training Loss #######\n",
      "[0.04523194]\n",
      "Checking accuracy on test set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "332 epoch,   500 iteration, loss:0.058\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "332 epoch,  1000 iteration, loss:0.028\n",
      " num 331 epoch \n",
      "####### Training Loss #######\n",
      "[0.04425405]\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "333 epoch,   500 iteration, loss:0.051\n",
      "Checking accuracy on test set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "333 epoch,  1000 iteration, loss:0.092\n",
      " num 332 epoch \n",
      "####### Training Loss #######\n",
      "[0.06853802]\n",
      "Checking accuracy on test set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "334 epoch,   500 iteration, loss:0.047\n",
      "Checking accuracy on test set\n",
      "Got 732 / 1000 correct (73.20)\n",
      "334 epoch,  1000 iteration, loss:0.053\n",
      " num 333 epoch \n",
      "####### Training Loss #######\n",
      "[0.0474613]\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "335 epoch,   500 iteration, loss:0.035\n",
      "Checking accuracy on test set\n",
      "Got 761 / 1000 correct (76.10)\n",
      "335 epoch,  1000 iteration, loss:0.021\n",
      " num 334 epoch \n",
      "####### Training Loss #######\n",
      "[0.0285128]\n",
      "Checking accuracy on test set\n",
      "Got 722 / 1000 correct (72.20)\n",
      "336 epoch,   500 iteration, loss:0.095\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "336 epoch,  1000 iteration, loss:0.069\n",
      " num 335 epoch \n",
      "####### Training Loss #######\n",
      "[0.07929012]\n",
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "337 epoch,   500 iteration, loss:0.052\n",
      "Checking accuracy on test set\n",
      "Got 726 / 1000 correct (72.60)\n",
      "337 epoch,  1000 iteration, loss:0.078\n",
      " num 336 epoch \n",
      "####### Training Loss #######\n",
      "[0.05807889]\n",
      "Checking accuracy on test set\n",
      "Got 689 / 1000 correct (68.90)\n",
      "338 epoch,   500 iteration, loss:0.082\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "338 epoch,  1000 iteration, loss:0.059\n",
      " num 337 epoch \n",
      "####### Training Loss #######\n",
      "[0.07432479]\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "339 epoch,   500 iteration, loss:0.055\n",
      "Checking accuracy on test set\n",
      "Got 714 / 1000 correct (71.40)\n",
      "339 epoch,  1000 iteration, loss:0.087\n",
      " num 338 epoch \n",
      "####### Training Loss #######\n",
      "[0.06768761]\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "340 epoch,   500 iteration, loss:0.080\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "340 epoch,  1000 iteration, loss:0.059\n",
      " num 339 epoch \n",
      "####### Training Loss #######\n",
      "[0.06753947]\n",
      "Checking accuracy on test set\n",
      "Got 721 / 1000 correct (72.10)\n",
      "341 epoch,   500 iteration, loss:0.055\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "341 epoch,  1000 iteration, loss:0.036\n",
      " num 340 epoch \n",
      "####### Training Loss #######\n",
      "[0.05157843]\n",
      "Checking accuracy on test set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "342 epoch,   500 iteration, loss:0.064\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "342 epoch,  1000 iteration, loss:0.076\n",
      " num 341 epoch \n",
      "####### Training Loss #######\n",
      "[0.06308552]\n",
      "Checking accuracy on test set\n",
      "Got 729 / 1000 correct (72.90)\n",
      "343 epoch,   500 iteration, loss:0.059\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "343 epoch,  1000 iteration, loss:0.098\n",
      " num 342 epoch \n",
      "####### Training Loss #######\n",
      "[0.0731683]\n",
      "Checking accuracy on test set\n",
      "Got 697 / 1000 correct (69.70)\n",
      "344 epoch,   500 iteration, loss:0.059\n",
      "Checking accuracy on test set\n",
      "Got 710 / 1000 correct (71.00)\n",
      "344 epoch,  1000 iteration, loss:0.053\n",
      " num 343 epoch \n",
      "####### Training Loss #######\n",
      "[0.05649379]\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "345 epoch,   500 iteration, loss:0.091\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "345 epoch,  1000 iteration, loss:0.054\n",
      " num 344 epoch \n",
      "####### Training Loss #######\n",
      "[0.06210098]\n",
      "Checking accuracy on test set\n",
      "Got 732 / 1000 correct (73.20)\n",
      "346 epoch,   500 iteration, loss:0.064\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "346 epoch,  1000 iteration, loss:0.038\n",
      " num 345 epoch \n",
      "####### Training Loss #######\n",
      "[0.0491913]\n",
      "Checking accuracy on test set\n",
      "Got 722 / 1000 correct (72.20)\n",
      "347 epoch,   500 iteration, loss:0.094\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "347 epoch,  1000 iteration, loss:0.047\n",
      " num 346 epoch \n",
      "####### Training Loss #######\n",
      "[0.07458432]\n",
      "Checking accuracy on test set\n",
      "Got 713 / 1000 correct (71.30)\n",
      "348 epoch,   500 iteration, loss:0.085\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "348 epoch,  1000 iteration, loss:0.058\n",
      " num 347 epoch \n",
      "####### Training Loss #######\n",
      "[0.06892142]\n",
      "Checking accuracy on test set\n",
      "Got 705 / 1000 correct (70.50)\n",
      "349 epoch,   500 iteration, loss:0.075\n",
      "Checking accuracy on test set\n",
      "Got 701 / 1000 correct (70.10)\n",
      "349 epoch,  1000 iteration, loss:0.067\n",
      " num 348 epoch \n",
      "####### Training Loss #######\n",
      "[0.07460478]\n",
      "Checking accuracy on test set\n",
      "Got 724 / 1000 correct (72.40)\n",
      "350 epoch,   500 iteration, loss:0.058\n",
      "Checking accuracy on test set\n",
      "Got 720 / 1000 correct (72.00)\n",
      "350 epoch,  1000 iteration, loss:0.109\n",
      " num 349 epoch \n",
      "####### Training Loss #######\n",
      "[0.07664737]\n",
      "finish training \n",
      "\n",
      "now begin saving datum for next step plotting\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2350f8fc20b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnet_name2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ConvPool_CNN_C_Class2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m convpool_cnn_c_class2 = running_model_B(run_num, convpool_cnn_c_class2, net_name2, \n\u001b[0;32m----> 3\u001b[0;31m                         lr, epoch, loaderB_train, loaderB_test)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-21ae8620e609>\u001b[0m in \u001b[0;36mrunning_model_B\u001b[0;34m(run_num, net, net_name, lr_list, epoch_list, loader_train, loader_test)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/test_acc.save'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0mcPickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcPickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_acc' is not defined"
     ]
    }
   ],
   "source": [
    "net_name2 = 'ConvPool_CNN_C_Class2'\n",
    "convpool_cnn_c_class2 = running_model_B(run_num, convpool_cnn_c_class2, net_name2, \n",
    "                        lr, epoch, loaderB_train, loaderB_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
