{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import help_func\n",
    "import new_ALL_Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 4\n",
    "test_batch_size = 4\n",
    "\n",
    "NUM_TRAIN = 49000\n",
    "\n",
    "transform = transforms.Compose(\n",
    "          [transforms.ToTensor(),\n",
    "           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "cifar10_train = torchvision.datasets.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = torch.utils.data.DataLoader(cifar10_train, batch_size=train_batch_size, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = torchvision.datasets.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = torch.utils.data.DataLoader(cifar10_val, batch_size=train_batch_size, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "cifar10_test = torchvision.datasets.CIFAR10('./cs231n/datasets', train=False, download=True, \n",
    "                            transform=transform)\n",
    "loader_test = torch.utils.data.DataLoader(cifar10_test, batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALL_CNN_C(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super (ALL_CNN_C, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 96, kernel_size=3, stride=1, padding=1)\n",
    "        nn.init.kaiming_normal_(self.conv1.weight)\n",
    "        nn.init.constant_(self.conv1.bias, 0)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout2d(0.2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(96, 96, kernel_size=3, stride=1, padding=1)\n",
    "        nn.init.kaiming_normal_(self.conv2.weight)\n",
    "        nn.init.constant_(self.conv2.bias, 0)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(96, 96, kernel_size=3, stride=2, padding=0)\n",
    "        nn.init.kaiming_normal_(self.conv3.weight)\n",
    "        nn.init.constant_(self.conv3.bias, 0)\n",
    "        \n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(96, 192, kernel_size=3, stride=1, padding=1)\n",
    "        nn.init.kaiming_normal_(self.conv3.weight)\n",
    "        nn.init.constant_(self.conv3.bias, 0)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(192, 192, kernel_size=3, stride=1, padding=1)\n",
    "        nn.init.kaiming_normal_(self.conv5.weight)\n",
    "        nn.init.constant_(self.conv5.bias, 0)\n",
    "        \n",
    "        self.conv6 = nn.Conv2d(192, 192, kernel_size=3, stride=2, padding=0)\n",
    "        nn.init.kaiming_normal_(self.conv6.weight)\n",
    "        nn.init.constant_(self.conv6.bias, 0)\n",
    "        \n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(192, 192, kernel_size=3, padding=3)\n",
    "        nn.init.kaiming_normal_(self.conv7.weight)\n",
    "        nn.init.constant_(self.conv7.bias, 0)\n",
    "        \n",
    "        self.conv8 = nn.Conv2d(192, 192, kernel_size=1)\n",
    "        nn.init.kaiming_normal_(self.conv8.weight)\n",
    "        nn.init.constant_(self.conv8.bias, 0)\n",
    "        \n",
    "        self.conv9 = nn.Conv2d(192, self.num_classes, kernel_size=1)\n",
    "        nn.init.kaiming_normal_(self.conv9.weight)\n",
    "        nn.init.constant_(self.conv9.bias, 0)\n",
    "        \n",
    "        self.glb_avg = nn.AvgPool2d(6)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = self.dropout1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.dropout2(out)\n",
    "        \n",
    "        out = self.conv4(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.conv5(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.conv6(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.dropout3(out)\n",
    "        \n",
    "        out = self.conv7(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.conv8(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.conv9(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.glb_avg(out)\n",
    "        out = out.view(-1, self.num_classes)\n",
    "        return out\n",
    "orig_all_cnn_c = ALL_CNN_C(num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n",
      "begin training\n",
      "Checking accuracy on validation set\n",
      "Got 220 / 1000 correct (22.00)\n",
      "1 epoch,  1000 iteration, loss:2.222\n",
      "Checking accuracy on validation set\n",
      "Got 241 / 1000 correct (24.10)\n",
      "1 epoch,  2000 iteration, loss:2.159\n",
      "Checking accuracy on validation set\n",
      "Got 258 / 1000 correct (25.80)\n",
      "1 epoch,  3000 iteration, loss:2.078\n",
      "Checking accuracy on validation set\n",
      "Got 262 / 1000 correct (26.20)\n",
      "1 epoch,  4000 iteration, loss:2.004\n",
      "Checking accuracy on validation set\n",
      "Got 322 / 1000 correct (32.20)\n",
      "1 epoch,  5000 iteration, loss:1.937\n",
      "Checking accuracy on validation set\n",
      "Got 325 / 1000 correct (32.50)\n",
      "1 epoch,  6000 iteration, loss:1.918\n",
      "Checking accuracy on validation set\n",
      "Got 372 / 1000 correct (37.20)\n",
      "1 epoch,  7000 iteration, loss:1.838\n",
      "Checking accuracy on validation set\n",
      "Got 397 / 1000 correct (39.70)\n",
      "1 epoch,  8000 iteration, loss:1.764\n",
      "Checking accuracy on validation set\n",
      "Got 393 / 1000 correct (39.30)\n",
      "1 epoch,  9000 iteration, loss:1.718\n",
      "Checking accuracy on validation set\n",
      "Got 371 / 1000 correct (37.10)\n",
      "1 epoch, 10000 iteration, loss:1.673\n",
      "Checking accuracy on validation set\n",
      "Got 434 / 1000 correct (43.40)\n",
      "1 epoch, 11000 iteration, loss:1.641\n",
      "Checking accuracy on validation set\n",
      "Got 461 / 1000 correct (46.10)\n",
      "1 epoch, 12000 iteration, loss:1.615\n",
      " num 0 epoch \n",
      "####### Training Loss #######\n",
      "[1.83899966]\n",
      "Checking accuracy on validation set\n",
      "Got 464 / 1000 correct (46.40)\n",
      "2 epoch,  1000 iteration, loss:1.574\n",
      "Checking accuracy on validation set\n",
      "Got 496 / 1000 correct (49.60)\n",
      "2 epoch,  2000 iteration, loss:1.550\n",
      "Checking accuracy on validation set\n",
      "Got 485 / 1000 correct (48.50)\n",
      "2 epoch,  3000 iteration, loss:1.516\n",
      "Checking accuracy on validation set\n",
      "Got 477 / 1000 correct (47.70)\n",
      "2 epoch,  4000 iteration, loss:1.484\n",
      "Checking accuracy on validation set\n",
      "Got 512 / 1000 correct (51.20)\n",
      "2 epoch,  5000 iteration, loss:1.499\n",
      "Checking accuracy on validation set\n",
      "Got 472 / 1000 correct (47.20)\n",
      "2 epoch,  6000 iteration, loss:1.475\n",
      "Checking accuracy on validation set\n",
      "Got 477 / 1000 correct (47.70)\n",
      "2 epoch,  7000 iteration, loss:1.468\n",
      "Checking accuracy on validation set\n",
      "Got 517 / 1000 correct (51.70)\n",
      "2 epoch,  8000 iteration, loss:1.440\n",
      "Checking accuracy on validation set\n",
      "Got 534 / 1000 correct (53.40)\n",
      "2 epoch,  9000 iteration, loss:1.418\n",
      "Checking accuracy on validation set\n",
      "Got 569 / 1000 correct (56.90)\n",
      "2 epoch, 10000 iteration, loss:1.411\n",
      "Checking accuracy on validation set\n",
      "Got 541 / 1000 correct (54.10)\n",
      "2 epoch, 11000 iteration, loss:1.361\n",
      "Checking accuracy on validation set\n",
      "Got 519 / 1000 correct (51.90)\n",
      "2 epoch, 12000 iteration, loss:1.363\n",
      " num 1 epoch \n",
      "####### Training Loss #######\n",
      "[1.43208899]\n",
      "Checking accuracy on validation set\n",
      "Got 549 / 1000 correct (54.90)\n",
      "3 epoch,  1000 iteration, loss:1.333\n",
      "Checking accuracy on validation set\n",
      "Got 565 / 1000 correct (56.50)\n",
      "3 epoch,  2000 iteration, loss:1.328\n",
      "Checking accuracy on validation set\n",
      "Got 546 / 1000 correct (54.60)\n",
      "3 epoch,  3000 iteration, loss:1.286\n",
      "Checking accuracy on validation set\n",
      "Got 584 / 1000 correct (58.40)\n",
      "3 epoch,  4000 iteration, loss:1.278\n",
      "Checking accuracy on validation set\n",
      "Got 545 / 1000 correct (54.50)\n",
      "3 epoch,  5000 iteration, loss:1.285\n",
      "Checking accuracy on validation set\n",
      "Got 547 / 1000 correct (54.70)\n",
      "3 epoch,  6000 iteration, loss:1.262\n",
      "Checking accuracy on validation set\n",
      "Got 595 / 1000 correct (59.50)\n",
      "3 epoch,  7000 iteration, loss:1.276\n",
      "Checking accuracy on validation set\n",
      "Got 530 / 1000 correct (53.00)\n",
      "3 epoch,  8000 iteration, loss:1.247\n",
      "Checking accuracy on validation set\n",
      "Got 562 / 1000 correct (56.20)\n",
      "3 epoch,  9000 iteration, loss:1.233\n",
      "Checking accuracy on validation set\n",
      "Got 566 / 1000 correct (56.60)\n",
      "3 epoch, 10000 iteration, loss:1.219\n",
      "Checking accuracy on validation set\n",
      "Got 569 / 1000 correct (56.90)\n",
      "3 epoch, 11000 iteration, loss:1.204\n",
      "Checking accuracy on validation set\n",
      "Got 574 / 1000 correct (57.40)\n",
      "3 epoch, 12000 iteration, loss:1.190\n",
      " num 2 epoch \n",
      "####### Training Loss #######\n",
      "[1.23534986]\n",
      "Checking accuracy on validation set\n",
      "Got 635 / 1000 correct (63.50)\n",
      "4 epoch,  1000 iteration, loss:1.191\n",
      "Checking accuracy on validation set\n",
      "Got 599 / 1000 correct (59.90)\n",
      "4 epoch,  2000 iteration, loss:1.160\n",
      "Checking accuracy on validation set\n",
      "Got 611 / 1000 correct (61.10)\n",
      "4 epoch,  3000 iteration, loss:1.140\n",
      "Checking accuracy on validation set\n",
      "Got 653 / 1000 correct (65.30)\n",
      "4 epoch,  4000 iteration, loss:1.137\n",
      "Checking accuracy on validation set\n",
      "Got 618 / 1000 correct (61.80)\n",
      "4 epoch,  5000 iteration, loss:1.120\n",
      "Checking accuracy on validation set\n",
      "Got 633 / 1000 correct (63.30)\n",
      "4 epoch,  6000 iteration, loss:1.115\n",
      "Checking accuracy on validation set\n",
      "Got 617 / 1000 correct (61.70)\n",
      "4 epoch,  7000 iteration, loss:1.112\n",
      "Checking accuracy on validation set\n",
      "Got 643 / 1000 correct (64.30)\n",
      "4 epoch,  8000 iteration, loss:1.119\n",
      "Checking accuracy on validation set\n",
      "Got 625 / 1000 correct (62.50)\n",
      "4 epoch,  9000 iteration, loss:1.110\n",
      "Checking accuracy on validation set\n",
      "Got 638 / 1000 correct (63.80)\n",
      "4 epoch, 10000 iteration, loss:1.093\n",
      "Checking accuracy on validation set\n",
      "Got 649 / 1000 correct (64.90)\n",
      "4 epoch, 11000 iteration, loss:1.119\n",
      "Checking accuracy on validation set\n",
      "Got 637 / 1000 correct (63.70)\n",
      "4 epoch, 12000 iteration, loss:1.051\n",
      " num 3 epoch \n",
      "####### Training Loss #######\n",
      "[1.09844939]\n",
      "Checking accuracy on validation set\n",
      "Got 658 / 1000 correct (65.80)\n",
      "5 epoch,  1000 iteration, loss:1.035\n",
      "Checking accuracy on validation set\n",
      "Got 670 / 1000 correct (67.00)\n",
      "5 epoch,  2000 iteration, loss:1.029\n",
      "Checking accuracy on validation set\n",
      "Got 650 / 1000 correct (65.00)\n",
      "5 epoch,  3000 iteration, loss:1.029\n",
      "Checking accuracy on validation set\n",
      "Got 669 / 1000 correct (66.90)\n",
      "5 epoch,  4000 iteration, loss:1.047\n",
      "Checking accuracy on validation set\n",
      "Got 642 / 1000 correct (64.20)\n",
      "5 epoch,  5000 iteration, loss:0.990\n",
      "Checking accuracy on validation set\n",
      "Got 642 / 1000 correct (64.20)\n",
      "5 epoch,  6000 iteration, loss:1.039\n",
      "Checking accuracy on validation set\n",
      "Got 678 / 1000 correct (67.80)\n",
      "5 epoch,  7000 iteration, loss:1.013\n",
      "Checking accuracy on validation set\n",
      "Got 659 / 1000 correct (65.90)\n",
      "5 epoch,  8000 iteration, loss:0.997\n",
      "Checking accuracy on validation set\n",
      "Got 650 / 1000 correct (65.00)\n",
      "5 epoch,  9000 iteration, loss:1.008\n",
      "Checking accuracy on validation set\n",
      "Got 671 / 1000 correct (67.10)\n",
      "5 epoch, 10000 iteration, loss:1.000\n",
      "Checking accuracy on validation set\n",
      "Got 670 / 1000 correct (67.00)\n",
      "5 epoch, 11000 iteration, loss:1.002\n",
      "Checking accuracy on validation set\n",
      "Got 673 / 1000 correct (67.30)\n",
      "5 epoch, 12000 iteration, loss:0.998\n",
      " num 4 epoch \n",
      "####### Training Loss #######\n",
      "[0.99389315]\n",
      "Checking accuracy on validation set\n",
      "Got 663 / 1000 correct (66.30)\n",
      "6 epoch,  1000 iteration, loss:0.957\n",
      "Checking accuracy on validation set\n",
      "Got 655 / 1000 correct (65.50)\n",
      "6 epoch,  2000 iteration, loss:0.940\n",
      "Checking accuracy on validation set\n",
      "Got 694 / 1000 correct (69.40)\n",
      "6 epoch,  3000 iteration, loss:0.961\n",
      "Checking accuracy on validation set\n",
      "Got 692 / 1000 correct (69.20)\n",
      "6 epoch,  4000 iteration, loss:0.983\n",
      "Checking accuracy on validation set\n",
      "Got 708 / 1000 correct (70.80)\n",
      "6 epoch,  5000 iteration, loss:0.940\n",
      "Checking accuracy on validation set\n",
      "Got 713 / 1000 correct (71.30)\n",
      "6 epoch,  6000 iteration, loss:0.927\n",
      "Checking accuracy on validation set\n",
      "Got 699 / 1000 correct (69.90)\n",
      "6 epoch,  7000 iteration, loss:0.958\n",
      "Checking accuracy on validation set\n",
      "Got 682 / 1000 correct (68.20)\n",
      "6 epoch,  8000 iteration, loss:0.927\n",
      "Checking accuracy on validation set\n",
      "Got 699 / 1000 correct (69.90)\n",
      "6 epoch,  9000 iteration, loss:0.948\n",
      "Checking accuracy on validation set\n",
      "Got 692 / 1000 correct (69.20)\n",
      "6 epoch, 10000 iteration, loss:0.914\n",
      "Checking accuracy on validation set\n",
      "Got 713 / 1000 correct (71.30)\n",
      "6 epoch, 11000 iteration, loss:0.943\n",
      "Checking accuracy on validation set\n",
      "Got 691 / 1000 correct (69.10)\n",
      "6 epoch, 12000 iteration, loss:0.911\n",
      " num 5 epoch \n",
      "####### Training Loss #######\n",
      "[0.92302945]\n",
      "Checking accuracy on validation set\n",
      "Got 682 / 1000 correct (68.20)\n",
      "7 epoch,  1000 iteration, loss:0.894\n",
      "Checking accuracy on validation set\n",
      "Got 697 / 1000 correct (69.70)\n",
      "7 epoch,  2000 iteration, loss:0.879\n",
      "Checking accuracy on validation set\n",
      "Got 704 / 1000 correct (70.40)\n",
      "7 epoch,  3000 iteration, loss:0.894\n",
      "Checking accuracy on validation set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 699 / 1000 correct (69.90)\n",
      "7 epoch,  4000 iteration, loss:0.898\n",
      "Checking accuracy on validation set\n",
      "Got 714 / 1000 correct (71.40)\n",
      "7 epoch,  5000 iteration, loss:0.875\n",
      "Checking accuracy on validation set\n",
      "Got 678 / 1000 correct (67.80)\n",
      "7 epoch,  6000 iteration, loss:0.896\n",
      "Checking accuracy on validation set\n",
      "Got 717 / 1000 correct (71.70)\n",
      "7 epoch,  7000 iteration, loss:0.883\n",
      "Checking accuracy on validation set\n",
      "Got 701 / 1000 correct (70.10)\n",
      "7 epoch,  8000 iteration, loss:0.880\n",
      "Checking accuracy on validation set\n",
      "Got 686 / 1000 correct (68.60)\n",
      "7 epoch,  9000 iteration, loss:0.873\n",
      "Checking accuracy on validation set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "7 epoch, 10000 iteration, loss:0.873\n",
      "Checking accuracy on validation set\n",
      "Got 694 / 1000 correct (69.40)\n",
      "7 epoch, 11000 iteration, loss:0.874\n",
      "Checking accuracy on validation set\n",
      "Got 732 / 1000 correct (73.20)\n",
      "7 epoch, 12000 iteration, loss:0.880\n",
      " num 6 epoch \n",
      "####### Training Loss #######\n",
      "[0.86412588]\n",
      "Checking accuracy on validation set\n",
      "Got 726 / 1000 correct (72.60)\n",
      "8 epoch,  1000 iteration, loss:0.835\n",
      "Checking accuracy on validation set\n",
      "Got 706 / 1000 correct (70.60)\n",
      "8 epoch,  2000 iteration, loss:0.817\n",
      "Checking accuracy on validation set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "8 epoch,  3000 iteration, loss:0.803\n",
      "Checking accuracy on validation set\n",
      "Got 713 / 1000 correct (71.30)\n",
      "8 epoch,  4000 iteration, loss:0.836\n",
      "Checking accuracy on validation set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "8 epoch,  5000 iteration, loss:0.858\n",
      "Checking accuracy on validation set\n",
      "Got 713 / 1000 correct (71.30)\n",
      "8 epoch,  6000 iteration, loss:0.827\n",
      "Checking accuracy on validation set\n",
      "Got 699 / 1000 correct (69.90)\n",
      "8 epoch,  7000 iteration, loss:0.835\n",
      "Checking accuracy on validation set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "8 epoch,  8000 iteration, loss:0.820\n",
      "Checking accuracy on validation set\n",
      "Got 727 / 1000 correct (72.70)\n",
      "8 epoch,  9000 iteration, loss:0.836\n",
      "Checking accuracy on validation set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "8 epoch, 10000 iteration, loss:0.830\n",
      "Checking accuracy on validation set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "8 epoch, 11000 iteration, loss:0.804\n",
      "Checking accuracy on validation set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "8 epoch, 12000 iteration, loss:0.821\n",
      " num 7 epoch \n",
      "####### Training Loss #######\n",
      "[0.81009663]\n",
      "Checking accuracy on validation set\n",
      "Got 704 / 1000 correct (70.40)\n",
      "9 epoch,  1000 iteration, loss:0.778\n",
      "Checking accuracy on validation set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "9 epoch,  2000 iteration, loss:0.801\n",
      "Checking accuracy on validation set\n",
      "Got 708 / 1000 correct (70.80)\n",
      "9 epoch,  3000 iteration, loss:0.776\n",
      "Checking accuracy on validation set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "9 epoch,  4000 iteration, loss:0.772\n",
      "Checking accuracy on validation set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "9 epoch,  5000 iteration, loss:0.818\n",
      "Checking accuracy on validation set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "9 epoch,  6000 iteration, loss:0.785\n",
      "Checking accuracy on validation set\n",
      "Got 759 / 1000 correct (75.90)\n",
      "9 epoch,  7000 iteration, loss:0.768\n",
      "Checking accuracy on validation set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "9 epoch,  8000 iteration, loss:0.789\n",
      "Checking accuracy on validation set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "9 epoch,  9000 iteration, loss:0.788\n",
      "Checking accuracy on validation set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "9 epoch, 10000 iteration, loss:0.806\n",
      "Checking accuracy on validation set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "9 epoch, 11000 iteration, loss:0.775\n",
      "Checking accuracy on validation set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "9 epoch, 12000 iteration, loss:0.786\n",
      " num 8 epoch \n",
      "####### Training Loss #######\n",
      "[0.77077825]\n",
      "Checking accuracy on validation set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "10 epoch,  1000 iteration, loss:0.719\n",
      "Checking accuracy on validation set\n",
      "Got 767 / 1000 correct (76.70)\n",
      "10 epoch,  2000 iteration, loss:0.747\n",
      "Checking accuracy on validation set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "10 epoch,  3000 iteration, loss:0.770\n",
      "Checking accuracy on validation set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "10 epoch,  4000 iteration, loss:0.747\n",
      "Checking accuracy on validation set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "10 epoch,  5000 iteration, loss:0.756\n",
      "Checking accuracy on validation set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "10 epoch,  6000 iteration, loss:0.763\n",
      "Checking accuracy on validation set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "10 epoch,  7000 iteration, loss:0.760\n",
      "Checking accuracy on validation set\n",
      "Got 765 / 1000 correct (76.50)\n",
      "10 epoch,  8000 iteration, loss:0.734\n",
      "Checking accuracy on validation set\n",
      "Got 719 / 1000 correct (71.90)\n",
      "10 epoch,  9000 iteration, loss:0.724\n",
      "Checking accuracy on validation set\n",
      "Got 761 / 1000 correct (76.10)\n",
      "10 epoch, 10000 iteration, loss:0.758\n",
      "Checking accuracy on validation set\n",
      "Got 770 / 1000 correct (77.00)\n",
      "10 epoch, 11000 iteration, loss:0.755\n",
      "Checking accuracy on validation set\n",
      "Got 760 / 1000 correct (76.00)\n",
      "10 epoch, 12000 iteration, loss:0.751\n",
      " num 9 epoch \n",
      "####### Training Loss #######\n",
      "[0.73266542]\n",
      "Checking accuracy on validation set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "11 epoch,  1000 iteration, loss:0.707\n",
      "Checking accuracy on validation set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "11 epoch,  2000 iteration, loss:0.718\n",
      "Checking accuracy on validation set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "11 epoch,  3000 iteration, loss:0.703\n",
      "Checking accuracy on validation set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "11 epoch,  4000 iteration, loss:0.736\n",
      "Checking accuracy on validation set\n",
      "Got 777 / 1000 correct (77.70)\n",
      "11 epoch,  5000 iteration, loss:0.728\n",
      "Checking accuracy on validation set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "11 epoch,  6000 iteration, loss:0.738\n",
      "Checking accuracy on validation set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "11 epoch,  7000 iteration, loss:0.692\n",
      "Checking accuracy on validation set\n",
      "Got 773 / 1000 correct (77.30)\n",
      "11 epoch,  8000 iteration, loss:0.730\n",
      "Checking accuracy on validation set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "11 epoch,  9000 iteration, loss:0.727\n",
      "Checking accuracy on validation set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "11 epoch, 10000 iteration, loss:0.685\n",
      "Checking accuracy on validation set\n",
      "Got 773 / 1000 correct (77.30)\n",
      "11 epoch, 11000 iteration, loss:0.698\n",
      "Checking accuracy on validation set\n",
      "Got 778 / 1000 correct (77.80)\n",
      "11 epoch, 12000 iteration, loss:0.742\n",
      " num 10 epoch \n",
      "####### Training Loss #######\n",
      "[0.70284759]\n",
      "Checking accuracy on validation set\n",
      "Got 759 / 1000 correct (75.90)\n",
      "12 epoch,  1000 iteration, loss:0.677\n",
      "Checking accuracy on validation set\n",
      "Got 762 / 1000 correct (76.20)\n",
      "12 epoch,  2000 iteration, loss:0.652\n",
      "Checking accuracy on validation set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "12 epoch,  3000 iteration, loss:0.682\n",
      "Checking accuracy on validation set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "12 epoch,  4000 iteration, loss:0.680\n",
      "Checking accuracy on validation set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "12 epoch,  5000 iteration, loss:0.711\n",
      "Checking accuracy on validation set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "12 epoch,  6000 iteration, loss:0.719\n",
      "Checking accuracy on validation set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "12 epoch,  7000 iteration, loss:0.690\n",
      "Checking accuracy on validation set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "12 epoch,  8000 iteration, loss:0.706\n",
      "Checking accuracy on validation set\n",
      "Got 775 / 1000 correct (77.50)\n",
      "12 epoch,  9000 iteration, loss:0.690\n",
      "Checking accuracy on validation set\n",
      "Got 761 / 1000 correct (76.10)\n",
      "12 epoch, 10000 iteration, loss:0.699\n",
      "Checking accuracy on validation set\n",
      "Got 767 / 1000 correct (76.70)\n",
      "12 epoch, 11000 iteration, loss:0.707\n",
      "Checking accuracy on validation set\n",
      "Got 771 / 1000 correct (77.10)\n",
      "12 epoch, 12000 iteration, loss:0.701\n",
      " num 11 epoch \n",
      "####### Training Loss #######\n",
      "[0.67964629]\n",
      "Checking accuracy on validation set\n",
      "Got 754 / 1000 correct (75.40)\n",
      "13 epoch,  1000 iteration, loss:0.641\n",
      "Checking accuracy on validation set\n",
      "Got 759 / 1000 correct (75.90)\n",
      "13 epoch,  2000 iteration, loss:0.683\n",
      "Checking accuracy on validation set\n",
      "Got 771 / 1000 correct (77.10)\n",
      "13 epoch,  3000 iteration, loss:0.646\n",
      "Checking accuracy on validation set\n",
      "Got 796 / 1000 correct (79.60)\n",
      "13 epoch,  4000 iteration, loss:0.647\n",
      "Checking accuracy on validation set\n",
      "Got 783 / 1000 correct (78.30)\n",
      "13 epoch,  5000 iteration, loss:0.678\n",
      "Checking accuracy on validation set\n",
      "Got 767 / 1000 correct (76.70)\n",
      "13 epoch,  6000 iteration, loss:0.676\n",
      "Checking accuracy on validation set\n",
      "Got 785 / 1000 correct (78.50)\n",
      "13 epoch,  7000 iteration, loss:0.674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 795 / 1000 correct (79.50)\n",
      "13 epoch,  8000 iteration, loss:0.647\n",
      "Checking accuracy on validation set\n",
      "Got 788 / 1000 correct (78.80)\n",
      "13 epoch,  9000 iteration, loss:0.686\n",
      "Checking accuracy on validation set\n",
      "Got 775 / 1000 correct (77.50)\n",
      "13 epoch, 10000 iteration, loss:0.680\n",
      "Checking accuracy on validation set\n",
      "Got 769 / 1000 correct (76.90)\n",
      "13 epoch, 11000 iteration, loss:0.678\n",
      "Checking accuracy on validation set\n",
      "Got 782 / 1000 correct (78.20)\n",
      "13 epoch, 12000 iteration, loss:0.678\n",
      " num 12 epoch \n",
      "####### Training Loss #######\n",
      "[0.65513467]\n",
      "Checking accuracy on validation set\n",
      "Got 789 / 1000 correct (78.90)\n",
      "14 epoch,  1000 iteration, loss:0.641\n",
      "Checking accuracy on validation set\n",
      "Got 777 / 1000 correct (77.70)\n",
      "14 epoch,  2000 iteration, loss:0.611\n",
      "Checking accuracy on validation set\n",
      "Got 797 / 1000 correct (79.70)\n",
      "14 epoch,  3000 iteration, loss:0.661\n",
      "Checking accuracy on validation set\n",
      "Got 789 / 1000 correct (78.90)\n",
      "14 epoch,  4000 iteration, loss:0.646\n",
      "Checking accuracy on validation set\n",
      "Got 777 / 1000 correct (77.70)\n",
      "14 epoch,  5000 iteration, loss:0.639\n",
      "Checking accuracy on validation set\n",
      "Got 781 / 1000 correct (78.10)\n",
      "14 epoch,  6000 iteration, loss:0.657\n",
      "Checking accuracy on validation set\n",
      "Got 767 / 1000 correct (76.70)\n",
      "14 epoch,  7000 iteration, loss:0.650\n",
      "Checking accuracy on validation set\n",
      "Got 765 / 1000 correct (76.50)\n",
      "14 epoch,  8000 iteration, loss:0.664\n",
      "Checking accuracy on validation set\n",
      "Got 769 / 1000 correct (76.90)\n",
      "14 epoch,  9000 iteration, loss:0.656\n",
      "Checking accuracy on validation set\n",
      "Got 794 / 1000 correct (79.40)\n",
      "14 epoch, 10000 iteration, loss:0.653\n",
      "Checking accuracy on validation set\n",
      "Got 799 / 1000 correct (79.90)\n",
      "14 epoch, 11000 iteration, loss:0.626\n",
      "Checking accuracy on validation set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "14 epoch, 12000 iteration, loss:0.669\n",
      " num 13 epoch \n",
      "####### Training Loss #######\n",
      "[0.63589244]\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "15 epoch,  1000 iteration, loss:0.598\n",
      "Checking accuracy on validation set\n",
      "Got 788 / 1000 correct (78.80)\n",
      "15 epoch,  2000 iteration, loss:0.628\n",
      "Checking accuracy on validation set\n",
      "Got 794 / 1000 correct (79.40)\n",
      "15 epoch,  3000 iteration, loss:0.620\n",
      "Checking accuracy on validation set\n",
      "Got 792 / 1000 correct (79.20)\n",
      "15 epoch,  4000 iteration, loss:0.643\n",
      "Checking accuracy on validation set\n",
      "Got 777 / 1000 correct (77.70)\n",
      "15 epoch,  5000 iteration, loss:0.623\n",
      "Checking accuracy on validation set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "15 epoch,  6000 iteration, loss:0.646\n",
      "Checking accuracy on validation set\n",
      "Got 786 / 1000 correct (78.60)\n",
      "15 epoch,  7000 iteration, loss:0.601\n",
      "Checking accuracy on validation set\n",
      "Got 794 / 1000 correct (79.40)\n",
      "15 epoch,  8000 iteration, loss:0.644\n",
      "Checking accuracy on validation set\n",
      "Got 774 / 1000 correct (77.40)\n",
      "15 epoch,  9000 iteration, loss:0.618\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "15 epoch, 10000 iteration, loss:0.643\n",
      "Checking accuracy on validation set\n",
      "Got 793 / 1000 correct (79.30)\n",
      "15 epoch, 11000 iteration, loss:0.646\n",
      "Checking accuracy on validation set\n",
      "Got 778 / 1000 correct (77.80)\n",
      "15 epoch, 12000 iteration, loss:0.636\n",
      " num 14 epoch \n",
      "####### Training Loss #######\n",
      "[0.61662629]\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10)\n",
      "16 epoch,  1000 iteration, loss:0.589\n",
      "Checking accuracy on validation set\n",
      "Got 792 / 1000 correct (79.20)\n",
      "16 epoch,  2000 iteration, loss:0.595\n",
      "Checking accuracy on validation set\n",
      "Got 773 / 1000 correct (77.30)\n",
      "16 epoch,  3000 iteration, loss:0.601\n",
      "Checking accuracy on validation set\n",
      "Got 770 / 1000 correct (77.00)\n",
      "16 epoch,  4000 iteration, loss:0.624\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "16 epoch,  5000 iteration, loss:0.612\n",
      "Checking accuracy on validation set\n",
      "Got 786 / 1000 correct (78.60)\n",
      "16 epoch,  6000 iteration, loss:0.609\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "16 epoch,  7000 iteration, loss:0.631\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "16 epoch,  8000 iteration, loss:0.618\n",
      "Checking accuracy on validation set\n",
      "Got 778 / 1000 correct (77.80)\n",
      "16 epoch,  9000 iteration, loss:0.597\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "16 epoch, 10000 iteration, loss:0.638\n",
      "Checking accuracy on validation set\n",
      "Got 787 / 1000 correct (78.70)\n",
      "16 epoch, 11000 iteration, loss:0.591\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "16 epoch, 12000 iteration, loss:0.616\n",
      " num 15 epoch \n",
      "####### Training Loss #######\n",
      "[0.59925644]\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "17 epoch,  1000 iteration, loss:0.578\n",
      "Checking accuracy on validation set\n",
      "Got 788 / 1000 correct (78.80)\n",
      "17 epoch,  2000 iteration, loss:0.590\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "17 epoch,  3000 iteration, loss:0.592\n",
      "Checking accuracy on validation set\n",
      "Got 783 / 1000 correct (78.30)\n",
      "17 epoch,  4000 iteration, loss:0.611\n",
      "Checking accuracy on validation set\n",
      "Got 779 / 1000 correct (77.90)\n",
      "17 epoch,  5000 iteration, loss:0.605\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "17 epoch,  6000 iteration, loss:0.594\n",
      "Checking accuracy on validation set\n",
      "Got 797 / 1000 correct (79.70)\n",
      "17 epoch,  7000 iteration, loss:0.612\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "17 epoch,  8000 iteration, loss:0.602\n",
      "Checking accuracy on validation set\n",
      "Got 774 / 1000 correct (77.40)\n",
      "17 epoch,  9000 iteration, loss:0.570\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "17 epoch, 10000 iteration, loss:0.598\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "17 epoch, 11000 iteration, loss:0.614\n",
      "Checking accuracy on validation set\n",
      "Got 773 / 1000 correct (77.30)\n",
      "17 epoch, 12000 iteration, loss:0.598\n",
      " num 16 epoch \n",
      "####### Training Loss #######\n",
      "[0.58654156]\n",
      "Checking accuracy on validation set\n",
      "Got 788 / 1000 correct (78.80)\n",
      "18 epoch,  1000 iteration, loss:0.564\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "18 epoch,  2000 iteration, loss:0.566\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "18 epoch,  3000 iteration, loss:0.560\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "18 epoch,  4000 iteration, loss:0.564\n",
      "Checking accuracy on validation set\n",
      "Got 787 / 1000 correct (78.70)\n",
      "18 epoch,  5000 iteration, loss:0.603\n",
      "Checking accuracy on validation set\n",
      "Got 780 / 1000 correct (78.00)\n",
      "18 epoch,  6000 iteration, loss:0.575\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "18 epoch,  7000 iteration, loss:0.564\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "18 epoch,  8000 iteration, loss:0.592\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "18 epoch,  9000 iteration, loss:0.612\n",
      "Checking accuracy on validation set\n",
      "Got 767 / 1000 correct (76.70)\n",
      "18 epoch, 10000 iteration, loss:0.601\n",
      "Checking accuracy on validation set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "18 epoch, 11000 iteration, loss:0.603\n",
      "Checking accuracy on validation set\n",
      "Got 792 / 1000 correct (79.20)\n",
      "18 epoch, 12000 iteration, loss:0.602\n",
      " num 17 epoch \n",
      "####### Training Loss #######\n",
      "[0.5730414]\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "19 epoch,  1000 iteration, loss:0.553\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "19 epoch,  2000 iteration, loss:0.551\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "19 epoch,  3000 iteration, loss:0.551\n",
      "Checking accuracy on validation set\n",
      "Got 798 / 1000 correct (79.80)\n",
      "19 epoch,  4000 iteration, loss:0.564\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "19 epoch,  5000 iteration, loss:0.562\n",
      "Checking accuracy on validation set\n",
      "Got 792 / 1000 correct (79.20)\n",
      "19 epoch,  6000 iteration, loss:0.593\n",
      "Checking accuracy on validation set\n",
      "Got 791 / 1000 correct (79.10)\n",
      "19 epoch,  7000 iteration, loss:0.587\n",
      "Checking accuracy on validation set\n",
      "Got 800 / 1000 correct (80.00)\n",
      "19 epoch,  8000 iteration, loss:0.584\n",
      "Checking accuracy on validation set\n",
      "Got 805 / 1000 correct (80.50)\n",
      "19 epoch,  9000 iteration, loss:0.574\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "19 epoch, 10000 iteration, loss:0.590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 770 / 1000 correct (77.00)\n",
      "19 epoch, 11000 iteration, loss:0.566\n",
      "Checking accuracy on validation set\n",
      "Got 794 / 1000 correct (79.40)\n",
      "19 epoch, 12000 iteration, loss:0.559\n",
      " num 18 epoch \n",
      "####### Training Loss #######\n",
      "[0.55773828]\n",
      "Checking accuracy on validation set\n",
      "Got 805 / 1000 correct (80.50)\n",
      "20 epoch,  1000 iteration, loss:0.535\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "20 epoch,  2000 iteration, loss:0.539\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "20 epoch,  3000 iteration, loss:0.558\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "20 epoch,  4000 iteration, loss:0.562\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "20 epoch,  5000 iteration, loss:0.552\n",
      "Checking accuracy on validation set\n",
      "Got 790 / 1000 correct (79.00)\n",
      "20 epoch,  6000 iteration, loss:0.570\n",
      "Checking accuracy on validation set\n",
      "Got 799 / 1000 correct (79.90)\n",
      "20 epoch,  7000 iteration, loss:0.571\n",
      "Checking accuracy on validation set\n",
      "Got 789 / 1000 correct (78.90)\n",
      "20 epoch,  8000 iteration, loss:0.572\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "20 epoch,  9000 iteration, loss:0.594\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "20 epoch, 10000 iteration, loss:0.560\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "20 epoch, 11000 iteration, loss:0.568\n",
      "Checking accuracy on validation set\n",
      "Got 800 / 1000 correct (80.00)\n",
      "20 epoch, 12000 iteration, loss:0.570\n",
      " num 19 epoch \n",
      "####### Training Loss #######\n",
      "[0.55173154]\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "21 epoch,  1000 iteration, loss:0.516\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "21 epoch,  2000 iteration, loss:0.547\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "21 epoch,  3000 iteration, loss:0.559\n",
      "Checking accuracy on validation set\n",
      "Got 795 / 1000 correct (79.50)\n",
      "21 epoch,  4000 iteration, loss:0.539\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10)\n",
      "21 epoch,  5000 iteration, loss:0.542\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "21 epoch,  6000 iteration, loss:0.529\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "21 epoch,  7000 iteration, loss:0.567\n",
      "Checking accuracy on validation set\n",
      "Got 800 / 1000 correct (80.00)\n",
      "21 epoch,  8000 iteration, loss:0.549\n",
      "Checking accuracy on validation set\n",
      "Got 759 / 1000 correct (75.90)\n",
      "21 epoch,  9000 iteration, loss:0.551\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "21 epoch, 10000 iteration, loss:0.534\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "21 epoch, 11000 iteration, loss:0.542\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "21 epoch, 12000 iteration, loss:0.586\n",
      " num 20 epoch \n",
      "####### Training Loss #######\n",
      "[0.53497672]\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "22 epoch,  1000 iteration, loss:0.519\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "22 epoch,  2000 iteration, loss:0.535\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "22 epoch,  3000 iteration, loss:0.525\n",
      "Checking accuracy on validation set\n",
      "Got 794 / 1000 correct (79.40)\n",
      "22 epoch,  4000 iteration, loss:0.540\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "22 epoch,  5000 iteration, loss:0.517\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "22 epoch,  6000 iteration, loss:0.555\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "22 epoch,  7000 iteration, loss:0.548\n",
      "Checking accuracy on validation set\n",
      "Got 795 / 1000 correct (79.50)\n",
      "22 epoch,  8000 iteration, loss:0.525\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "22 epoch,  9000 iteration, loss:0.546\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10)\n",
      "22 epoch, 10000 iteration, loss:0.547\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "22 epoch, 11000 iteration, loss:0.551\n",
      "Checking accuracy on validation set\n",
      "Got 790 / 1000 correct (79.00)\n",
      "22 epoch, 12000 iteration, loss:0.566\n",
      " num 21 epoch \n",
      "####### Training Loss #######\n",
      "[0.52972744]\n",
      "Checking accuracy on validation set\n",
      "Got 799 / 1000 correct (79.90)\n",
      "23 epoch,  1000 iteration, loss:0.474\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "23 epoch,  2000 iteration, loss:0.506\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "23 epoch,  3000 iteration, loss:0.538\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "23 epoch,  4000 iteration, loss:0.538\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "23 epoch,  5000 iteration, loss:0.540\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "23 epoch,  6000 iteration, loss:0.527\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "23 epoch,  7000 iteration, loss:0.516\n",
      "Checking accuracy on validation set\n",
      "Got 787 / 1000 correct (78.70)\n",
      "23 epoch,  8000 iteration, loss:0.536\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "23 epoch,  9000 iteration, loss:0.535\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10)\n",
      "23 epoch, 10000 iteration, loss:0.537\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "23 epoch, 11000 iteration, loss:0.553\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "23 epoch, 12000 iteration, loss:0.529\n",
      " num 22 epoch \n",
      "####### Training Loss #######\n",
      "[0.51692293]\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "24 epoch,  1000 iteration, loss:0.484\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "24 epoch,  2000 iteration, loss:0.512\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "24 epoch,  3000 iteration, loss:0.516\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "24 epoch,  4000 iteration, loss:0.516\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "24 epoch,  5000 iteration, loss:0.523\n",
      "Checking accuracy on validation set\n",
      "Got 802 / 1000 correct (80.20)\n",
      "24 epoch,  6000 iteration, loss:0.519\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "24 epoch,  7000 iteration, loss:0.533\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "24 epoch,  8000 iteration, loss:0.498\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "24 epoch,  9000 iteration, loss:0.539\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "24 epoch, 10000 iteration, loss:0.531\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "24 epoch, 11000 iteration, loss:0.515\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "24 epoch, 12000 iteration, loss:0.530\n",
      " num 23 epoch \n",
      "####### Training Loss #######\n",
      "[0.50821792]\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "25 epoch,  1000 iteration, loss:0.487\n",
      "Checking accuracy on validation set\n",
      "Got 800 / 1000 correct (80.00)\n",
      "25 epoch,  2000 iteration, loss:0.486\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "25 epoch,  3000 iteration, loss:0.499\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "25 epoch,  4000 iteration, loss:0.507\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "25 epoch,  5000 iteration, loss:0.495\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "25 epoch,  6000 iteration, loss:0.527\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "25 epoch,  7000 iteration, loss:0.524\n",
      "Checking accuracy on validation set\n",
      "Got 793 / 1000 correct (79.30)\n",
      "25 epoch,  8000 iteration, loss:0.541\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "25 epoch,  9000 iteration, loss:0.503\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "25 epoch, 10000 iteration, loss:0.546\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "25 epoch, 11000 iteration, loss:0.519\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30)\n",
      "25 epoch, 12000 iteration, loss:0.539\n",
      " num 24 epoch \n",
      "####### Training Loss #######\n",
      "[0.50489261]\n",
      "Checking accuracy on validation set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 844 / 1000 correct (84.40)\n",
      "26 epoch,  1000 iteration, loss:0.497\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "26 epoch,  2000 iteration, loss:0.500\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "26 epoch,  3000 iteration, loss:0.487\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "26 epoch,  4000 iteration, loss:0.492\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "26 epoch,  5000 iteration, loss:0.497\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "26 epoch,  6000 iteration, loss:0.527\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "26 epoch,  7000 iteration, loss:0.516\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "26 epoch,  8000 iteration, loss:0.485\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "26 epoch,  9000 iteration, loss:0.507\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "26 epoch, 10000 iteration, loss:0.501\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "26 epoch, 11000 iteration, loss:0.499\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "26 epoch, 12000 iteration, loss:0.501\n",
      " num 25 epoch \n",
      "####### Training Loss #######\n",
      "[0.49115763]\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "27 epoch,  1000 iteration, loss:0.489\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "27 epoch,  2000 iteration, loss:0.490\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "27 epoch,  3000 iteration, loss:0.496\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "27 epoch,  4000 iteration, loss:0.482\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "27 epoch,  5000 iteration, loss:0.489\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "27 epoch,  6000 iteration, loss:0.492\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "27 epoch,  7000 iteration, loss:0.501\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "27 epoch,  8000 iteration, loss:0.494\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "27 epoch,  9000 iteration, loss:0.508\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "27 epoch, 10000 iteration, loss:0.491\n",
      "Checking accuracy on validation set\n",
      "Got 799 / 1000 correct (79.90)\n",
      "27 epoch, 11000 iteration, loss:0.501\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "27 epoch, 12000 iteration, loss:0.498\n",
      " num 26 epoch \n",
      "####### Training Loss #######\n",
      "[0.48435243]\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "28 epoch,  1000 iteration, loss:0.469\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "28 epoch,  2000 iteration, loss:0.475\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "28 epoch,  3000 iteration, loss:0.472\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "28 epoch,  4000 iteration, loss:0.488\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "28 epoch,  5000 iteration, loss:0.490\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "28 epoch,  6000 iteration, loss:0.488\n",
      "Checking accuracy on validation set\n",
      "Got 800 / 1000 correct (80.00)\n",
      "28 epoch,  7000 iteration, loss:0.486\n",
      "Checking accuracy on validation set\n",
      "Got 780 / 1000 correct (78.00)\n",
      "28 epoch,  8000 iteration, loss:0.497\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "28 epoch,  9000 iteration, loss:0.470\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "28 epoch, 10000 iteration, loss:0.494\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "28 epoch, 11000 iteration, loss:0.519\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "28 epoch, 12000 iteration, loss:0.514\n",
      " num 27 epoch \n",
      "####### Training Loss #######\n",
      "[0.47955565]\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "29 epoch,  1000 iteration, loss:0.461\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "29 epoch,  2000 iteration, loss:0.459\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "29 epoch,  3000 iteration, loss:0.466\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "29 epoch,  4000 iteration, loss:0.475\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "29 epoch,  5000 iteration, loss:0.455\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "29 epoch,  6000 iteration, loss:0.496\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "29 epoch,  7000 iteration, loss:0.490\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "29 epoch,  8000 iteration, loss:0.494\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "29 epoch,  9000 iteration, loss:0.490\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "29 epoch, 10000 iteration, loss:0.487\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "29 epoch, 11000 iteration, loss:0.503\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "29 epoch, 12000 iteration, loss:0.500\n",
      " num 28 epoch \n",
      "####### Training Loss #######\n",
      "[0.47208706]\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "30 epoch,  1000 iteration, loss:0.462\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "30 epoch,  2000 iteration, loss:0.462\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "30 epoch,  3000 iteration, loss:0.456\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "30 epoch,  4000 iteration, loss:0.473\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "30 epoch,  5000 iteration, loss:0.468\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "30 epoch,  6000 iteration, loss:0.474\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "30 epoch,  7000 iteration, loss:0.464\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "30 epoch,  8000 iteration, loss:0.487\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "30 epoch,  9000 iteration, loss:0.473\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "30 epoch, 10000 iteration, loss:0.516\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "30 epoch, 11000 iteration, loss:0.489\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "30 epoch, 12000 iteration, loss:0.504\n",
      " num 29 epoch \n",
      "####### Training Loss #######\n",
      "[0.46794663]\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "31 epoch,  1000 iteration, loss:0.431\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "31 epoch,  2000 iteration, loss:0.442\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "31 epoch,  3000 iteration, loss:0.462\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "31 epoch,  4000 iteration, loss:0.429\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "31 epoch,  5000 iteration, loss:0.448\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "31 epoch,  6000 iteration, loss:0.473\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "31 epoch,  7000 iteration, loss:0.485\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "31 epoch,  8000 iteration, loss:0.470\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "31 epoch,  9000 iteration, loss:0.495\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "31 epoch, 10000 iteration, loss:0.498\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "31 epoch, 11000 iteration, loss:0.489\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "31 epoch, 12000 iteration, loss:0.482\n",
      " num 30 epoch \n",
      "####### Training Loss #######\n",
      "[0.45757952]\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "32 epoch,  1000 iteration, loss:0.435\n",
      "Checking accuracy on validation set\n",
      "Got 788 / 1000 correct (78.80)\n",
      "32 epoch,  2000 iteration, loss:0.456\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "32 epoch,  3000 iteration, loss:0.467\n",
      "Checking accuracy on validation set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 796 / 1000 correct (79.60)\n",
      "32 epoch,  4000 iteration, loss:0.465\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "32 epoch,  5000 iteration, loss:0.467\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "32 epoch,  6000 iteration, loss:0.460\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "32 epoch,  7000 iteration, loss:0.478\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "32 epoch,  8000 iteration, loss:0.465\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "32 epoch,  9000 iteration, loss:0.450\n",
      "Checking accuracy on validation set\n",
      "Got 799 / 1000 correct (79.90)\n",
      "32 epoch, 10000 iteration, loss:0.483\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "32 epoch, 11000 iteration, loss:0.487\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "32 epoch, 12000 iteration, loss:0.475\n",
      " num 31 epoch \n",
      "####### Training Loss #######\n",
      "[0.45607103]\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "33 epoch,  1000 iteration, loss:0.425\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "33 epoch,  2000 iteration, loss:0.422\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "33 epoch,  3000 iteration, loss:0.454\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "33 epoch,  4000 iteration, loss:0.463\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "33 epoch,  5000 iteration, loss:0.466\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "33 epoch,  6000 iteration, loss:0.457\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "33 epoch,  7000 iteration, loss:0.464\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "33 epoch,  8000 iteration, loss:0.462\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "33 epoch,  9000 iteration, loss:0.472\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "33 epoch, 10000 iteration, loss:0.440\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "33 epoch, 11000 iteration, loss:0.471\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "33 epoch, 12000 iteration, loss:0.471\n",
      " num 32 epoch \n",
      "####### Training Loss #######\n",
      "[0.44670312]\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "34 epoch,  1000 iteration, loss:0.419\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "34 epoch,  2000 iteration, loss:0.428\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "34 epoch,  3000 iteration, loss:0.433\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "34 epoch,  4000 iteration, loss:0.459\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "34 epoch,  5000 iteration, loss:0.464\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "34 epoch,  6000 iteration, loss:0.460\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "34 epoch,  7000 iteration, loss:0.469\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "34 epoch,  8000 iteration, loss:0.467\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "34 epoch,  9000 iteration, loss:0.474\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "34 epoch, 10000 iteration, loss:0.482\n",
      "Checking accuracy on validation set\n",
      "Got 802 / 1000 correct (80.20)\n",
      "34 epoch, 11000 iteration, loss:0.463\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "34 epoch, 12000 iteration, loss:0.468\n",
      " num 33 epoch \n",
      "####### Training Loss #######\n",
      "[0.44839587]\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "35 epoch,  1000 iteration, loss:0.428\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "35 epoch,  2000 iteration, loss:0.446\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "35 epoch,  3000 iteration, loss:0.421\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "35 epoch,  4000 iteration, loss:0.445\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "35 epoch,  5000 iteration, loss:0.477\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "35 epoch,  6000 iteration, loss:0.464\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "35 epoch,  7000 iteration, loss:0.457\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "35 epoch,  8000 iteration, loss:0.458\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "35 epoch,  9000 iteration, loss:0.453\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "35 epoch, 10000 iteration, loss:0.460\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "35 epoch, 11000 iteration, loss:0.468\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "35 epoch, 12000 iteration, loss:0.452\n",
      " num 34 epoch \n",
      "####### Training Loss #######\n",
      "[0.44408249]\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "36 epoch,  1000 iteration, loss:0.419\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "36 epoch,  2000 iteration, loss:0.425\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "36 epoch,  3000 iteration, loss:0.425\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "36 epoch,  4000 iteration, loss:0.430\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "36 epoch,  5000 iteration, loss:0.450\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "36 epoch,  6000 iteration, loss:0.459\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "36 epoch,  7000 iteration, loss:0.463\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "36 epoch,  8000 iteration, loss:0.439\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "36 epoch,  9000 iteration, loss:0.458\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "36 epoch, 10000 iteration, loss:0.452\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "36 epoch, 11000 iteration, loss:0.476\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "36 epoch, 12000 iteration, loss:0.439\n",
      " num 35 epoch \n",
      "####### Training Loss #######\n",
      "[0.43570917]\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "37 epoch,  1000 iteration, loss:0.419\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "37 epoch,  2000 iteration, loss:0.424\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "37 epoch,  3000 iteration, loss:0.409\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "37 epoch,  4000 iteration, loss:0.437\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "37 epoch,  5000 iteration, loss:0.431\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "37 epoch,  6000 iteration, loss:0.432\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "37 epoch,  7000 iteration, loss:0.445\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "37 epoch,  8000 iteration, loss:0.455\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "37 epoch,  9000 iteration, loss:0.469\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "37 epoch, 10000 iteration, loss:0.466\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "37 epoch, 11000 iteration, loss:0.495\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "37 epoch, 12000 iteration, loss:0.452\n",
      " num 36 epoch \n",
      "####### Training Loss #######\n",
      "[0.43596013]\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "38 epoch,  1000 iteration, loss:0.396\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "38 epoch,  2000 iteration, loss:0.430\n",
      "Checking accuracy on validation set\n",
      "Got 802 / 1000 correct (80.20)\n",
      "38 epoch,  3000 iteration, loss:0.405\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "38 epoch,  4000 iteration, loss:0.453\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "38 epoch,  5000 iteration, loss:0.436\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "38 epoch,  6000 iteration, loss:0.430\n",
      "Checking accuracy on validation set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 836 / 1000 correct (83.60)\n",
      "38 epoch,  7000 iteration, loss:0.443\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "38 epoch,  8000 iteration, loss:0.445\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "38 epoch,  9000 iteration, loss:0.449\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "38 epoch, 10000 iteration, loss:0.461\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "38 epoch, 11000 iteration, loss:0.449\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "38 epoch, 12000 iteration, loss:0.482\n",
      " num 37 epoch \n",
      "####### Training Loss #######\n",
      "[0.4320715]\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "39 epoch,  1000 iteration, loss:0.414\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "39 epoch,  2000 iteration, loss:0.426\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "39 epoch,  3000 iteration, loss:0.425\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "39 epoch,  4000 iteration, loss:0.409\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "39 epoch,  5000 iteration, loss:0.412\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "39 epoch,  6000 iteration, loss:0.438\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "39 epoch,  7000 iteration, loss:0.438\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "39 epoch,  8000 iteration, loss:0.434\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "39 epoch,  9000 iteration, loss:0.453\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "39 epoch, 10000 iteration, loss:0.431\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "39 epoch, 11000 iteration, loss:0.462\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "39 epoch, 12000 iteration, loss:0.477\n",
      " num 38 epoch \n",
      "####### Training Loss #######\n",
      "[0.42586983]\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "40 epoch,  1000 iteration, loss:0.396\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "40 epoch,  2000 iteration, loss:0.409\n",
      "Checking accuracy on validation set\n",
      "Got 785 / 1000 correct (78.50)\n",
      "40 epoch,  3000 iteration, loss:0.414\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "40 epoch,  4000 iteration, loss:0.397\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "40 epoch,  5000 iteration, loss:0.416\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "40 epoch,  6000 iteration, loss:0.444\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "40 epoch,  7000 iteration, loss:0.448\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "40 epoch,  8000 iteration, loss:0.440\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "40 epoch,  9000 iteration, loss:0.461\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "40 epoch, 10000 iteration, loss:0.455\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "40 epoch, 11000 iteration, loss:0.425\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "40 epoch, 12000 iteration, loss:0.462\n",
      " num 39 epoch \n",
      "####### Training Loss #######\n",
      "[0.42179168]\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "41 epoch,  1000 iteration, loss:0.392\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "41 epoch,  2000 iteration, loss:0.413\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "41 epoch,  3000 iteration, loss:0.420\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "41 epoch,  4000 iteration, loss:0.419\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "41 epoch,  5000 iteration, loss:0.448\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "41 epoch,  6000 iteration, loss:0.417\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "41 epoch,  7000 iteration, loss:0.431\n",
      "Checking accuracy on validation set\n",
      "Got 773 / 1000 correct (77.30)\n",
      "41 epoch,  8000 iteration, loss:0.431\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "41 epoch,  9000 iteration, loss:0.417\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "41 epoch, 10000 iteration, loss:0.452\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "41 epoch, 11000 iteration, loss:0.443\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "41 epoch, 12000 iteration, loss:0.453\n",
      " num 40 epoch \n",
      "####### Training Loss #######\n",
      "[0.42035406]\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "42 epoch,  1000 iteration, loss:0.405\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "42 epoch,  2000 iteration, loss:0.394\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "42 epoch,  3000 iteration, loss:0.412\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "42 epoch,  4000 iteration, loss:0.401\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "42 epoch,  5000 iteration, loss:0.418\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "42 epoch,  6000 iteration, loss:0.448\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "42 epoch,  7000 iteration, loss:0.416\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "42 epoch,  8000 iteration, loss:0.430\n",
      "Checking accuracy on validation set\n",
      "Got 789 / 1000 correct (78.90)\n",
      "42 epoch,  9000 iteration, loss:0.440\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "42 epoch, 10000 iteration, loss:0.415\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "42 epoch, 11000 iteration, loss:0.459\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "42 epoch, 12000 iteration, loss:0.432\n",
      " num 41 epoch \n",
      "####### Training Loss #######\n",
      "[0.41449278]\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "43 epoch,  1000 iteration, loss:0.415\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "43 epoch,  2000 iteration, loss:0.421\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "43 epoch,  3000 iteration, loss:0.380\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "43 epoch,  4000 iteration, loss:0.396\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "43 epoch,  5000 iteration, loss:0.434\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "43 epoch,  6000 iteration, loss:0.400\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "43 epoch,  7000 iteration, loss:0.432\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "43 epoch,  8000 iteration, loss:0.445\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "43 epoch,  9000 iteration, loss:0.429\n",
      "Checking accuracy on validation set\n",
      "Got 788 / 1000 correct (78.80)\n",
      "43 epoch, 10000 iteration, loss:0.435\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "43 epoch, 11000 iteration, loss:0.449\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "43 epoch, 12000 iteration, loss:0.440\n",
      " num 42 epoch \n",
      "####### Training Loss #######\n",
      "[0.41476221]\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "44 epoch,  1000 iteration, loss:0.391\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10)\n",
      "44 epoch,  2000 iteration, loss:0.408\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "44 epoch,  3000 iteration, loss:0.393\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "44 epoch,  4000 iteration, loss:0.406\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "44 epoch,  5000 iteration, loss:0.390\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "44 epoch,  6000 iteration, loss:0.432\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "44 epoch,  7000 iteration, loss:0.421\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "44 epoch,  8000 iteration, loss:0.418\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "44 epoch,  9000 iteration, loss:0.422\n",
      "Checking accuracy on validation set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 823 / 1000 correct (82.30)\n",
      "44 epoch, 10000 iteration, loss:0.426\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "44 epoch, 11000 iteration, loss:0.418\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "44 epoch, 12000 iteration, loss:0.445\n",
      " num 43 epoch \n",
      "####### Training Loss #######\n",
      "[0.40606007]\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "45 epoch,  1000 iteration, loss:0.387\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "45 epoch,  2000 iteration, loss:0.393\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "45 epoch,  3000 iteration, loss:0.378\n",
      "Checking accuracy on validation set\n",
      "Got 798 / 1000 correct (79.80)\n",
      "45 epoch,  4000 iteration, loss:0.396\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "45 epoch,  5000 iteration, loss:0.399\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "45 epoch,  6000 iteration, loss:0.405\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "45 epoch,  7000 iteration, loss:0.414\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "45 epoch,  8000 iteration, loss:0.420\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "45 epoch,  9000 iteration, loss:0.427\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "45 epoch, 10000 iteration, loss:0.432\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "45 epoch, 11000 iteration, loss:0.448\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "45 epoch, 12000 iteration, loss:0.447\n",
      " num 44 epoch \n",
      "####### Training Loss #######\n",
      "[0.40493805]\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "46 epoch,  1000 iteration, loss:0.401\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "46 epoch,  2000 iteration, loss:0.383\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "46 epoch,  3000 iteration, loss:0.397\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "46 epoch,  4000 iteration, loss:0.432\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "46 epoch,  5000 iteration, loss:0.430\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "46 epoch,  6000 iteration, loss:0.408\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "46 epoch,  7000 iteration, loss:0.391\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "46 epoch,  8000 iteration, loss:0.431\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "46 epoch,  9000 iteration, loss:0.429\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "46 epoch, 10000 iteration, loss:0.433\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "46 epoch, 11000 iteration, loss:0.428\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "46 epoch, 12000 iteration, loss:0.412\n",
      " num 45 epoch \n",
      "####### Training Loss #######\n",
      "[0.40678752]\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "47 epoch,  1000 iteration, loss:0.383\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "47 epoch,  2000 iteration, loss:0.417\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "47 epoch,  3000 iteration, loss:0.394\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "47 epoch,  4000 iteration, loss:0.395\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "47 epoch,  5000 iteration, loss:0.402\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "47 epoch,  6000 iteration, loss:0.404\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "47 epoch,  7000 iteration, loss:0.432\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "47 epoch,  8000 iteration, loss:0.402\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "47 epoch,  9000 iteration, loss:0.415\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "47 epoch, 10000 iteration, loss:0.444\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "47 epoch, 11000 iteration, loss:0.435\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "47 epoch, 12000 iteration, loss:0.437\n",
      " num 46 epoch \n",
      "####### Training Loss #######\n",
      "[0.40565454]\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "48 epoch,  1000 iteration, loss:0.377\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "48 epoch,  2000 iteration, loss:0.385\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "48 epoch,  3000 iteration, loss:0.408\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "48 epoch,  4000 iteration, loss:0.399\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "48 epoch,  5000 iteration, loss:0.397\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "48 epoch,  6000 iteration, loss:0.399\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "48 epoch,  7000 iteration, loss:0.399\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "48 epoch,  8000 iteration, loss:0.421\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "48 epoch,  9000 iteration, loss:0.393\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "48 epoch, 10000 iteration, loss:0.422\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "48 epoch, 11000 iteration, loss:0.436\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "48 epoch, 12000 iteration, loss:0.426\n",
      " num 47 epoch \n",
      "####### Training Loss #######\n",
      "[0.39739904]\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "49 epoch,  1000 iteration, loss:0.373\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "49 epoch,  2000 iteration, loss:0.390\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "49 epoch,  3000 iteration, loss:0.391\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "49 epoch,  4000 iteration, loss:0.405\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "49 epoch,  5000 iteration, loss:0.401\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "49 epoch,  6000 iteration, loss:0.429\n",
      "Checking accuracy on validation set\n",
      "Got 800 / 1000 correct (80.00)\n",
      "49 epoch,  7000 iteration, loss:0.429\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "49 epoch,  8000 iteration, loss:0.420\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "49 epoch,  9000 iteration, loss:0.400\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "49 epoch, 10000 iteration, loss:0.431\n",
      "Checking accuracy on validation set\n",
      "Got 802 / 1000 correct (80.20)\n",
      "49 epoch, 11000 iteration, loss:0.424\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "49 epoch, 12000 iteration, loss:0.434\n",
      " num 48 epoch \n",
      "####### Training Loss #######\n",
      "[0.40327027]\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "50 epoch,  1000 iteration, loss:0.373\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "50 epoch,  2000 iteration, loss:0.395\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "50 epoch,  3000 iteration, loss:0.383\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "50 epoch,  4000 iteration, loss:0.405\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "50 epoch,  5000 iteration, loss:0.408\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "50 epoch,  6000 iteration, loss:0.398\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "50 epoch,  7000 iteration, loss:0.432\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "50 epoch,  8000 iteration, loss:0.392\n",
      "Checking accuracy on validation set\n",
      "Got 796 / 1000 correct (79.60)\n",
      "50 epoch,  9000 iteration, loss:0.377\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "50 epoch, 10000 iteration, loss:0.403\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "50 epoch, 11000 iteration, loss:0.435\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "50 epoch, 12000 iteration, loss:0.417\n",
      " num 49 epoch \n",
      "####### Training Loss #######\n",
      "[0.3933008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "51 epoch,  1000 iteration, loss:0.373\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "51 epoch,  2000 iteration, loss:0.380\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "51 epoch,  3000 iteration, loss:0.401\n",
      "Checking accuracy on validation set\n",
      "Got 855 / 1000 correct (85.50)\n",
      "51 epoch,  4000 iteration, loss:0.384\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "51 epoch,  5000 iteration, loss:0.387\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "51 epoch,  6000 iteration, loss:0.403\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "51 epoch,  7000 iteration, loss:0.395\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "51 epoch,  8000 iteration, loss:0.415\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "51 epoch,  9000 iteration, loss:0.425\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "51 epoch, 10000 iteration, loss:0.401\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "51 epoch, 11000 iteration, loss:0.454\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "51 epoch, 12000 iteration, loss:0.422\n",
      " num 50 epoch \n",
      "####### Training Loss #######\n",
      "[0.39542842]\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "52 epoch,  1000 iteration, loss:0.376\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "52 epoch,  2000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "52 epoch,  3000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "52 epoch,  4000 iteration, loss:0.389\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "52 epoch,  5000 iteration, loss:0.415\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "52 epoch,  6000 iteration, loss:0.408\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "52 epoch,  7000 iteration, loss:0.415\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "52 epoch,  8000 iteration, loss:0.396\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "52 epoch,  9000 iteration, loss:0.418\n",
      "Checking accuracy on validation set\n",
      "Got 796 / 1000 correct (79.60)\n",
      "52 epoch, 10000 iteration, loss:0.401\n",
      "Checking accuracy on validation set\n",
      "Got 805 / 1000 correct (80.50)\n",
      "52 epoch, 11000 iteration, loss:0.424\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "52 epoch, 12000 iteration, loss:0.427\n",
      " num 51 epoch \n",
      "####### Training Loss #######\n",
      "[0.39278716]\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "53 epoch,  1000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "53 epoch,  2000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "53 epoch,  3000 iteration, loss:0.380\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "53 epoch,  4000 iteration, loss:0.405\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "53 epoch,  5000 iteration, loss:0.380\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "53 epoch,  6000 iteration, loss:0.387\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "53 epoch,  7000 iteration, loss:0.401\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "53 epoch,  8000 iteration, loss:0.394\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "53 epoch,  9000 iteration, loss:0.439\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "53 epoch, 10000 iteration, loss:0.411\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "53 epoch, 11000 iteration, loss:0.425\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "53 epoch, 12000 iteration, loss:0.417\n",
      " num 52 epoch \n",
      "####### Training Loss #######\n",
      "[0.38816179]\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "54 epoch,  1000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "54 epoch,  2000 iteration, loss:0.384\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "54 epoch,  3000 iteration, loss:0.403\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "54 epoch,  4000 iteration, loss:0.377\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "54 epoch,  5000 iteration, loss:0.401\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "54 epoch,  6000 iteration, loss:0.402\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "54 epoch,  7000 iteration, loss:0.416\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "54 epoch,  8000 iteration, loss:0.387\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "54 epoch,  9000 iteration, loss:0.395\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "54 epoch, 10000 iteration, loss:0.396\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "54 epoch, 11000 iteration, loss:0.434\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "54 epoch, 12000 iteration, loss:0.425\n",
      " num 53 epoch \n",
      "####### Training Loss #######\n",
      "[0.39065682]\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "55 epoch,  1000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "55 epoch,  2000 iteration, loss:0.388\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "55 epoch,  3000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "55 epoch,  4000 iteration, loss:0.400\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "55 epoch,  5000 iteration, loss:0.381\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "55 epoch,  6000 iteration, loss:0.399\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "55 epoch,  7000 iteration, loss:0.406\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "55 epoch,  8000 iteration, loss:0.411\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "55 epoch,  9000 iteration, loss:0.415\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "55 epoch, 10000 iteration, loss:0.412\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "55 epoch, 11000 iteration, loss:0.401\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "55 epoch, 12000 iteration, loss:0.441\n",
      " num 54 epoch \n",
      "####### Training Loss #######\n",
      "[0.39045003]\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "56 epoch,  1000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "56 epoch,  2000 iteration, loss:0.373\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "56 epoch,  3000 iteration, loss:0.385\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "56 epoch,  4000 iteration, loss:0.387\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "56 epoch,  5000 iteration, loss:0.391\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "56 epoch,  6000 iteration, loss:0.398\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "56 epoch,  7000 iteration, loss:0.388\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "56 epoch,  8000 iteration, loss:0.400\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "56 epoch,  9000 iteration, loss:0.416\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "56 epoch, 10000 iteration, loss:0.399\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "56 epoch, 11000 iteration, loss:0.411\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "56 epoch, 12000 iteration, loss:0.386\n",
      " num 55 epoch \n",
      "####### Training Loss #######\n",
      "[0.3837431]\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "57 epoch,  1000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "57 epoch,  2000 iteration, loss:0.395\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "57 epoch,  3000 iteration, loss:0.355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "57 epoch,  4000 iteration, loss:0.394\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "57 epoch,  5000 iteration, loss:0.394\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "57 epoch,  6000 iteration, loss:0.418\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "57 epoch,  7000 iteration, loss:0.418\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "57 epoch,  8000 iteration, loss:0.391\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "57 epoch,  9000 iteration, loss:0.407\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "57 epoch, 10000 iteration, loss:0.404\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "57 epoch, 11000 iteration, loss:0.414\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "57 epoch, 12000 iteration, loss:0.414\n",
      " num 56 epoch \n",
      "####### Training Loss #######\n",
      "[0.38829289]\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "58 epoch,  1000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "58 epoch,  2000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "58 epoch,  3000 iteration, loss:0.384\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "58 epoch,  4000 iteration, loss:0.410\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "58 epoch,  5000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "58 epoch,  6000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "58 epoch,  7000 iteration, loss:0.375\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "58 epoch,  8000 iteration, loss:0.381\n",
      "Checking accuracy on validation set\n",
      "Got 792 / 1000 correct (79.20)\n",
      "58 epoch,  9000 iteration, loss:0.411\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "58 epoch, 10000 iteration, loss:0.393\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "58 epoch, 11000 iteration, loss:0.419\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "58 epoch, 12000 iteration, loss:0.420\n",
      " num 57 epoch \n",
      "####### Training Loss #######\n",
      "[0.38158227]\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "59 epoch,  1000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "59 epoch,  2000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "59 epoch,  3000 iteration, loss:0.390\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "59 epoch,  4000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "59 epoch,  5000 iteration, loss:0.376\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "59 epoch,  6000 iteration, loss:0.382\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "59 epoch,  7000 iteration, loss:0.375\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "59 epoch,  8000 iteration, loss:0.388\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "59 epoch,  9000 iteration, loss:0.391\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "59 epoch, 10000 iteration, loss:0.400\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "59 epoch, 11000 iteration, loss:0.396\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "59 epoch, 12000 iteration, loss:0.413\n",
      " num 58 epoch \n",
      "####### Training Loss #######\n",
      "[0.37732465]\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "60 epoch,  1000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "60 epoch,  2000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30)\n",
      "60 epoch,  3000 iteration, loss:0.379\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "60 epoch,  4000 iteration, loss:0.386\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "60 epoch,  5000 iteration, loss:0.394\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "60 epoch,  6000 iteration, loss:0.396\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "60 epoch,  7000 iteration, loss:0.397\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "60 epoch,  8000 iteration, loss:0.396\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "60 epoch,  9000 iteration, loss:0.417\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "60 epoch, 10000 iteration, loss:0.402\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "60 epoch, 11000 iteration, loss:0.389\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "60 epoch, 12000 iteration, loss:0.374\n",
      " num 59 epoch \n",
      "####### Training Loss #######\n",
      "[0.37911373]\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "61 epoch,  1000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "61 epoch,  2000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10)\n",
      "61 epoch,  3000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "61 epoch,  4000 iteration, loss:0.379\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "61 epoch,  5000 iteration, loss:0.378\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "61 epoch,  6000 iteration, loss:0.373\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "61 epoch,  7000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "61 epoch,  8000 iteration, loss:0.403\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "61 epoch,  9000 iteration, loss:0.407\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "61 epoch, 10000 iteration, loss:0.407\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "61 epoch, 11000 iteration, loss:0.410\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "61 epoch, 12000 iteration, loss:0.420\n",
      " num 60 epoch \n",
      "####### Training Loss #######\n",
      "[0.37656]\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "62 epoch,  1000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 850 / 1000 correct (85.00)\n",
      "62 epoch,  2000 iteration, loss:0.372\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "62 epoch,  3000 iteration, loss:0.388\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "62 epoch,  4000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "62 epoch,  5000 iteration, loss:0.377\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "62 epoch,  6000 iteration, loss:0.399\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "62 epoch,  7000 iteration, loss:0.385\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "62 epoch,  8000 iteration, loss:0.388\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "62 epoch,  9000 iteration, loss:0.397\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "62 epoch, 10000 iteration, loss:0.424\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "62 epoch, 11000 iteration, loss:0.388\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "62 epoch, 12000 iteration, loss:0.411\n",
      " num 61 epoch \n",
      "####### Training Loss #######\n",
      "[0.37983499]\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "63 epoch,  1000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "63 epoch,  2000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "63 epoch,  3000 iteration, loss:0.381\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "63 epoch,  4000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "63 epoch,  5000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "63 epoch,  6000 iteration, loss:0.391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "63 epoch,  7000 iteration, loss:0.382\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "63 epoch,  8000 iteration, loss:0.390\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "63 epoch,  9000 iteration, loss:0.385\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "63 epoch, 10000 iteration, loss:0.400\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "63 epoch, 11000 iteration, loss:0.417\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "63 epoch, 12000 iteration, loss:0.420\n",
      " num 62 epoch \n",
      "####### Training Loss #######\n",
      "[0.37515081]\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "64 epoch,  1000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "64 epoch,  2000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "64 epoch,  3000 iteration, loss:0.376\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "64 epoch,  4000 iteration, loss:0.371\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "64 epoch,  5000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "64 epoch,  6000 iteration, loss:0.391\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "64 epoch,  7000 iteration, loss:0.392\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "64 epoch,  8000 iteration, loss:0.383\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "64 epoch,  9000 iteration, loss:0.377\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "64 epoch, 10000 iteration, loss:0.405\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "64 epoch, 11000 iteration, loss:0.409\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "64 epoch, 12000 iteration, loss:0.413\n",
      " num 63 epoch \n",
      "####### Training Loss #######\n",
      "[0.37430172]\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "65 epoch,  1000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "65 epoch,  2000 iteration, loss:0.378\n",
      "Checking accuracy on validation set\n",
      "Got 797 / 1000 correct (79.70)\n",
      "65 epoch,  3000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "65 epoch,  4000 iteration, loss:0.390\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "65 epoch,  5000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "65 epoch,  6000 iteration, loss:0.375\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "65 epoch,  7000 iteration, loss:0.376\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "65 epoch,  8000 iteration, loss:0.401\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "65 epoch,  9000 iteration, loss:0.383\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "65 epoch, 10000 iteration, loss:0.389\n",
      "Checking accuracy on validation set\n",
      "Got 797 / 1000 correct (79.70)\n",
      "65 epoch, 11000 iteration, loss:0.390\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "65 epoch, 12000 iteration, loss:0.414\n",
      " num 64 epoch \n",
      "####### Training Loss #######\n",
      "[0.37433815]\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "66 epoch,  1000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "66 epoch,  2000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "66 epoch,  3000 iteration, loss:0.371\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "66 epoch,  4000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "66 epoch,  5000 iteration, loss:0.381\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "66 epoch,  6000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "66 epoch,  7000 iteration, loss:0.378\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "66 epoch,  8000 iteration, loss:0.373\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "66 epoch,  9000 iteration, loss:0.388\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "66 epoch, 10000 iteration, loss:0.397\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "66 epoch, 11000 iteration, loss:0.389\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "66 epoch, 12000 iteration, loss:0.405\n",
      " num 65 epoch \n",
      "####### Training Loss #######\n",
      "[0.36872441]\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "67 epoch,  1000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "67 epoch,  2000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "67 epoch,  3000 iteration, loss:0.393\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "67 epoch,  4000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "67 epoch,  5000 iteration, loss:0.386\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "67 epoch,  6000 iteration, loss:0.391\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "67 epoch,  7000 iteration, loss:0.379\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "67 epoch,  8000 iteration, loss:0.387\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "67 epoch,  9000 iteration, loss:0.402\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "67 epoch, 10000 iteration, loss:0.400\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "67 epoch, 11000 iteration, loss:0.403\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "67 epoch, 12000 iteration, loss:0.397\n",
      " num 66 epoch \n",
      "####### Training Loss #######\n",
      "[0.37476322]\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "68 epoch,  1000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "68 epoch,  2000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "68 epoch,  3000 iteration, loss:0.378\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "68 epoch,  4000 iteration, loss:0.392\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "68 epoch,  5000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "68 epoch,  6000 iteration, loss:0.387\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "68 epoch,  7000 iteration, loss:0.385\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "68 epoch,  8000 iteration, loss:0.407\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "68 epoch,  9000 iteration, loss:0.376\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "68 epoch, 10000 iteration, loss:0.397\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "68 epoch, 11000 iteration, loss:0.384\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "68 epoch, 12000 iteration, loss:0.403\n",
      " num 67 epoch \n",
      "####### Training Loss #######\n",
      "[0.37186436]\n",
      "Checking accuracy on validation set\n",
      "Got 850 / 1000 correct (85.00)\n",
      "69 epoch,  1000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "69 epoch,  2000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "69 epoch,  3000 iteration, loss:0.372\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "69 epoch,  4000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "69 epoch,  5000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "69 epoch,  6000 iteration, loss:0.398\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10)\n",
      "69 epoch,  7000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 793 / 1000 correct (79.30)\n",
      "69 epoch,  8000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "69 epoch,  9000 iteration, loss:0.384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "69 epoch, 10000 iteration, loss:0.400\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "69 epoch, 11000 iteration, loss:0.390\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "69 epoch, 12000 iteration, loss:0.382\n",
      " num 68 epoch \n",
      "####### Training Loss #######\n",
      "[0.36741895]\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "70 epoch,  1000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "70 epoch,  2000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "70 epoch,  3000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "70 epoch,  4000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "70 epoch,  5000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "70 epoch,  6000 iteration, loss:0.403\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "70 epoch,  7000 iteration, loss:0.384\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "70 epoch,  8000 iteration, loss:0.391\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "70 epoch,  9000 iteration, loss:0.386\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "70 epoch, 10000 iteration, loss:0.392\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "70 epoch, 11000 iteration, loss:0.395\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "70 epoch, 12000 iteration, loss:0.402\n",
      " num 69 epoch \n",
      "####### Training Loss #######\n",
      "[0.37021324]\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "71 epoch,  1000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "71 epoch,  2000 iteration, loss:0.380\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "71 epoch,  3000 iteration, loss:0.381\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "71 epoch,  4000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "71 epoch,  5000 iteration, loss:0.378\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "71 epoch,  6000 iteration, loss:0.379\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "71 epoch,  7000 iteration, loss:0.392\n",
      "Checking accuracy on validation set\n",
      "Got 800 / 1000 correct (80.00)\n",
      "71 epoch,  8000 iteration, loss:0.377\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "71 epoch,  9000 iteration, loss:0.394\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "71 epoch, 10000 iteration, loss:0.392\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "71 epoch, 11000 iteration, loss:0.395\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "71 epoch, 12000 iteration, loss:0.415\n",
      " num 70 epoch \n",
      "####### Training Loss #######\n",
      "[0.37359755]\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "72 epoch,  1000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "72 epoch,  2000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "72 epoch,  3000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "72 epoch,  4000 iteration, loss:0.379\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "72 epoch,  5000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "72 epoch,  6000 iteration, loss:0.382\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "72 epoch,  7000 iteration, loss:0.379\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "72 epoch,  8000 iteration, loss:0.395\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "72 epoch,  9000 iteration, loss:0.389\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30)\n",
      "72 epoch, 10000 iteration, loss:0.385\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "72 epoch, 11000 iteration, loss:0.396\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "72 epoch, 12000 iteration, loss:0.391\n",
      " num 71 epoch \n",
      "####### Training Loss #######\n",
      "[0.36951717]\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "73 epoch,  1000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "73 epoch,  2000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "73 epoch,  3000 iteration, loss:0.376\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "73 epoch,  4000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "73 epoch,  5000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "73 epoch,  6000 iteration, loss:0.380\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "73 epoch,  7000 iteration, loss:0.379\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "73 epoch,  8000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "73 epoch,  9000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "73 epoch, 10000 iteration, loss:0.398\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "73 epoch, 11000 iteration, loss:0.403\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "73 epoch, 12000 iteration, loss:0.407\n",
      " num 72 epoch \n",
      "####### Training Loss #######\n",
      "[0.36669497]\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "74 epoch,  1000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "74 epoch,  2000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "74 epoch,  3000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "74 epoch,  4000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "74 epoch,  5000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "74 epoch,  6000 iteration, loss:0.373\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "74 epoch,  7000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "74 epoch,  8000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "74 epoch,  9000 iteration, loss:0.382\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "74 epoch, 10000 iteration, loss:0.432\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "74 epoch, 11000 iteration, loss:0.409\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "74 epoch, 12000 iteration, loss:0.387\n",
      " num 73 epoch \n",
      "####### Training Loss #######\n",
      "[0.36364984]\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "75 epoch,  1000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "75 epoch,  2000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "75 epoch,  3000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "75 epoch,  4000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "75 epoch,  5000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "75 epoch,  6000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "75 epoch,  7000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "75 epoch,  8000 iteration, loss:0.394\n",
      "Checking accuracy on validation set\n",
      "Got 786 / 1000 correct (78.60)\n",
      "75 epoch,  9000 iteration, loss:0.385\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "75 epoch, 10000 iteration, loss:0.388\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "75 epoch, 11000 iteration, loss:0.395\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "75 epoch, 12000 iteration, loss:0.379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num 74 epoch \n",
      "####### Training Loss #######\n",
      "[0.3632993]\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "76 epoch,  1000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "76 epoch,  2000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "76 epoch,  3000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "76 epoch,  4000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "76 epoch,  5000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "76 epoch,  6000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "76 epoch,  7000 iteration, loss:0.382\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "76 epoch,  8000 iteration, loss:0.378\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "76 epoch,  9000 iteration, loss:0.388\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "76 epoch, 10000 iteration, loss:0.386\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "76 epoch, 11000 iteration, loss:0.387\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "76 epoch, 12000 iteration, loss:0.393\n",
      " num 75 epoch \n",
      "####### Training Loss #######\n",
      "[0.36178606]\n",
      "Checking accuracy on validation set\n",
      "Got 805 / 1000 correct (80.50)\n",
      "77 epoch,  1000 iteration, loss:0.310\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "77 epoch,  2000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 805 / 1000 correct (80.50)\n",
      "77 epoch,  3000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "77 epoch,  4000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "77 epoch,  5000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "77 epoch,  6000 iteration, loss:0.380\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "77 epoch,  7000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "77 epoch,  8000 iteration, loss:0.386\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "77 epoch,  9000 iteration, loss:0.391\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "77 epoch, 10000 iteration, loss:0.384\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "77 epoch, 11000 iteration, loss:0.389\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "77 epoch, 12000 iteration, loss:0.396\n",
      " num 76 epoch \n",
      "####### Training Loss #######\n",
      "[0.35919558]\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "78 epoch,  1000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "78 epoch,  2000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 853 / 1000 correct (85.30)\n",
      "78 epoch,  3000 iteration, loss:0.380\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "78 epoch,  4000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "78 epoch,  5000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "78 epoch,  6000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "78 epoch,  7000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "78 epoch,  8000 iteration, loss:0.384\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "78 epoch,  9000 iteration, loss:0.386\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "78 epoch, 10000 iteration, loss:0.403\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "78 epoch, 11000 iteration, loss:0.375\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "78 epoch, 12000 iteration, loss:0.407\n",
      " num 77 epoch \n",
      "####### Training Loss #######\n",
      "[0.3619884]\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "79 epoch,  1000 iteration, loss:0.315\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "79 epoch,  2000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "79 epoch,  3000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "79 epoch,  4000 iteration, loss:0.373\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "79 epoch,  5000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "79 epoch,  6000 iteration, loss:0.387\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "79 epoch,  7000 iteration, loss:0.389\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "79 epoch,  8000 iteration, loss:0.371\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "79 epoch,  9000 iteration, loss:0.380\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "79 epoch, 10000 iteration, loss:0.380\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "79 epoch, 11000 iteration, loss:0.389\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "79 epoch, 12000 iteration, loss:0.390\n",
      " num 78 epoch \n",
      "####### Training Loss #######\n",
      "[0.3610028]\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "80 epoch,  1000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "80 epoch,  2000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "80 epoch,  3000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "80 epoch,  4000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "80 epoch,  5000 iteration, loss:0.380\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "80 epoch,  6000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "80 epoch,  7000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "80 epoch,  8000 iteration, loss:0.382\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "80 epoch,  9000 iteration, loss:0.392\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "80 epoch, 10000 iteration, loss:0.387\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "80 epoch, 11000 iteration, loss:0.399\n",
      "Checking accuracy on validation set\n",
      "Got 779 / 1000 correct (77.90)\n",
      "80 epoch, 12000 iteration, loss:0.377\n",
      " num 79 epoch \n",
      "####### Training Loss #######\n",
      "[0.36407418]\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30)\n",
      "81 epoch,  1000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "81 epoch,  2000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "81 epoch,  3000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "81 epoch,  4000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "81 epoch,  5000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "81 epoch,  6000 iteration, loss:0.383\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "81 epoch,  7000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "81 epoch,  8000 iteration, loss:0.394\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "81 epoch,  9000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "81 epoch, 10000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "81 epoch, 11000 iteration, loss:0.398\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "81 epoch, 12000 iteration, loss:0.409\n",
      " num 80 epoch \n",
      "####### Training Loss #######\n",
      "[0.35854251]\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "82 epoch,  1000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "82 epoch,  2000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 832 / 1000 correct (83.20)\n",
      "82 epoch,  3000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "82 epoch,  4000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 802 / 1000 correct (80.20)\n",
      "82 epoch,  5000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "82 epoch,  6000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "82 epoch,  7000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "82 epoch,  8000 iteration, loss:0.372\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "82 epoch,  9000 iteration, loss:0.409\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "82 epoch, 10000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "82 epoch, 11000 iteration, loss:0.381\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "82 epoch, 12000 iteration, loss:0.390\n",
      " num 81 epoch \n",
      "####### Training Loss #######\n",
      "[0.35613546]\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "83 epoch,  1000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "83 epoch,  2000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "83 epoch,  3000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "83 epoch,  4000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "83 epoch,  5000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "83 epoch,  6000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "83 epoch,  7000 iteration, loss:0.395\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "83 epoch,  8000 iteration, loss:0.376\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "83 epoch,  9000 iteration, loss:0.391\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "83 epoch, 10000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "83 epoch, 11000 iteration, loss:0.394\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "83 epoch, 12000 iteration, loss:0.406\n",
      " num 82 epoch \n",
      "####### Training Loss #######\n",
      "[0.36306293]\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "84 epoch,  1000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "84 epoch,  2000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "84 epoch,  3000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "84 epoch,  4000 iteration, loss:0.380\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "84 epoch,  5000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "84 epoch,  6000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "84 epoch,  7000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "84 epoch,  8000 iteration, loss:0.378\n",
      "Checking accuracy on validation set\n",
      "Got 851 / 1000 correct (85.10)\n",
      "84 epoch,  9000 iteration, loss:0.376\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "84 epoch, 10000 iteration, loss:0.385\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "84 epoch, 11000 iteration, loss:0.372\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "84 epoch, 12000 iteration, loss:0.398\n",
      " num 83 epoch \n",
      "####### Training Loss #######\n",
      "[0.35692829]\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "85 epoch,  1000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "85 epoch,  2000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "85 epoch,  3000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "85 epoch,  4000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "85 epoch,  5000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "85 epoch,  6000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 796 / 1000 correct (79.60)\n",
      "85 epoch,  7000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "85 epoch,  8000 iteration, loss:0.373\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "85 epoch,  9000 iteration, loss:0.379\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "85 epoch, 10000 iteration, loss:0.390\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "85 epoch, 11000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "85 epoch, 12000 iteration, loss:0.406\n",
      " num 84 epoch \n",
      "####### Training Loss #######\n",
      "[0.35447334]\n",
      "Checking accuracy on validation set\n",
      "Got 853 / 1000 correct (85.30)\n",
      "86 epoch,  1000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "86 epoch,  2000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "86 epoch,  3000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "86 epoch,  4000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "86 epoch,  5000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "86 epoch,  6000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "86 epoch,  7000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "86 epoch,  8000 iteration, loss:0.383\n",
      "Checking accuracy on validation set\n",
      "Got 795 / 1000 correct (79.50)\n",
      "86 epoch,  9000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "86 epoch, 10000 iteration, loss:0.383\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "86 epoch, 11000 iteration, loss:0.377\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "86 epoch, 12000 iteration, loss:0.385\n",
      " num 85 epoch \n",
      "####### Training Loss #######\n",
      "[0.35466651]\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "87 epoch,  1000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "87 epoch,  2000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "87 epoch,  3000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "87 epoch,  4000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "87 epoch,  5000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "87 epoch,  6000 iteration, loss:0.372\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "87 epoch,  7000 iteration, loss:0.392\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "87 epoch,  8000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "87 epoch,  9000 iteration, loss:0.390\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "87 epoch, 10000 iteration, loss:0.376\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "87 epoch, 11000 iteration, loss:0.404\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "87 epoch, 12000 iteration, loss:0.398\n",
      " num 86 epoch \n",
      "####### Training Loss #######\n",
      "[0.36044474]\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "88 epoch,  1000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "88 epoch,  2000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "88 epoch,  3000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "88 epoch,  4000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "88 epoch,  5000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 838 / 1000 correct (83.80)\n",
      "88 epoch,  6000 iteration, loss:0.372\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "88 epoch,  7000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "88 epoch,  8000 iteration, loss:0.373\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "88 epoch,  9000 iteration, loss:0.380\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "88 epoch, 10000 iteration, loss:0.373\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "88 epoch, 11000 iteration, loss:0.371\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "88 epoch, 12000 iteration, loss:0.393\n",
      " num 87 epoch \n",
      "####### Training Loss #######\n",
      "[0.35528131]\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "89 epoch,  1000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "89 epoch,  2000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "89 epoch,  3000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "89 epoch,  4000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "89 epoch,  5000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "89 epoch,  6000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "89 epoch,  7000 iteration, loss:0.406\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "89 epoch,  8000 iteration, loss:0.406\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "89 epoch,  9000 iteration, loss:0.375\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "89 epoch, 10000 iteration, loss:0.386\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "89 epoch, 11000 iteration, loss:0.378\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "89 epoch, 12000 iteration, loss:0.377\n",
      " num 88 epoch \n",
      "####### Training Loss #######\n",
      "[0.3559414]\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "90 epoch,  1000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 792 / 1000 correct (79.20)\n",
      "90 epoch,  2000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "90 epoch,  3000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "90 epoch,  4000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "90 epoch,  5000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "90 epoch,  6000 iteration, loss:0.372\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "90 epoch,  7000 iteration, loss:0.377\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "90 epoch,  8000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "90 epoch,  9000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "90 epoch, 10000 iteration, loss:0.385\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "90 epoch, 11000 iteration, loss:0.383\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "90 epoch, 12000 iteration, loss:0.373\n",
      " num 89 epoch \n",
      "####### Training Loss #######\n",
      "[0.35478567]\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "91 epoch,  1000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "91 epoch,  2000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "91 epoch,  3000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "91 epoch,  4000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "91 epoch,  5000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "91 epoch,  6000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "91 epoch,  7000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "91 epoch,  8000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "91 epoch,  9000 iteration, loss:0.394\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "91 epoch, 10000 iteration, loss:0.372\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "91 epoch, 11000 iteration, loss:0.376\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30)\n",
      "91 epoch, 12000 iteration, loss:0.387\n",
      " num 90 epoch \n",
      "####### Training Loss #######\n",
      "[0.35446121]\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "92 epoch,  1000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "92 epoch,  2000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 805 / 1000 correct (80.50)\n",
      "92 epoch,  3000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "92 epoch,  4000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "92 epoch,  5000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "92 epoch,  6000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "92 epoch,  7000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "92 epoch,  8000 iteration, loss:0.391\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "92 epoch,  9000 iteration, loss:0.384\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "92 epoch, 10000 iteration, loss:0.381\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "92 epoch, 11000 iteration, loss:0.371\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "92 epoch, 12000 iteration, loss:0.376\n",
      " num 91 epoch \n",
      "####### Training Loss #######\n",
      "[0.35463094]\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "93 epoch,  1000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "93 epoch,  2000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "93 epoch,  3000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "93 epoch,  4000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "93 epoch,  5000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "93 epoch,  6000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "93 epoch,  7000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "93 epoch,  8000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "93 epoch,  9000 iteration, loss:0.387\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "93 epoch, 10000 iteration, loss:0.386\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "93 epoch, 11000 iteration, loss:0.386\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "93 epoch, 12000 iteration, loss:0.392\n",
      " num 92 epoch \n",
      "####### Training Loss #######\n",
      "[0.35596038]\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "94 epoch,  1000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "94 epoch,  2000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 797 / 1000 correct (79.70)\n",
      "94 epoch,  3000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 793 / 1000 correct (79.30)\n",
      "94 epoch,  4000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "94 epoch,  5000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "94 epoch,  6000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10)\n",
      "94 epoch,  7000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "94 epoch,  8000 iteration, loss:0.398\n",
      "Checking accuracy on validation set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 829 / 1000 correct (82.90)\n",
      "94 epoch,  9000 iteration, loss:0.375\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "94 epoch, 10000 iteration, loss:0.395\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "94 epoch, 11000 iteration, loss:0.385\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "94 epoch, 12000 iteration, loss:0.377\n",
      " num 93 epoch \n",
      "####### Training Loss #######\n",
      "[0.35315682]\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "95 epoch,  1000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "95 epoch,  2000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "95 epoch,  3000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "95 epoch,  4000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "95 epoch,  5000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 787 / 1000 correct (78.70)\n",
      "95 epoch,  6000 iteration, loss:0.389\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "95 epoch,  7000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "95 epoch,  8000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "95 epoch,  9000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "95 epoch, 10000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "95 epoch, 11000 iteration, loss:0.378\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "95 epoch, 12000 iteration, loss:0.367\n",
      " num 94 epoch \n",
      "####### Training Loss #######\n",
      "[0.35311936]\n",
      "Checking accuracy on validation set\n",
      "Got 802 / 1000 correct (80.20)\n",
      "96 epoch,  1000 iteration, loss:0.315\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "96 epoch,  2000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "96 epoch,  3000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "96 epoch,  4000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 805 / 1000 correct (80.50)\n",
      "96 epoch,  5000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "96 epoch,  6000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "96 epoch,  7000 iteration, loss:0.378\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "96 epoch,  8000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "96 epoch,  9000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "96 epoch, 10000 iteration, loss:0.401\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "96 epoch, 11000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "96 epoch, 12000 iteration, loss:0.394\n",
      " num 95 epoch \n",
      "####### Training Loss #######\n",
      "[0.35524023]\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "97 epoch,  1000 iteration, loss:0.316\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "97 epoch,  2000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "97 epoch,  3000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "97 epoch,  4000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "97 epoch,  5000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "97 epoch,  6000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10)\n",
      "97 epoch,  7000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "97 epoch,  8000 iteration, loss:0.383\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "97 epoch,  9000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "97 epoch, 10000 iteration, loss:0.406\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "97 epoch, 11000 iteration, loss:0.386\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10)\n",
      "97 epoch, 12000 iteration, loss:0.375\n",
      " num 96 epoch \n",
      "####### Training Loss #######\n",
      "[0.35123886]\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "98 epoch,  1000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "98 epoch,  2000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 792 / 1000 correct (79.20)\n",
      "98 epoch,  3000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 805 / 1000 correct (80.50)\n",
      "98 epoch,  4000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "98 epoch,  5000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "98 epoch,  6000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "98 epoch,  7000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "98 epoch,  8000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "98 epoch,  9000 iteration, loss:0.393\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "98 epoch, 10000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "98 epoch, 11000 iteration, loss:0.376\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "98 epoch, 12000 iteration, loss:0.387\n",
      " num 97 epoch \n",
      "####### Training Loss #######\n",
      "[0.35069149]\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "99 epoch,  1000 iteration, loss:0.310\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "99 epoch,  2000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "99 epoch,  3000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "99 epoch,  4000 iteration, loss:0.381\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "99 epoch,  5000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "99 epoch,  6000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "99 epoch,  7000 iteration, loss:0.378\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "99 epoch,  8000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "99 epoch,  9000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "99 epoch, 10000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "99 epoch, 11000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "99 epoch, 12000 iteration, loss:0.390\n",
      " num 98 epoch \n",
      "####### Training Loss #######\n",
      "[0.35163719]\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "100 epoch,  1000 iteration, loss:0.315\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "100 epoch,  2000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "100 epoch,  3000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "100 epoch,  4000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "100 epoch,  5000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "100 epoch,  6000 iteration, loss:0.385\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "100 epoch,  7000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "100 epoch,  8000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "100 epoch,  9000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "100 epoch, 10000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "100 epoch, 11000 iteration, loss:0.397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "100 epoch, 12000 iteration, loss:0.390\n",
      " num 99 epoch \n",
      "####### Training Loss #######\n",
      "[0.35155264]\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "101 epoch,  1000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "101 epoch,  2000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "101 epoch,  3000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "101 epoch,  4000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "101 epoch,  5000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "101 epoch,  6000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "101 epoch,  7000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "101 epoch,  8000 iteration, loss:0.397\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "101 epoch,  9000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "101 epoch, 10000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "101 epoch, 11000 iteration, loss:0.373\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "101 epoch, 12000 iteration, loss:0.399\n",
      " num 100 epoch \n",
      "####### Training Loss #######\n",
      "[0.35346329]\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "102 epoch,  1000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "102 epoch,  2000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "102 epoch,  3000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "102 epoch,  4000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "102 epoch,  5000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "102 epoch,  6000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "102 epoch,  7000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "102 epoch,  8000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 805 / 1000 correct (80.50)\n",
      "102 epoch,  9000 iteration, loss:0.381\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "102 epoch, 10000 iteration, loss:0.377\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "102 epoch, 11000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "102 epoch, 12000 iteration, loss:0.379\n",
      " num 101 epoch \n",
      "####### Training Loss #######\n",
      "[0.35104741]\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "103 epoch,  1000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "103 epoch,  2000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "103 epoch,  3000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "103 epoch,  4000 iteration, loss:0.377\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "103 epoch,  5000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "103 epoch,  6000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "103 epoch,  7000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "103 epoch,  8000 iteration, loss:0.375\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30)\n",
      "103 epoch,  9000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "103 epoch, 10000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "103 epoch, 11000 iteration, loss:0.371\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "103 epoch, 12000 iteration, loss:0.396\n",
      " num 102 epoch \n",
      "####### Training Loss #######\n",
      "[0.34575745]\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "104 epoch,  1000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "104 epoch,  2000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "104 epoch,  3000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "104 epoch,  4000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "104 epoch,  5000 iteration, loss:0.371\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "104 epoch,  6000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "104 epoch,  7000 iteration, loss:0.372\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "104 epoch,  8000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "104 epoch,  9000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "104 epoch, 10000 iteration, loss:0.390\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "104 epoch, 11000 iteration, loss:0.376\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "104 epoch, 12000 iteration, loss:0.376\n",
      " num 103 epoch \n",
      "####### Training Loss #######\n",
      "[0.34788859]\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "105 epoch,  1000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "105 epoch,  2000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "105 epoch,  3000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "105 epoch,  4000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "105 epoch,  5000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "105 epoch,  6000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "105 epoch,  7000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "105 epoch,  8000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "105 epoch,  9000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "105 epoch, 10000 iteration, loss:0.377\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "105 epoch, 11000 iteration, loss:0.398\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "105 epoch, 12000 iteration, loss:0.371\n",
      " num 104 epoch \n",
      "####### Training Loss #######\n",
      "[0.34809918]\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "106 epoch,  1000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "106 epoch,  2000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "106 epoch,  3000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "106 epoch,  4000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "106 epoch,  5000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "106 epoch,  6000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "106 epoch,  7000 iteration, loss:0.371\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "106 epoch,  8000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 793 / 1000 correct (79.30)\n",
      "106 epoch,  9000 iteration, loss:0.383\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "106 epoch, 10000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 854 / 1000 correct (85.40)\n",
      "106 epoch, 11000 iteration, loss:0.402\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "106 epoch, 12000 iteration, loss:0.364\n",
      " num 105 epoch \n",
      "####### Training Loss #######\n",
      "[0.34892661]\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "107 epoch,  1000 iteration, loss:0.305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "107 epoch,  2000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 851 / 1000 correct (85.10)\n",
      "107 epoch,  3000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "107 epoch,  4000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "107 epoch,  5000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "107 epoch,  6000 iteration, loss:0.377\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "107 epoch,  7000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "107 epoch,  8000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "107 epoch,  9000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 798 / 1000 correct (79.80)\n",
      "107 epoch, 10000 iteration, loss:0.398\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "107 epoch, 11000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 797 / 1000 correct (79.70)\n",
      "107 epoch, 12000 iteration, loss:0.384\n",
      " num 106 epoch \n",
      "####### Training Loss #######\n",
      "[0.34750869]\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "108 epoch,  1000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "108 epoch,  2000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "108 epoch,  3000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 785 / 1000 correct (78.50)\n",
      "108 epoch,  4000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "108 epoch,  5000 iteration, loss:0.382\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "108 epoch,  6000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "108 epoch,  7000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "108 epoch,  8000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "108 epoch,  9000 iteration, loss:0.376\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "108 epoch, 10000 iteration, loss:0.386\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "108 epoch, 11000 iteration, loss:0.395\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "108 epoch, 12000 iteration, loss:0.362\n",
      " num 107 epoch \n",
      "####### Training Loss #######\n",
      "[0.34710213]\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "109 epoch,  1000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "109 epoch,  2000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "109 epoch,  3000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "109 epoch,  4000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "109 epoch,  5000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "109 epoch,  6000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 787 / 1000 correct (78.70)\n",
      "109 epoch,  7000 iteration, loss:0.371\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "109 epoch,  8000 iteration, loss:0.382\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "109 epoch,  9000 iteration, loss:0.382\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "109 epoch, 10000 iteration, loss:0.375\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "109 epoch, 11000 iteration, loss:0.390\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "109 epoch, 12000 iteration, loss:0.375\n",
      " num 108 epoch \n",
      "####### Training Loss #######\n",
      "[0.34992552]\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "110 epoch,  1000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "110 epoch,  2000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "110 epoch,  3000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "110 epoch,  4000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "110 epoch,  5000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "110 epoch,  6000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "110 epoch,  7000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "110 epoch,  8000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "110 epoch,  9000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "110 epoch, 10000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "110 epoch, 11000 iteration, loss:0.372\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "110 epoch, 12000 iteration, loss:0.374\n",
      " num 109 epoch \n",
      "####### Training Loss #######\n",
      "[0.34507997]\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "111 epoch,  1000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "111 epoch,  2000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "111 epoch,  3000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "111 epoch,  4000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "111 epoch,  5000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "111 epoch,  6000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "111 epoch,  7000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "111 epoch,  8000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "111 epoch,  9000 iteration, loss:0.394\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "111 epoch, 10000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "111 epoch, 11000 iteration, loss:0.386\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "111 epoch, 12000 iteration, loss:0.379\n",
      " num 110 epoch \n",
      "####### Training Loss #######\n",
      "[0.34912341]\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "112 epoch,  1000 iteration, loss:0.302\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "112 epoch,  2000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "112 epoch,  3000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10)\n",
      "112 epoch,  4000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "112 epoch,  5000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "112 epoch,  6000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "112 epoch,  7000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "112 epoch,  8000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 799 / 1000 correct (79.90)\n",
      "112 epoch,  9000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "112 epoch, 10000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "112 epoch, 11000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "112 epoch, 12000 iteration, loss:0.389\n",
      " num 111 epoch \n",
      "####### Training Loss #######\n",
      "[0.34678944]\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "113 epoch,  1000 iteration, loss:0.307\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "113 epoch,  2000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "113 epoch,  3000 iteration, loss:0.349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "113 epoch,  4000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "113 epoch,  5000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "113 epoch,  6000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "113 epoch,  7000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "113 epoch,  8000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "113 epoch,  9000 iteration, loss:0.376\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "113 epoch, 10000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "113 epoch, 11000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "113 epoch, 12000 iteration, loss:0.393\n",
      " num 112 epoch \n",
      "####### Training Loss #######\n",
      "[0.34738284]\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "114 epoch,  1000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "114 epoch,  2000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "114 epoch,  3000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "114 epoch,  4000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "114 epoch,  5000 iteration, loss:0.379\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "114 epoch,  6000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "114 epoch,  7000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "114 epoch,  8000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "114 epoch,  9000 iteration, loss:0.372\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "114 epoch, 10000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "114 epoch, 11000 iteration, loss:0.387\n",
      "Checking accuracy on validation set\n",
      "Got 805 / 1000 correct (80.50)\n",
      "114 epoch, 12000 iteration, loss:0.373\n",
      " num 113 epoch \n",
      "####### Training Loss #######\n",
      "[0.34348892]\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "115 epoch,  1000 iteration, loss:0.304\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "115 epoch,  2000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "115 epoch,  3000 iteration, loss:0.316\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "115 epoch,  4000 iteration, loss:0.373\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "115 epoch,  5000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "115 epoch,  6000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "115 epoch,  7000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "115 epoch,  8000 iteration, loss:0.378\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "115 epoch,  9000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 854 / 1000 correct (85.40)\n",
      "115 epoch, 10000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "115 epoch, 11000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "115 epoch, 12000 iteration, loss:0.372\n",
      " num 114 epoch \n",
      "####### Training Loss #######\n",
      "[0.34498866]\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "116 epoch,  1000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "116 epoch,  2000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "116 epoch,  3000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "116 epoch,  4000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "116 epoch,  5000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "116 epoch,  6000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "116 epoch,  7000 iteration, loss:0.373\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "116 epoch,  8000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "116 epoch,  9000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "116 epoch, 10000 iteration, loss:0.379\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "116 epoch, 11000 iteration, loss:0.379\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "116 epoch, 12000 iteration, loss:0.386\n",
      " num 115 epoch \n",
      "####### Training Loss #######\n",
      "[0.34849913]\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "117 epoch,  1000 iteration, loss:0.309\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "117 epoch,  2000 iteration, loss:0.319\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "117 epoch,  3000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 851 / 1000 correct (85.10)\n",
      "117 epoch,  4000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "117 epoch,  5000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "117 epoch,  6000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "117 epoch,  7000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "117 epoch,  8000 iteration, loss:0.379\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "117 epoch,  9000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "117 epoch, 10000 iteration, loss:0.379\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "117 epoch, 11000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "117 epoch, 12000 iteration, loss:0.381\n",
      " num 116 epoch \n",
      "####### Training Loss #######\n",
      "[0.34518885]\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "118 epoch,  1000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "118 epoch,  2000 iteration, loss:0.307\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "118 epoch,  3000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "118 epoch,  4000 iteration, loss:0.315\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "118 epoch,  5000 iteration, loss:0.378\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "118 epoch,  6000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "118 epoch,  7000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "118 epoch,  8000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "118 epoch,  9000 iteration, loss:0.387\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "118 epoch, 10000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "118 epoch, 11000 iteration, loss:0.387\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "118 epoch, 12000 iteration, loss:0.388\n",
      " num 117 epoch \n",
      "####### Training Loss #######\n",
      "[0.34577724]\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "119 epoch,  1000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "119 epoch,  2000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "119 epoch,  3000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "119 epoch,  4000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "119 epoch,  5000 iteration, loss:0.346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "119 epoch,  6000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "119 epoch,  7000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "119 epoch,  8000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "119 epoch,  9000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "119 epoch, 10000 iteration, loss:0.372\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "119 epoch, 11000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "119 epoch, 12000 iteration, loss:0.360\n",
      " num 118 epoch \n",
      "####### Training Loss #######\n",
      "[0.34227466]\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "120 epoch,  1000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "120 epoch,  2000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "120 epoch,  3000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "120 epoch,  4000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "120 epoch,  5000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 800 / 1000 correct (80.00)\n",
      "120 epoch,  6000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 791 / 1000 correct (79.10)\n",
      "120 epoch,  7000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "120 epoch,  8000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "120 epoch,  9000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "120 epoch, 10000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "120 epoch, 11000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "120 epoch, 12000 iteration, loss:0.390\n",
      " num 119 epoch \n",
      "####### Training Loss #######\n",
      "[0.34546878]\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "121 epoch,  1000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "121 epoch,  2000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "121 epoch,  3000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "121 epoch,  4000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "121 epoch,  5000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "121 epoch,  6000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "121 epoch,  7000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "121 epoch,  8000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "121 epoch,  9000 iteration, loss:0.376\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "121 epoch, 10000 iteration, loss:0.389\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "121 epoch, 11000 iteration, loss:0.379\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "121 epoch, 12000 iteration, loss:0.397\n",
      " num 120 epoch \n",
      "####### Training Loss #######\n",
      "[0.35014692]\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "122 epoch,  1000 iteration, loss:0.297\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "122 epoch,  2000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "122 epoch,  3000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "122 epoch,  4000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "122 epoch,  5000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "122 epoch,  6000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 790 / 1000 correct (79.00)\n",
      "122 epoch,  7000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "122 epoch,  8000 iteration, loss:0.375\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "122 epoch,  9000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "122 epoch, 10000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "122 epoch, 11000 iteration, loss:0.381\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10)\n",
      "122 epoch, 12000 iteration, loss:0.376\n",
      " num 121 epoch \n",
      "####### Training Loss #######\n",
      "[0.34333302]\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "123 epoch,  1000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "123 epoch,  2000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "123 epoch,  3000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "123 epoch,  4000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "123 epoch,  5000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "123 epoch,  6000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "123 epoch,  7000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "123 epoch,  8000 iteration, loss:0.376\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "123 epoch,  9000 iteration, loss:0.373\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "123 epoch, 10000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "123 epoch, 11000 iteration, loss:0.389\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "123 epoch, 12000 iteration, loss:0.354\n",
      " num 122 epoch \n",
      "####### Training Loss #######\n",
      "[0.34440352]\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "124 epoch,  1000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "124 epoch,  2000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "124 epoch,  3000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "124 epoch,  4000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "124 epoch,  5000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "124 epoch,  6000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "124 epoch,  7000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "124 epoch,  8000 iteration, loss:0.385\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "124 epoch,  9000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "124 epoch, 10000 iteration, loss:0.373\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30)\n",
      "124 epoch, 11000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "124 epoch, 12000 iteration, loss:0.386\n",
      " num 123 epoch \n",
      "####### Training Loss #######\n",
      "[0.34122122]\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "125 epoch,  1000 iteration, loss:0.304\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "125 epoch,  2000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "125 epoch,  3000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "125 epoch,  4000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "125 epoch,  5000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "125 epoch,  6000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "125 epoch,  7000 iteration, loss:0.361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "125 epoch,  8000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 853 / 1000 correct (85.30)\n",
      "125 epoch,  9000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "125 epoch, 10000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "125 epoch, 11000 iteration, loss:0.380\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30)\n",
      "125 epoch, 12000 iteration, loss:0.378\n",
      " num 124 epoch \n",
      "####### Training Loss #######\n",
      "[0.34747004]\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "126 epoch,  1000 iteration, loss:0.315\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "126 epoch,  2000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "126 epoch,  3000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "126 epoch,  4000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "126 epoch,  5000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "126 epoch,  6000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "126 epoch,  7000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "126 epoch,  8000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "126 epoch,  9000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "126 epoch, 10000 iteration, loss:0.372\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "126 epoch, 11000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "126 epoch, 12000 iteration, loss:0.360\n",
      " num 125 epoch \n",
      "####### Training Loss #######\n",
      "[0.33980023]\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "127 epoch,  1000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "127 epoch,  2000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "127 epoch,  3000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "127 epoch,  4000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "127 epoch,  5000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "127 epoch,  6000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "127 epoch,  7000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "127 epoch,  8000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "127 epoch,  9000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "127 epoch, 10000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "127 epoch, 11000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "127 epoch, 12000 iteration, loss:0.385\n",
      " num 126 epoch \n",
      "####### Training Loss #######\n",
      "[0.34403611]\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "128 epoch,  1000 iteration, loss:0.288\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "128 epoch,  2000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "128 epoch,  3000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "128 epoch,  4000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "128 epoch,  5000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "128 epoch,  6000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 797 / 1000 correct (79.70)\n",
      "128 epoch,  7000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "128 epoch,  8000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "128 epoch,  9000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "128 epoch, 10000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "128 epoch, 11000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "128 epoch, 12000 iteration, loss:0.361\n",
      " num 127 epoch \n",
      "####### Training Loss #######\n",
      "[0.33969425]\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "129 epoch,  1000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "129 epoch,  2000 iteration, loss:0.316\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "129 epoch,  3000 iteration, loss:0.316\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "129 epoch,  4000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "129 epoch,  5000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "129 epoch,  6000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "129 epoch,  7000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "129 epoch,  8000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "129 epoch,  9000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "129 epoch, 10000 iteration, loss:0.373\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "129 epoch, 11000 iteration, loss:0.388\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "129 epoch, 12000 iteration, loss:0.366\n",
      " num 128 epoch \n",
      "####### Training Loss #######\n",
      "[0.34002541]\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "130 epoch,  1000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "130 epoch,  2000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 800 / 1000 correct (80.00)\n",
      "130 epoch,  3000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "130 epoch,  4000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "130 epoch,  5000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "130 epoch,  6000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "130 epoch,  7000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "130 epoch,  8000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "130 epoch,  9000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "130 epoch, 10000 iteration, loss:0.378\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "130 epoch, 11000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "130 epoch, 12000 iteration, loss:0.393\n",
      " num 129 epoch \n",
      "####### Training Loss #######\n",
      "[0.34445952]\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "131 epoch,  1000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "131 epoch,  2000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "131 epoch,  3000 iteration, loss:0.299\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "131 epoch,  4000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "131 epoch,  5000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "131 epoch,  6000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "131 epoch,  7000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "131 epoch,  8000 iteration, loss:0.402\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "131 epoch,  9000 iteration, loss:0.346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 790 / 1000 correct (79.00)\n",
      "131 epoch, 10000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "131 epoch, 11000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "131 epoch, 12000 iteration, loss:0.366\n",
      " num 130 epoch \n",
      "####### Training Loss #######\n",
      "[0.33803976]\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "132 epoch,  1000 iteration, loss:0.300\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "132 epoch,  2000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "132 epoch,  3000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "132 epoch,  4000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "132 epoch,  5000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "132 epoch,  6000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "132 epoch,  7000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "132 epoch,  8000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "132 epoch,  9000 iteration, loss:0.379\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "132 epoch, 10000 iteration, loss:0.383\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "132 epoch, 11000 iteration, loss:0.379\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "132 epoch, 12000 iteration, loss:0.373\n",
      " num 131 epoch \n",
      "####### Training Loss #######\n",
      "[0.34603314]\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "133 epoch,  1000 iteration, loss:0.300\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "133 epoch,  2000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "133 epoch,  3000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "133 epoch,  4000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "133 epoch,  5000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "133 epoch,  6000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "133 epoch,  7000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "133 epoch,  8000 iteration, loss:0.385\n",
      "Checking accuracy on validation set\n",
      "Got 854 / 1000 correct (85.40)\n",
      "133 epoch,  9000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "133 epoch, 10000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "133 epoch, 11000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "133 epoch, 12000 iteration, loss:0.368\n",
      " num 132 epoch \n",
      "####### Training Loss #######\n",
      "[0.34119302]\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "134 epoch,  1000 iteration, loss:0.309\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "134 epoch,  2000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "134 epoch,  3000 iteration, loss:0.316\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "134 epoch,  4000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "134 epoch,  5000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "134 epoch,  6000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "134 epoch,  7000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "134 epoch,  8000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "134 epoch,  9000 iteration, loss:0.385\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "134 epoch, 10000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "134 epoch, 11000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "134 epoch, 12000 iteration, loss:0.394\n",
      " num 133 epoch \n",
      "####### Training Loss #######\n",
      "[0.34241808]\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "135 epoch,  1000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "135 epoch,  2000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "135 epoch,  3000 iteration, loss:0.303\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "135 epoch,  4000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "135 epoch,  5000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "135 epoch,  6000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "135 epoch,  7000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "135 epoch,  8000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "135 epoch,  9000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "135 epoch, 10000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "135 epoch, 11000 iteration, loss:0.391\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "135 epoch, 12000 iteration, loss:0.367\n",
      " num 134 epoch \n",
      "####### Training Loss #######\n",
      "[0.3388512]\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "136 epoch,  1000 iteration, loss:0.309\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "136 epoch,  2000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "136 epoch,  3000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "136 epoch,  4000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "136 epoch,  5000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "136 epoch,  6000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "136 epoch,  7000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "136 epoch,  8000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "136 epoch,  9000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "136 epoch, 10000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "136 epoch, 11000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "136 epoch, 12000 iteration, loss:0.352\n",
      " num 135 epoch \n",
      "####### Training Loss #######\n",
      "[0.337967]\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "137 epoch,  1000 iteration, loss:0.288\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "137 epoch,  2000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "137 epoch,  3000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "137 epoch,  4000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "137 epoch,  5000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "137 epoch,  6000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "137 epoch,  7000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "137 epoch,  8000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "137 epoch,  9000 iteration, loss:0.391\n",
      "Checking accuracy on validation set\n",
      "Got 805 / 1000 correct (80.50)\n",
      "137 epoch, 10000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "137 epoch, 11000 iteration, loss:0.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "137 epoch, 12000 iteration, loss:0.371\n",
      " num 136 epoch \n",
      "####### Training Loss #######\n",
      "[0.33999656]\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "138 epoch,  1000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "138 epoch,  2000 iteration, loss:0.303\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "138 epoch,  3000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 850 / 1000 correct (85.00)\n",
      "138 epoch,  4000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "138 epoch,  5000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "138 epoch,  6000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "138 epoch,  7000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "138 epoch,  8000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "138 epoch,  9000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "138 epoch, 10000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "138 epoch, 11000 iteration, loss:0.371\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "138 epoch, 12000 iteration, loss:0.373\n",
      " num 137 epoch \n",
      "####### Training Loss #######\n",
      "[0.33907321]\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "139 epoch,  1000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "139 epoch,  2000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "139 epoch,  3000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "139 epoch,  4000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "139 epoch,  5000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "139 epoch,  6000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "139 epoch,  7000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "139 epoch,  8000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "139 epoch,  9000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "139 epoch, 10000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "139 epoch, 11000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "139 epoch, 12000 iteration, loss:0.357\n",
      " num 138 epoch \n",
      "####### Training Loss #######\n",
      "[0.33983476]\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "140 epoch,  1000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "140 epoch,  2000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "140 epoch,  3000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "140 epoch,  4000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "140 epoch,  5000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "140 epoch,  6000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "140 epoch,  7000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "140 epoch,  8000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "140 epoch,  9000 iteration, loss:0.373\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "140 epoch, 10000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "140 epoch, 11000 iteration, loss:0.377\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "140 epoch, 12000 iteration, loss:0.359\n",
      " num 139 epoch \n",
      "####### Training Loss #######\n",
      "[0.34159695]\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "141 epoch,  1000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "141 epoch,  2000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "141 epoch,  3000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "141 epoch,  4000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "141 epoch,  5000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "141 epoch,  6000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "141 epoch,  7000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "141 epoch,  8000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "141 epoch,  9000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "141 epoch, 10000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "141 epoch, 11000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "141 epoch, 12000 iteration, loss:0.385\n",
      " num 140 epoch \n",
      "####### Training Loss #######\n",
      "[0.34228608]\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "142 epoch,  1000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "142 epoch,  2000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "142 epoch,  3000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "142 epoch,  4000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "142 epoch,  5000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "142 epoch,  6000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "142 epoch,  7000 iteration, loss:0.372\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "142 epoch,  8000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "142 epoch,  9000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "142 epoch, 10000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "142 epoch, 11000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "142 epoch, 12000 iteration, loss:0.346\n",
      " num 141 epoch \n",
      "####### Training Loss #######\n",
      "[0.33565243]\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "143 epoch,  1000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "143 epoch,  2000 iteration, loss:0.309\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "143 epoch,  3000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "143 epoch,  4000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "143 epoch,  5000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "143 epoch,  6000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "143 epoch,  7000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "143 epoch,  8000 iteration, loss:0.371\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "143 epoch,  9000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "143 epoch, 10000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "143 epoch, 11000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "143 epoch, 12000 iteration, loss:0.382\n",
      " num 142 epoch \n",
      "####### Training Loss #######\n",
      "[0.34093861]\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "144 epoch,  1000 iteration, loss:0.318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "144 epoch,  2000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "144 epoch,  3000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "144 epoch,  4000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "144 epoch,  5000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "144 epoch,  6000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "144 epoch,  7000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "144 epoch,  8000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 795 / 1000 correct (79.50)\n",
      "144 epoch,  9000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "144 epoch, 10000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "144 epoch, 11000 iteration, loss:0.376\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "144 epoch, 12000 iteration, loss:0.381\n",
      " num 143 epoch \n",
      "####### Training Loss #######\n",
      "[0.34167828]\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "145 epoch,  1000 iteration, loss:0.287\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "145 epoch,  2000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "145 epoch,  3000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "145 epoch,  4000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 798 / 1000 correct (79.80)\n",
      "145 epoch,  5000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "145 epoch,  6000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "145 epoch,  7000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "145 epoch,  8000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "145 epoch,  9000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "145 epoch, 10000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "145 epoch, 11000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "145 epoch, 12000 iteration, loss:0.368\n",
      " num 144 epoch \n",
      "####### Training Loss #######\n",
      "[0.33578261]\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "146 epoch,  1000 iteration, loss:0.294\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "146 epoch,  2000 iteration, loss:0.309\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "146 epoch,  3000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "146 epoch,  4000 iteration, loss:0.319\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "146 epoch,  5000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "146 epoch,  6000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "146 epoch,  7000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "146 epoch,  8000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "146 epoch,  9000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "146 epoch, 10000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "146 epoch, 11000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "146 epoch, 12000 iteration, loss:0.372\n",
      " num 145 epoch \n",
      "####### Training Loss #######\n",
      "[0.33521148]\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "147 epoch,  1000 iteration, loss:0.283\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "147 epoch,  2000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "147 epoch,  3000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "147 epoch,  4000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "147 epoch,  5000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "147 epoch,  6000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "147 epoch,  7000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "147 epoch,  8000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "147 epoch,  9000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "147 epoch, 10000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "147 epoch, 11000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 778 / 1000 correct (77.80)\n",
      "147 epoch, 12000 iteration, loss:0.388\n",
      " num 146 epoch \n",
      "####### Training Loss #######\n",
      "[0.33869741]\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "148 epoch,  1000 iteration, loss:0.300\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "148 epoch,  2000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "148 epoch,  3000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "148 epoch,  4000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "148 epoch,  5000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "148 epoch,  6000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "148 epoch,  7000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "148 epoch,  8000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "148 epoch,  9000 iteration, loss:0.373\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "148 epoch, 10000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "148 epoch, 11000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "148 epoch, 12000 iteration, loss:0.387\n",
      " num 147 epoch \n",
      "####### Training Loss #######\n",
      "[0.33941619]\n",
      "Checking accuracy on validation set\n",
      "Got 800 / 1000 correct (80.00)\n",
      "149 epoch,  1000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "149 epoch,  2000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "149 epoch,  3000 iteration, loss:0.315\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "149 epoch,  4000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "149 epoch,  5000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "149 epoch,  6000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "149 epoch,  7000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "149 epoch,  8000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "149 epoch,  9000 iteration, loss:0.371\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "149 epoch, 10000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "149 epoch, 11000 iteration, loss:0.402\n",
      "Checking accuracy on validation set\n",
      "Got 796 / 1000 correct (79.60)\n",
      "149 epoch, 12000 iteration, loss:0.377\n",
      " num 148 epoch \n",
      "####### Training Loss #######\n",
      "[0.33815509]\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "150 epoch,  1000 iteration, loss:0.303\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "150 epoch,  2000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "150 epoch,  3000 iteration, loss:0.329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "150 epoch,  4000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "150 epoch,  5000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "150 epoch,  6000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "150 epoch,  7000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "150 epoch,  8000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 805 / 1000 correct (80.50)\n",
      "150 epoch,  9000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "150 epoch, 10000 iteration, loss:0.389\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "150 epoch, 11000 iteration, loss:0.375\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "150 epoch, 12000 iteration, loss:0.367\n",
      " num 149 epoch \n",
      "####### Training Loss #######\n",
      "[0.3388202]\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "151 epoch,  1000 iteration, loss:0.291\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "151 epoch,  2000 iteration, loss:0.307\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "151 epoch,  3000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "151 epoch,  4000 iteration, loss:0.319\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "151 epoch,  5000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "151 epoch,  6000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "151 epoch,  7000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "151 epoch,  8000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "151 epoch,  9000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "151 epoch, 10000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "151 epoch, 11000 iteration, loss:0.375\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "151 epoch, 12000 iteration, loss:0.382\n",
      " num 150 epoch \n",
      "####### Training Loss #######\n",
      "[0.33605668]\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "152 epoch,  1000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "152 epoch,  2000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "152 epoch,  3000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "152 epoch,  4000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "152 epoch,  5000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "152 epoch,  6000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "152 epoch,  7000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "152 epoch,  8000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "152 epoch,  9000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10)\n",
      "152 epoch, 10000 iteration, loss:0.379\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "152 epoch, 11000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "152 epoch, 12000 iteration, loss:0.363\n",
      " num 151 epoch \n",
      "####### Training Loss #######\n",
      "[0.33867689]\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "153 epoch,  1000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "153 epoch,  2000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "153 epoch,  3000 iteration, loss:0.307\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "153 epoch,  4000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "153 epoch,  5000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "153 epoch,  6000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "153 epoch,  7000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "153 epoch,  8000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "153 epoch,  9000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "153 epoch, 10000 iteration, loss:0.373\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "153 epoch, 11000 iteration, loss:0.383\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "153 epoch, 12000 iteration, loss:0.371\n",
      " num 152 epoch \n",
      "####### Training Loss #######\n",
      "[0.33679138]\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "154 epoch,  1000 iteration, loss:0.290\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "154 epoch,  2000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 791 / 1000 correct (79.10)\n",
      "154 epoch,  3000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "154 epoch,  4000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "154 epoch,  5000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "154 epoch,  6000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "154 epoch,  7000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "154 epoch,  8000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "154 epoch,  9000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "154 epoch, 10000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "154 epoch, 11000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "154 epoch, 12000 iteration, loss:0.366\n",
      " num 153 epoch \n",
      "####### Training Loss #######\n",
      "[0.33702208]\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "155 epoch,  1000 iteration, loss:0.303\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "155 epoch,  2000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30)\n",
      "155 epoch,  3000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "155 epoch,  4000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "155 epoch,  5000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "155 epoch,  6000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "155 epoch,  7000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 782 / 1000 correct (78.20)\n",
      "155 epoch,  8000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "155 epoch,  9000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "155 epoch, 10000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "155 epoch, 11000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "155 epoch, 12000 iteration, loss:0.386\n",
      " num 154 epoch \n",
      "####### Training Loss #######\n",
      "[0.33958898]\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "156 epoch,  1000 iteration, loss:0.307\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "156 epoch,  2000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "156 epoch,  3000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "156 epoch,  4000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 794 / 1000 correct (79.40)\n",
      "156 epoch,  5000 iteration, loss:0.330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "156 epoch,  6000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "156 epoch,  7000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "156 epoch,  8000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "156 epoch,  9000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "156 epoch, 10000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "156 epoch, 11000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "156 epoch, 12000 iteration, loss:0.370\n",
      " num 155 epoch \n",
      "####### Training Loss #######\n",
      "[0.33649689]\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "157 epoch,  1000 iteration, loss:0.304\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "157 epoch,  2000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "157 epoch,  3000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "157 epoch,  4000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "157 epoch,  5000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "157 epoch,  6000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 797 / 1000 correct (79.70)\n",
      "157 epoch,  7000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "157 epoch,  8000 iteration, loss:0.373\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "157 epoch,  9000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "157 epoch, 10000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "157 epoch, 11000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "157 epoch, 12000 iteration, loss:0.355\n",
      " num 156 epoch \n",
      "####### Training Loss #######\n",
      "[0.33498135]\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "158 epoch,  1000 iteration, loss:0.299\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "158 epoch,  2000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "158 epoch,  3000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "158 epoch,  4000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "158 epoch,  5000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "158 epoch,  6000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "158 epoch,  7000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "158 epoch,  8000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "158 epoch,  9000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "158 epoch, 10000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "158 epoch, 11000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "158 epoch, 12000 iteration, loss:0.375\n",
      " num 157 epoch \n",
      "####### Training Loss #######\n",
      "[0.33757379]\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "159 epoch,  1000 iteration, loss:0.294\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "159 epoch,  2000 iteration, loss:0.292\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "159 epoch,  3000 iteration, loss:0.316\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "159 epoch,  4000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "159 epoch,  5000 iteration, loss:0.376\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "159 epoch,  6000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 805 / 1000 correct (80.50)\n",
      "159 epoch,  7000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "159 epoch,  8000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "159 epoch,  9000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "159 epoch, 10000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "159 epoch, 11000 iteration, loss:0.373\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "159 epoch, 12000 iteration, loss:0.371\n",
      " num 158 epoch \n",
      "####### Training Loss #######\n",
      "[0.33508128]\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "160 epoch,  1000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "160 epoch,  2000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "160 epoch,  3000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "160 epoch,  4000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "160 epoch,  5000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "160 epoch,  6000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "160 epoch,  7000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "160 epoch,  8000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "160 epoch,  9000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "160 epoch, 10000 iteration, loss:0.390\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "160 epoch, 11000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "160 epoch, 12000 iteration, loss:0.361\n",
      " num 159 epoch \n",
      "####### Training Loss #######\n",
      "[0.33331063]\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "161 epoch,  1000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 777 / 1000 correct (77.70)\n",
      "161 epoch,  2000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "161 epoch,  3000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "161 epoch,  4000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "161 epoch,  5000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 782 / 1000 correct (78.20)\n",
      "161 epoch,  6000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "161 epoch,  7000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "161 epoch,  8000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "161 epoch,  9000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "161 epoch, 10000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "161 epoch, 11000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 852 / 1000 correct (85.20)\n",
      "161 epoch, 12000 iteration, loss:0.372\n",
      " num 160 epoch \n",
      "####### Training Loss #######\n",
      "[0.33605468]\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "162 epoch,  1000 iteration, loss:0.296\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "162 epoch,  2000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "162 epoch,  3000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "162 epoch,  4000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "162 epoch,  5000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "162 epoch,  6000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 798 / 1000 correct (79.80)\n",
      "162 epoch,  7000 iteration, loss:0.374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 799 / 1000 correct (79.90)\n",
      "162 epoch,  8000 iteration, loss:0.372\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "162 epoch,  9000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "162 epoch, 10000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "162 epoch, 11000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "162 epoch, 12000 iteration, loss:0.381\n",
      " num 161 epoch \n",
      "####### Training Loss #######\n",
      "[0.33413057]\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "163 epoch,  1000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "163 epoch,  2000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "163 epoch,  3000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "163 epoch,  4000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "163 epoch,  5000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "163 epoch,  6000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "163 epoch,  7000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "163 epoch,  8000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "163 epoch,  9000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "163 epoch, 10000 iteration, loss:0.382\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "163 epoch, 11000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "163 epoch, 12000 iteration, loss:0.355\n",
      " num 162 epoch \n",
      "####### Training Loss #######\n",
      "[0.33388837]\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "164 epoch,  1000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "164 epoch,  2000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "164 epoch,  3000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "164 epoch,  4000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "164 epoch,  5000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "164 epoch,  6000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 857 / 1000 correct (85.70)\n",
      "164 epoch,  7000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "164 epoch,  8000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "164 epoch,  9000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "164 epoch, 10000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "164 epoch, 11000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "164 epoch, 12000 iteration, loss:0.374\n",
      " num 163 epoch \n",
      "####### Training Loss #######\n",
      "[0.33613654]\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "165 epoch,  1000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "165 epoch,  2000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "165 epoch,  3000 iteration, loss:0.310\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "165 epoch,  4000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "165 epoch,  5000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 856 / 1000 correct (85.60)\n",
      "165 epoch,  6000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "165 epoch,  7000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "165 epoch,  8000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "165 epoch,  9000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "165 epoch, 10000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "165 epoch, 11000 iteration, loss:0.381\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "165 epoch, 12000 iteration, loss:0.351\n",
      " num 164 epoch \n",
      "####### Training Loss #######\n",
      "[0.33566537]\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "166 epoch,  1000 iteration, loss:0.288\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10)\n",
      "166 epoch,  2000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "166 epoch,  3000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "166 epoch,  4000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "166 epoch,  5000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "166 epoch,  6000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "166 epoch,  7000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "166 epoch,  8000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 850 / 1000 correct (85.00)\n",
      "166 epoch,  9000 iteration, loss:0.381\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "166 epoch, 10000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "166 epoch, 11000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "166 epoch, 12000 iteration, loss:0.351\n",
      " num 165 epoch \n",
      "####### Training Loss #######\n",
      "[0.33533368]\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "167 epoch,  1000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "167 epoch,  2000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "167 epoch,  3000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "167 epoch,  4000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 851 / 1000 correct (85.10)\n",
      "167 epoch,  5000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "167 epoch,  6000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 856 / 1000 correct (85.60)\n",
      "167 epoch,  7000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "167 epoch,  8000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "167 epoch,  9000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "167 epoch, 10000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "167 epoch, 11000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "167 epoch, 12000 iteration, loss:0.351\n",
      " num 166 epoch \n",
      "####### Training Loss #######\n",
      "[0.3378728]\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "168 epoch,  1000 iteration, loss:0.290\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "168 epoch,  2000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "168 epoch,  3000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 788 / 1000 correct (78.80)\n",
      "168 epoch,  4000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "168 epoch,  5000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "168 epoch,  6000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "168 epoch,  7000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "168 epoch,  8000 iteration, loss:0.383\n",
      "Checking accuracy on validation set\n",
      "Got 800 / 1000 correct (80.00)\n",
      "168 epoch,  9000 iteration, loss:0.343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "168 epoch, 10000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "168 epoch, 11000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "168 epoch, 12000 iteration, loss:0.381\n",
      " num 167 epoch \n",
      "####### Training Loss #######\n",
      "[0.33931173]\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "169 epoch,  1000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "169 epoch,  2000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 850 / 1000 correct (85.00)\n",
      "169 epoch,  3000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "169 epoch,  4000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "169 epoch,  5000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "169 epoch,  6000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "169 epoch,  7000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "169 epoch,  8000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "169 epoch,  9000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "169 epoch, 10000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "169 epoch, 11000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "169 epoch, 12000 iteration, loss:0.362\n",
      " num 168 epoch \n",
      "####### Training Loss #######\n",
      "[0.33274593]\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "170 epoch,  1000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "170 epoch,  2000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "170 epoch,  3000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "170 epoch,  4000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "170 epoch,  5000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "170 epoch,  6000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "170 epoch,  7000 iteration, loss:0.376\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "170 epoch,  8000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "170 epoch,  9000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "170 epoch, 10000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "170 epoch, 11000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "170 epoch, 12000 iteration, loss:0.344\n",
      " num 169 epoch \n",
      "####### Training Loss #######\n",
      "[0.33567845]\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "171 epoch,  1000 iteration, loss:0.315\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "171 epoch,  2000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "171 epoch,  3000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "171 epoch,  4000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "171 epoch,  5000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "171 epoch,  6000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "171 epoch,  7000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "171 epoch,  8000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "171 epoch,  9000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "171 epoch, 10000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "171 epoch, 11000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "171 epoch, 12000 iteration, loss:0.386\n",
      " num 170 epoch \n",
      "####### Training Loss #######\n",
      "[0.3386264]\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "172 epoch,  1000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "172 epoch,  2000 iteration, loss:0.319\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "172 epoch,  3000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "172 epoch,  4000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "172 epoch,  5000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "172 epoch,  6000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "172 epoch,  7000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "172 epoch,  8000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "172 epoch,  9000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "172 epoch, 10000 iteration, loss:0.378\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "172 epoch, 11000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "172 epoch, 12000 iteration, loss:0.356\n",
      " num 171 epoch \n",
      "####### Training Loss #######\n",
      "[0.33555183]\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "173 epoch,  1000 iteration, loss:0.281\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "173 epoch,  2000 iteration, loss:0.319\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "173 epoch,  3000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "173 epoch,  4000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "173 epoch,  5000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10)\n",
      "173 epoch,  6000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "173 epoch,  7000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "173 epoch,  8000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "173 epoch,  9000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "173 epoch, 10000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "173 epoch, 11000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "173 epoch, 12000 iteration, loss:0.364\n",
      " num 172 epoch \n",
      "####### Training Loss #######\n",
      "[0.33278869]\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "174 epoch,  1000 iteration, loss:0.309\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "174 epoch,  2000 iteration, loss:0.300\n",
      "Checking accuracy on validation set\n",
      "Got 779 / 1000 correct (77.90)\n",
      "174 epoch,  3000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "174 epoch,  4000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "174 epoch,  5000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "174 epoch,  6000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "174 epoch,  7000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "174 epoch,  8000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "174 epoch,  9000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "174 epoch, 10000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "174 epoch, 11000 iteration, loss:0.351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "174 epoch, 12000 iteration, loss:0.357\n",
      " num 173 epoch \n",
      "####### Training Loss #######\n",
      "[0.33004191]\n",
      "Checking accuracy on validation set\n",
      "Got 851 / 1000 correct (85.10)\n",
      "175 epoch,  1000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "175 epoch,  2000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "175 epoch,  3000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "175 epoch,  4000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "175 epoch,  5000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "175 epoch,  6000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "175 epoch,  7000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "175 epoch,  8000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "175 epoch,  9000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "175 epoch, 10000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "175 epoch, 11000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "175 epoch, 12000 iteration, loss:0.370\n",
      " num 174 epoch \n",
      "####### Training Loss #######\n",
      "[0.3376156]\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "176 epoch,  1000 iteration, loss:0.289\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "176 epoch,  2000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "176 epoch,  3000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "176 epoch,  4000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "176 epoch,  5000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "176 epoch,  6000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "176 epoch,  7000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "176 epoch,  8000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "176 epoch,  9000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "176 epoch, 10000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "176 epoch, 11000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "176 epoch, 12000 iteration, loss:0.356\n",
      " num 175 epoch \n",
      "####### Training Loss #######\n",
      "[0.33386929]\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "177 epoch,  1000 iteration, loss:0.287\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "177 epoch,  2000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "177 epoch,  3000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "177 epoch,  4000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "177 epoch,  5000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "177 epoch,  6000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "177 epoch,  7000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "177 epoch,  8000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "177 epoch,  9000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "177 epoch, 10000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "177 epoch, 11000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "177 epoch, 12000 iteration, loss:0.374\n",
      " num 176 epoch \n",
      "####### Training Loss #######\n",
      "[0.33548674]\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "178 epoch,  1000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "178 epoch,  2000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "178 epoch,  3000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "178 epoch,  4000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "178 epoch,  5000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "178 epoch,  6000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "178 epoch,  7000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "178 epoch,  8000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "178 epoch,  9000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 793 / 1000 correct (79.30)\n",
      "178 epoch, 10000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "178 epoch, 11000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "178 epoch, 12000 iteration, loss:0.373\n",
      " num 177 epoch \n",
      "####### Training Loss #######\n",
      "[0.33218959]\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "179 epoch,  1000 iteration, loss:0.309\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "179 epoch,  2000 iteration, loss:0.293\n",
      "Checking accuracy on validation set\n",
      "Got 856 / 1000 correct (85.60)\n",
      "179 epoch,  3000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "179 epoch,  4000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "179 epoch,  5000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "179 epoch,  6000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "179 epoch,  7000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "179 epoch,  8000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "179 epoch,  9000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "179 epoch, 10000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "179 epoch, 11000 iteration, loss:0.371\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "179 epoch, 12000 iteration, loss:0.357\n",
      " num 178 epoch \n",
      "####### Training Loss #######\n",
      "[0.3352893]\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "180 epoch,  1000 iteration, loss:0.286\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "180 epoch,  2000 iteration, loss:0.295\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "180 epoch,  3000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "180 epoch,  4000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "180 epoch,  5000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "180 epoch,  6000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "180 epoch,  7000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "180 epoch,  8000 iteration, loss:0.378\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "180 epoch,  9000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "180 epoch, 10000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "180 epoch, 11000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "180 epoch, 12000 iteration, loss:0.343\n",
      " num 179 epoch \n",
      "####### Training Loss #######\n",
      "[0.33003392]\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "181 epoch,  1000 iteration, loss:0.299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "181 epoch,  2000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30)\n",
      "181 epoch,  3000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "181 epoch,  4000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "181 epoch,  5000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "181 epoch,  6000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "181 epoch,  7000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "181 epoch,  8000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "181 epoch,  9000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "181 epoch, 10000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "181 epoch, 11000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "181 epoch, 12000 iteration, loss:0.372\n",
      " num 180 epoch \n",
      "####### Training Loss #######\n",
      "[0.33229065]\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "182 epoch,  1000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "182 epoch,  2000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "182 epoch,  3000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "182 epoch,  4000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "182 epoch,  5000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "182 epoch,  6000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "182 epoch,  7000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "182 epoch,  8000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "182 epoch,  9000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "182 epoch, 10000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "182 epoch, 11000 iteration, loss:0.377\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "182 epoch, 12000 iteration, loss:0.364\n",
      " num 181 epoch \n",
      "####### Training Loss #######\n",
      "[0.33152369]\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "183 epoch,  1000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "183 epoch,  2000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "183 epoch,  3000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "183 epoch,  4000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "183 epoch,  5000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "183 epoch,  6000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "183 epoch,  7000 iteration, loss:0.379\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "183 epoch,  8000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "183 epoch,  9000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "183 epoch, 10000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "183 epoch, 11000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "183 epoch, 12000 iteration, loss:0.373\n",
      " num 182 epoch \n",
      "####### Training Loss #######\n",
      "[0.33486118]\n",
      "Checking accuracy on validation set\n",
      "Got 805 / 1000 correct (80.50)\n",
      "184 epoch,  1000 iteration, loss:0.304\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "184 epoch,  2000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "184 epoch,  3000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 805 / 1000 correct (80.50)\n",
      "184 epoch,  4000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "184 epoch,  5000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "184 epoch,  6000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "184 epoch,  7000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "184 epoch,  8000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 851 / 1000 correct (85.10)\n",
      "184 epoch,  9000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "184 epoch, 10000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "184 epoch, 11000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "184 epoch, 12000 iteration, loss:0.359\n",
      " num 183 epoch \n",
      "####### Training Loss #######\n",
      "[0.33338436]\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "185 epoch,  1000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "185 epoch,  2000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "185 epoch,  3000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "185 epoch,  4000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "185 epoch,  5000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "185 epoch,  6000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "185 epoch,  7000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "185 epoch,  8000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "185 epoch,  9000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "185 epoch, 10000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "185 epoch, 11000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "185 epoch, 12000 iteration, loss:0.370\n",
      " num 184 epoch \n",
      "####### Training Loss #######\n",
      "[0.3305684]\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "186 epoch,  1000 iteration, loss:0.289\n",
      "Checking accuracy on validation set\n",
      "Got 798 / 1000 correct (79.80)\n",
      "186 epoch,  2000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "186 epoch,  3000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "186 epoch,  4000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "186 epoch,  5000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "186 epoch,  6000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "186 epoch,  7000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "186 epoch,  8000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "186 epoch,  9000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "186 epoch, 10000 iteration, loss:0.377\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "186 epoch, 11000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "186 epoch, 12000 iteration, loss:0.372\n",
      " num 185 epoch \n",
      "####### Training Loss #######\n",
      "[0.3324507]\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "187 epoch,  1000 iteration, loss:0.289\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "187 epoch,  2000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "187 epoch,  3000 iteration, loss:0.311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "187 epoch,  4000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "187 epoch,  5000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "187 epoch,  6000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "187 epoch,  7000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 851 / 1000 correct (85.10)\n",
      "187 epoch,  8000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "187 epoch,  9000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "187 epoch, 10000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "187 epoch, 11000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "187 epoch, 12000 iteration, loss:0.381\n",
      " num 186 epoch \n",
      "####### Training Loss #######\n",
      "[0.32986372]\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "188 epoch,  1000 iteration, loss:0.299\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "188 epoch,  2000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "188 epoch,  3000 iteration, loss:0.310\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "188 epoch,  4000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "188 epoch,  5000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "188 epoch,  6000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "188 epoch,  7000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "188 epoch,  8000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "188 epoch,  9000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 802 / 1000 correct (80.20)\n",
      "188 epoch, 10000 iteration, loss:0.375\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "188 epoch, 11000 iteration, loss:0.394\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "188 epoch, 12000 iteration, loss:0.353\n",
      " num 187 epoch \n",
      "####### Training Loss #######\n",
      "[0.33597118]\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "189 epoch,  1000 iteration, loss:0.285\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "189 epoch,  2000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "189 epoch,  3000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "189 epoch,  4000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "189 epoch,  5000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "189 epoch,  6000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "189 epoch,  7000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "189 epoch,  8000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "189 epoch,  9000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "189 epoch, 10000 iteration, loss:0.375\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "189 epoch, 11000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "189 epoch, 12000 iteration, loss:0.363\n",
      " num 188 epoch \n",
      "####### Training Loss #######\n",
      "[0.33008234]\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "190 epoch,  1000 iteration, loss:0.291\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "190 epoch,  2000 iteration, loss:0.295\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "190 epoch,  3000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "190 epoch,  4000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "190 epoch,  5000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "190 epoch,  6000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "190 epoch,  7000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "190 epoch,  8000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "190 epoch,  9000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "190 epoch, 10000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "190 epoch, 11000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "190 epoch, 12000 iteration, loss:0.368\n",
      " num 189 epoch \n",
      "####### Training Loss #######\n",
      "[0.33026072]\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "191 epoch,  1000 iteration, loss:0.303\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "191 epoch,  2000 iteration, loss:0.302\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "191 epoch,  3000 iteration, loss:0.293\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "191 epoch,  4000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "191 epoch,  5000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "191 epoch,  6000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "191 epoch,  7000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "191 epoch,  8000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "191 epoch,  9000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "191 epoch, 10000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "191 epoch, 11000 iteration, loss:0.385\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "191 epoch, 12000 iteration, loss:0.363\n",
      " num 190 epoch \n",
      "####### Training Loss #######\n",
      "[0.33065207]\n",
      "Checking accuracy on validation set\n",
      "Got 852 / 1000 correct (85.20)\n",
      "192 epoch,  1000 iteration, loss:0.293\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "192 epoch,  2000 iteration, loss:0.309\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "192 epoch,  3000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "192 epoch,  4000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "192 epoch,  5000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "192 epoch,  6000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "192 epoch,  7000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "192 epoch,  8000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "192 epoch,  9000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "192 epoch, 10000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "192 epoch, 11000 iteration, loss:0.376\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "192 epoch, 12000 iteration, loss:0.371\n",
      " num 191 epoch \n",
      "####### Training Loss #######\n",
      "[0.33118763]\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "193 epoch,  1000 iteration, loss:0.279\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "193 epoch,  2000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "193 epoch,  3000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "193 epoch,  4000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "193 epoch,  5000 iteration, loss:0.319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "193 epoch,  6000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "193 epoch,  7000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "193 epoch,  8000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 794 / 1000 correct (79.40)\n",
      "193 epoch,  9000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "193 epoch, 10000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "193 epoch, 11000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "193 epoch, 12000 iteration, loss:0.386\n",
      " num 192 epoch \n",
      "####### Training Loss #######\n",
      "[0.33359134]\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "194 epoch,  1000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "194 epoch,  2000 iteration, loss:0.319\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "194 epoch,  3000 iteration, loss:0.307\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "194 epoch,  4000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10)\n",
      "194 epoch,  5000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "194 epoch,  6000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "194 epoch,  7000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "194 epoch,  8000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "194 epoch,  9000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "194 epoch, 10000 iteration, loss:0.371\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "194 epoch, 11000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "194 epoch, 12000 iteration, loss:0.354\n",
      " num 193 epoch \n",
      "####### Training Loss #######\n",
      "[0.33179409]\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "195 epoch,  1000 iteration, loss:0.304\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "195 epoch,  2000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "195 epoch,  3000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "195 epoch,  4000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "195 epoch,  5000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "195 epoch,  6000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "195 epoch,  7000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "195 epoch,  8000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "195 epoch,  9000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "195 epoch, 10000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "195 epoch, 11000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "195 epoch, 12000 iteration, loss:0.365\n",
      " num 194 epoch \n",
      "####### Training Loss #######\n",
      "[0.3311989]\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "196 epoch,  1000 iteration, loss:0.290\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "196 epoch,  2000 iteration, loss:0.296\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "196 epoch,  3000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "196 epoch,  4000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "196 epoch,  5000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "196 epoch,  6000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "196 epoch,  7000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "196 epoch,  8000 iteration, loss:0.375\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "196 epoch,  9000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "196 epoch, 10000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "196 epoch, 11000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "196 epoch, 12000 iteration, loss:0.370\n",
      " num 195 epoch \n",
      "####### Training Loss #######\n",
      "[0.33310187]\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "197 epoch,  1000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "197 epoch,  2000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "197 epoch,  3000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "197 epoch,  4000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "197 epoch,  5000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "197 epoch,  6000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "197 epoch,  7000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "197 epoch,  8000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "197 epoch,  9000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "197 epoch, 10000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "197 epoch, 11000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 802 / 1000 correct (80.20)\n",
      "197 epoch, 12000 iteration, loss:0.368\n",
      " num 196 epoch \n",
      "####### Training Loss #######\n",
      "[0.33466252]\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "198 epoch,  1000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "198 epoch,  2000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "198 epoch,  3000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "198 epoch,  4000 iteration, loss:0.307\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "198 epoch,  5000 iteration, loss:0.315\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "198 epoch,  6000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "198 epoch,  7000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "198 epoch,  8000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 786 / 1000 correct (78.60)\n",
      "198 epoch,  9000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "198 epoch, 10000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "198 epoch, 11000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "198 epoch, 12000 iteration, loss:0.339\n",
      " num 197 epoch \n",
      "####### Training Loss #######\n",
      "[0.32789613]\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "199 epoch,  1000 iteration, loss:0.304\n",
      "Checking accuracy on validation set\n",
      "Got 796 / 1000 correct (79.60)\n",
      "199 epoch,  2000 iteration, loss:0.297\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "199 epoch,  3000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "199 epoch,  4000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "199 epoch,  5000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "199 epoch,  6000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "199 epoch,  7000 iteration, loss:0.348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "199 epoch,  8000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "199 epoch,  9000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 802 / 1000 correct (80.20)\n",
      "199 epoch, 10000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "199 epoch, 11000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "199 epoch, 12000 iteration, loss:0.373\n",
      " num 198 epoch \n",
      "####### Training Loss #######\n",
      "[0.33185748]\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "200 epoch,  1000 iteration, loss:0.295\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "200 epoch,  2000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "200 epoch,  3000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "200 epoch,  4000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "200 epoch,  5000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "200 epoch,  6000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "200 epoch,  7000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "200 epoch,  8000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "200 epoch,  9000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "200 epoch, 10000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "200 epoch, 11000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "200 epoch, 12000 iteration, loss:0.377\n",
      " num 199 epoch \n",
      "####### Training Loss #######\n",
      "[0.33001931]\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "201 epoch,  1000 iteration, loss:0.272\n",
      "Checking accuracy on validation set\n",
      "Got 851 / 1000 correct (85.10)\n",
      "201 epoch,  2000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "201 epoch,  3000 iteration, loss:0.302\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "201 epoch,  4000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "201 epoch,  5000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "201 epoch,  6000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "201 epoch,  7000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "201 epoch,  8000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "201 epoch,  9000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "201 epoch, 10000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "201 epoch, 11000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "201 epoch, 12000 iteration, loss:0.358\n",
      " num 200 epoch \n",
      "####### Training Loss #######\n",
      "[0.32931316]\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "202 epoch,  1000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "202 epoch,  2000 iteration, loss:0.310\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "202 epoch,  3000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "202 epoch,  4000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "202 epoch,  5000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "202 epoch,  6000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "202 epoch,  7000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "202 epoch,  8000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "202 epoch,  9000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "202 epoch, 10000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "202 epoch, 11000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "202 epoch, 12000 iteration, loss:0.374\n",
      " num 201 epoch \n",
      "####### Training Loss #######\n",
      "[0.33393462]\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "203 epoch,  1000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "203 epoch,  2000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "203 epoch,  3000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "203 epoch,  4000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "203 epoch,  5000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "203 epoch,  6000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "203 epoch,  7000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "203 epoch,  8000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "203 epoch,  9000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "203 epoch, 10000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "203 epoch, 11000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "203 epoch, 12000 iteration, loss:0.374\n",
      " num 202 epoch \n",
      "####### Training Loss #######\n",
      "[0.32983971]\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "204 epoch,  1000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "204 epoch,  2000 iteration, loss:0.310\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "204 epoch,  3000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "204 epoch,  4000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "204 epoch,  5000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "204 epoch,  6000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "204 epoch,  7000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "204 epoch,  8000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "204 epoch,  9000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "204 epoch, 10000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "204 epoch, 11000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "204 epoch, 12000 iteration, loss:0.346\n",
      " num 203 epoch \n",
      "####### Training Loss #######\n",
      "[0.33133721]\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "205 epoch,  1000 iteration, loss:0.287\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "205 epoch,  2000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "205 epoch,  3000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 792 / 1000 correct (79.20)\n",
      "205 epoch,  4000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "205 epoch,  5000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "205 epoch,  6000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "205 epoch,  7000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "205 epoch,  8000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "205 epoch,  9000 iteration, loss:0.345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "205 epoch, 10000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "205 epoch, 11000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "205 epoch, 12000 iteration, loss:0.385\n",
      " num 204 epoch \n",
      "####### Training Loss #######\n",
      "[0.33000508]\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "206 epoch,  1000 iteration, loss:0.294\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "206 epoch,  2000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "206 epoch,  3000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "206 epoch,  4000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "206 epoch,  5000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "206 epoch,  6000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "206 epoch,  7000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "206 epoch,  8000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "206 epoch,  9000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "206 epoch, 10000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "206 epoch, 11000 iteration, loss:0.379\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "206 epoch, 12000 iteration, loss:0.361\n",
      " num 205 epoch \n",
      "####### Training Loss #######\n",
      "[0.33367549]\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "207 epoch,  1000 iteration, loss:0.294\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "207 epoch,  2000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "207 epoch,  3000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "207 epoch,  4000 iteration, loss:0.307\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "207 epoch,  5000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "207 epoch,  6000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "207 epoch,  7000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "207 epoch,  8000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "207 epoch,  9000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "207 epoch, 10000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "207 epoch, 11000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 851 / 1000 correct (85.10)\n",
      "207 epoch, 12000 iteration, loss:0.364\n",
      " num 206 epoch \n",
      "####### Training Loss #######\n",
      "[0.32663912]\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "208 epoch,  1000 iteration, loss:0.296\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "208 epoch,  2000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "208 epoch,  3000 iteration, loss:0.304\n",
      "Checking accuracy on validation set\n",
      "Got 856 / 1000 correct (85.60)\n",
      "208 epoch,  4000 iteration, loss:0.309\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "208 epoch,  5000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "208 epoch,  6000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "208 epoch,  7000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "208 epoch,  8000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "208 epoch,  9000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "208 epoch, 10000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "208 epoch, 11000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "208 epoch, 12000 iteration, loss:0.374\n",
      " num 207 epoch \n",
      "####### Training Loss #######\n",
      "[0.3321049]\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "209 epoch,  1000 iteration, loss:0.297\n",
      "Checking accuracy on validation set\n",
      "Got 852 / 1000 correct (85.20)\n",
      "209 epoch,  2000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "209 epoch,  3000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30)\n",
      "209 epoch,  4000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "209 epoch,  5000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "209 epoch,  6000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "209 epoch,  7000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "209 epoch,  8000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "209 epoch,  9000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "209 epoch, 10000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "209 epoch, 11000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "209 epoch, 12000 iteration, loss:0.373\n",
      " num 208 epoch \n",
      "####### Training Loss #######\n",
      "[0.33028779]\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "210 epoch,  1000 iteration, loss:0.297\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "210 epoch,  2000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "210 epoch,  3000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "210 epoch,  4000 iteration, loss:0.319\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "210 epoch,  5000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "210 epoch,  6000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "210 epoch,  7000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "210 epoch,  8000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "210 epoch,  9000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "210 epoch, 10000 iteration, loss:0.382\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "210 epoch, 11000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "210 epoch, 12000 iteration, loss:0.363\n",
      " num 209 epoch \n",
      "####### Training Loss #######\n",
      "[0.3305092]\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "211 epoch,  1000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "211 epoch,  2000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "211 epoch,  3000 iteration, loss:0.315\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "211 epoch,  4000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "211 epoch,  5000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "211 epoch,  6000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 798 / 1000 correct (79.80)\n",
      "211 epoch,  7000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "211 epoch,  8000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "211 epoch,  9000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "211 epoch, 10000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "211 epoch, 11000 iteration, loss:0.363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "211 epoch, 12000 iteration, loss:0.369\n",
      " num 210 epoch \n",
      "####### Training Loss #######\n",
      "[0.33389892]\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "212 epoch,  1000 iteration, loss:0.302\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "212 epoch,  2000 iteration, loss:0.288\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "212 epoch,  3000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "212 epoch,  4000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "212 epoch,  5000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "212 epoch,  6000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "212 epoch,  7000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "212 epoch,  8000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "212 epoch,  9000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "212 epoch, 10000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "212 epoch, 11000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "212 epoch, 12000 iteration, loss:0.354\n",
      " num 211 epoch \n",
      "####### Training Loss #######\n",
      "[0.32603547]\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "213 epoch,  1000 iteration, loss:0.299\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "213 epoch,  2000 iteration, loss:0.309\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "213 epoch,  3000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "213 epoch,  4000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "213 epoch,  5000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "213 epoch,  6000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "213 epoch,  7000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "213 epoch,  8000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "213 epoch,  9000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "213 epoch, 10000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "213 epoch, 11000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 794 / 1000 correct (79.40)\n",
      "213 epoch, 12000 iteration, loss:0.385\n",
      " num 212 epoch \n",
      "####### Training Loss #######\n",
      "[0.32986386]\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "214 epoch,  1000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "214 epoch,  2000 iteration, loss:0.300\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "214 epoch,  3000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "214 epoch,  4000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "214 epoch,  5000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "214 epoch,  6000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "214 epoch,  7000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "214 epoch,  8000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "214 epoch,  9000 iteration, loss:0.371\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "214 epoch, 10000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "214 epoch, 11000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "214 epoch, 12000 iteration, loss:0.362\n",
      " num 213 epoch \n",
      "####### Training Loss #######\n",
      "[0.32873192]\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "215 epoch,  1000 iteration, loss:0.300\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "215 epoch,  2000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "215 epoch,  3000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "215 epoch,  4000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "215 epoch,  5000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "215 epoch,  6000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "215 epoch,  7000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "215 epoch,  8000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "215 epoch,  9000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "215 epoch, 10000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "215 epoch, 11000 iteration, loss:0.371\n",
      "Checking accuracy on validation set\n",
      "Got 800 / 1000 correct (80.00)\n",
      "215 epoch, 12000 iteration, loss:0.351\n",
      " num 214 epoch \n",
      "####### Training Loss #######\n",
      "[0.3329469]\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "216 epoch,  1000 iteration, loss:0.290\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "216 epoch,  2000 iteration, loss:0.292\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "216 epoch,  3000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "216 epoch,  4000 iteration, loss:0.316\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "216 epoch,  5000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "216 epoch,  6000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "216 epoch,  7000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "216 epoch,  8000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "216 epoch,  9000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "216 epoch, 10000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "216 epoch, 11000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "216 epoch, 12000 iteration, loss:0.367\n",
      " num 215 epoch \n",
      "####### Training Loss #######\n",
      "[0.33117404]\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "217 epoch,  1000 iteration, loss:0.315\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "217 epoch,  2000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "217 epoch,  3000 iteration, loss:0.294\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "217 epoch,  4000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "217 epoch,  5000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "217 epoch,  6000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "217 epoch,  7000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "217 epoch,  8000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "217 epoch,  9000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "217 epoch, 10000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "217 epoch, 11000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "217 epoch, 12000 iteration, loss:0.358\n",
      " num 216 epoch \n",
      "####### Training Loss #######\n",
      "[0.32585479]\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "218 epoch,  1000 iteration, loss:0.297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "218 epoch,  2000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "218 epoch,  3000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "218 epoch,  4000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "218 epoch,  5000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "218 epoch,  6000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "218 epoch,  7000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "218 epoch,  8000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "218 epoch,  9000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "218 epoch, 10000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "218 epoch, 11000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "218 epoch, 12000 iteration, loss:0.376\n",
      " num 217 epoch \n",
      "####### Training Loss #######\n",
      "[0.33439943]\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "219 epoch,  1000 iteration, loss:0.289\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "219 epoch,  2000 iteration, loss:0.315\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "219 epoch,  3000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "219 epoch,  4000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "219 epoch,  5000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "219 epoch,  6000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "219 epoch,  7000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "219 epoch,  8000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "219 epoch,  9000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "219 epoch, 10000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "219 epoch, 11000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "219 epoch, 12000 iteration, loss:0.348\n",
      " num 218 epoch \n",
      "####### Training Loss #######\n",
      "[0.32871625]\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "220 epoch,  1000 iteration, loss:0.295\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "220 epoch,  2000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "220 epoch,  3000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "220 epoch,  4000 iteration, loss:0.310\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "220 epoch,  5000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "220 epoch,  6000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "220 epoch,  7000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "220 epoch,  8000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "220 epoch,  9000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "220 epoch, 10000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "220 epoch, 11000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "220 epoch, 12000 iteration, loss:0.364\n",
      " num 219 epoch \n",
      "####### Training Loss #######\n",
      "[0.33398887]\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "221 epoch,  1000 iteration, loss:0.296\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "221 epoch,  2000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "221 epoch,  3000 iteration, loss:0.310\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "221 epoch,  4000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "221 epoch,  5000 iteration, loss:0.315\n",
      "Checking accuracy on validation set\n",
      "Got 802 / 1000 correct (80.20)\n",
      "221 epoch,  6000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "221 epoch,  7000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "221 epoch,  8000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "221 epoch,  9000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "221 epoch, 10000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "221 epoch, 11000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "221 epoch, 12000 iteration, loss:0.358\n",
      " num 220 epoch \n",
      "####### Training Loss #######\n",
      "[0.33227423]\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "222 epoch,  1000 iteration, loss:0.304\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "222 epoch,  2000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "222 epoch,  3000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "222 epoch,  4000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "222 epoch,  5000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "222 epoch,  6000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "222 epoch,  7000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "222 epoch,  8000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "222 epoch,  9000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "222 epoch, 10000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "222 epoch, 11000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "222 epoch, 12000 iteration, loss:0.363\n",
      " num 221 epoch \n",
      "####### Training Loss #######\n",
      "[0.3326877]\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "223 epoch,  1000 iteration, loss:0.280\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "223 epoch,  2000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "223 epoch,  3000 iteration, loss:0.303\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "223 epoch,  4000 iteration, loss:0.307\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "223 epoch,  5000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "223 epoch,  6000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "223 epoch,  7000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "223 epoch,  8000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "223 epoch,  9000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "223 epoch, 10000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "223 epoch, 11000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "223 epoch, 12000 iteration, loss:0.338\n",
      " num 222 epoch \n",
      "####### Training Loss #######\n",
      "[0.32622861]\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "224 epoch,  1000 iteration, loss:0.284\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "224 epoch,  2000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "224 epoch,  3000 iteration, loss:0.305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "224 epoch,  4000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "224 epoch,  5000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "224 epoch,  6000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "224 epoch,  7000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "224 epoch,  8000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "224 epoch,  9000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "224 epoch, 10000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "224 epoch, 11000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "224 epoch, 12000 iteration, loss:0.360\n",
      " num 223 epoch \n",
      "####### Training Loss #######\n",
      "[0.32971122]\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "225 epoch,  1000 iteration, loss:0.288\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "225 epoch,  2000 iteration, loss:0.304\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "225 epoch,  3000 iteration, loss:0.316\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "225 epoch,  4000 iteration, loss:0.319\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "225 epoch,  5000 iteration, loss:0.319\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "225 epoch,  6000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "225 epoch,  7000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "225 epoch,  8000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "225 epoch,  9000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "225 epoch, 10000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "225 epoch, 11000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "225 epoch, 12000 iteration, loss:0.385\n",
      " num 224 epoch \n",
      "####### Training Loss #######\n",
      "[0.32927452]\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "226 epoch,  1000 iteration, loss:0.291\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "226 epoch,  2000 iteration, loss:0.295\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "226 epoch,  3000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "226 epoch,  4000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "226 epoch,  5000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "226 epoch,  6000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "226 epoch,  7000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "226 epoch,  8000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 795 / 1000 correct (79.50)\n",
      "226 epoch,  9000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "226 epoch, 10000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "226 epoch, 11000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "226 epoch, 12000 iteration, loss:0.345\n",
      " num 225 epoch \n",
      "####### Training Loss #######\n",
      "[0.32908768]\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "227 epoch,  1000 iteration, loss:0.300\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "227 epoch,  2000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "227 epoch,  3000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "227 epoch,  4000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "227 epoch,  5000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "227 epoch,  6000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "227 epoch,  7000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "227 epoch,  8000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "227 epoch,  9000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "227 epoch, 10000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "227 epoch, 11000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "227 epoch, 12000 iteration, loss:0.374\n",
      " num 226 epoch \n",
      "####### Training Loss #######\n",
      "[0.33064493]\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "228 epoch,  1000 iteration, loss:0.295\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "228 epoch,  2000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "228 epoch,  3000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 800 / 1000 correct (80.00)\n",
      "228 epoch,  4000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "228 epoch,  5000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "228 epoch,  6000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "228 epoch,  7000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "228 epoch,  8000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "228 epoch,  9000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "228 epoch, 10000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "228 epoch, 11000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "228 epoch, 12000 iteration, loss:0.362\n",
      " num 227 epoch \n",
      "####### Training Loss #######\n",
      "[0.3295242]\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "229 epoch,  1000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "229 epoch,  2000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "229 epoch,  3000 iteration, loss:0.307\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "229 epoch,  4000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "229 epoch,  5000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "229 epoch,  6000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30)\n",
      "229 epoch,  7000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "229 epoch,  8000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "229 epoch,  9000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "229 epoch, 10000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "229 epoch, 11000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "229 epoch, 12000 iteration, loss:0.353\n",
      " num 228 epoch \n",
      "####### Training Loss #######\n",
      "[0.33369082]\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "230 epoch,  1000 iteration, loss:0.300\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "230 epoch,  2000 iteration, loss:0.299\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "230 epoch,  3000 iteration, loss:0.295\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "230 epoch,  4000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "230 epoch,  5000 iteration, loss:0.327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "230 epoch,  6000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "230 epoch,  7000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "230 epoch,  8000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "230 epoch,  9000 iteration, loss:0.372\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "230 epoch, 10000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "230 epoch, 11000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "230 epoch, 12000 iteration, loss:0.381\n",
      " num 229 epoch \n",
      "####### Training Loss #######\n",
      "[0.32949929]\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "231 epoch,  1000 iteration, loss:0.279\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "231 epoch,  2000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "231 epoch,  3000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "231 epoch,  4000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "231 epoch,  5000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "231 epoch,  6000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "231 epoch,  7000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "231 epoch,  8000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "231 epoch,  9000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 795 / 1000 correct (79.50)\n",
      "231 epoch, 10000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 800 / 1000 correct (80.00)\n",
      "231 epoch, 11000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "231 epoch, 12000 iteration, loss:0.356\n",
      " num 230 epoch \n",
      "####### Training Loss #######\n",
      "[0.3318852]\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "232 epoch,  1000 iteration, loss:0.296\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "232 epoch,  2000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "232 epoch,  3000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "232 epoch,  4000 iteration, loss:0.315\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "232 epoch,  5000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "232 epoch,  6000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "232 epoch,  7000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "232 epoch,  8000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "232 epoch,  9000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "232 epoch, 10000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "232 epoch, 11000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "232 epoch, 12000 iteration, loss:0.370\n",
      " num 231 epoch \n",
      "####### Training Loss #######\n",
      "[0.33159468]\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "233 epoch,  1000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "233 epoch,  2000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "233 epoch,  3000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "233 epoch,  4000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "233 epoch,  5000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "233 epoch,  6000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 850 / 1000 correct (85.00)\n",
      "233 epoch,  7000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "233 epoch,  8000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "233 epoch,  9000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "233 epoch, 10000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "233 epoch, 11000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "233 epoch, 12000 iteration, loss:0.362\n",
      " num 232 epoch \n",
      "####### Training Loss #######\n",
      "[0.33407623]\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "234 epoch,  1000 iteration, loss:0.283\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "234 epoch,  2000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "234 epoch,  3000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "234 epoch,  4000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "234 epoch,  5000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "234 epoch,  6000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "234 epoch,  7000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "234 epoch,  8000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "234 epoch,  9000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "234 epoch, 10000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "234 epoch, 11000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "234 epoch, 12000 iteration, loss:0.368\n",
      " num 233 epoch \n",
      "####### Training Loss #######\n",
      "[0.32886431]\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "235 epoch,  1000 iteration, loss:0.299\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "235 epoch,  2000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "235 epoch,  3000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "235 epoch,  4000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "235 epoch,  5000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "235 epoch,  6000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "235 epoch,  7000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "235 epoch,  8000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "235 epoch,  9000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "235 epoch, 10000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "235 epoch, 11000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "235 epoch, 12000 iteration, loss:0.371\n",
      " num 234 epoch \n",
      "####### Training Loss #######\n",
      "[0.32491329]\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "236 epoch,  1000 iteration, loss:0.281\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "236 epoch,  2000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "236 epoch,  3000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "236 epoch,  4000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "236 epoch,  5000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "236 epoch,  6000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "236 epoch,  7000 iteration, loss:0.338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "236 epoch,  8000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "236 epoch,  9000 iteration, loss:0.379\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "236 epoch, 10000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "236 epoch, 11000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "236 epoch, 12000 iteration, loss:0.356\n",
      " num 235 epoch \n",
      "####### Training Loss #######\n",
      "[0.33225122]\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "237 epoch,  1000 iteration, loss:0.304\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "237 epoch,  2000 iteration, loss:0.310\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "237 epoch,  3000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "237 epoch,  4000 iteration, loss:0.310\n",
      "Checking accuracy on validation set\n",
      "Got 784 / 1000 correct (78.40)\n",
      "237 epoch,  5000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "237 epoch,  6000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "237 epoch,  7000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "237 epoch,  8000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "237 epoch,  9000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "237 epoch, 10000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "237 epoch, 11000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "237 epoch, 12000 iteration, loss:0.342\n",
      " num 236 epoch \n",
      "####### Training Loss #######\n",
      "[0.33186852]\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "238 epoch,  1000 iteration, loss:0.294\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "238 epoch,  2000 iteration, loss:0.310\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "238 epoch,  3000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "238 epoch,  4000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "238 epoch,  5000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "238 epoch,  6000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "238 epoch,  7000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "238 epoch,  8000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "238 epoch,  9000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "238 epoch, 10000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "238 epoch, 11000 iteration, loss:0.380\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "238 epoch, 12000 iteration, loss:0.372\n",
      " num 237 epoch \n",
      "####### Training Loss #######\n",
      "[0.33157588]\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "239 epoch,  1000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "239 epoch,  2000 iteration, loss:0.303\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "239 epoch,  3000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 850 / 1000 correct (85.00)\n",
      "239 epoch,  4000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "239 epoch,  5000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "239 epoch,  6000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "239 epoch,  7000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "239 epoch,  8000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "239 epoch,  9000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "239 epoch, 10000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "239 epoch, 11000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "239 epoch, 12000 iteration, loss:0.362\n",
      " num 238 epoch \n",
      "####### Training Loss #######\n",
      "[0.32839063]\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "240 epoch,  1000 iteration, loss:0.303\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "240 epoch,  2000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "240 epoch,  3000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "240 epoch,  4000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "240 epoch,  5000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "240 epoch,  6000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "240 epoch,  7000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "240 epoch,  8000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "240 epoch,  9000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "240 epoch, 10000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 792 / 1000 correct (79.20)\n",
      "240 epoch, 11000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "240 epoch, 12000 iteration, loss:0.342\n",
      " num 239 epoch \n",
      "####### Training Loss #######\n",
      "[0.32732807]\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "241 epoch,  1000 iteration, loss:0.296\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "241 epoch,  2000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "241 epoch,  3000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "241 epoch,  4000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "241 epoch,  5000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "241 epoch,  6000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "241 epoch,  7000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "241 epoch,  8000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "241 epoch,  9000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 794 / 1000 correct (79.40)\n",
      "241 epoch, 10000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "241 epoch, 11000 iteration, loss:0.377\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "241 epoch, 12000 iteration, loss:0.340\n",
      " num 240 epoch \n",
      "####### Training Loss #######\n",
      "[0.33318679]\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "242 epoch,  1000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "242 epoch,  2000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "242 epoch,  3000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "242 epoch,  4000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "242 epoch,  5000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 805 / 1000 correct (80.50)\n",
      "242 epoch,  6000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "242 epoch,  7000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "242 epoch,  8000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "242 epoch,  9000 iteration, loss:0.348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "242 epoch, 10000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "242 epoch, 11000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "242 epoch, 12000 iteration, loss:0.382\n",
      " num 241 epoch \n",
      "####### Training Loss #######\n",
      "[0.33078787]\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "243 epoch,  1000 iteration, loss:0.315\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "243 epoch,  2000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "243 epoch,  3000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "243 epoch,  4000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "243 epoch,  5000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "243 epoch,  6000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "243 epoch,  7000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "243 epoch,  8000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 783 / 1000 correct (78.30)\n",
      "243 epoch,  9000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "243 epoch, 10000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "243 epoch, 11000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "243 epoch, 12000 iteration, loss:0.366\n",
      " num 242 epoch \n",
      "####### Training Loss #######\n",
      "[0.32995262]\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "244 epoch,  1000 iteration, loss:0.296\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "244 epoch,  2000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "244 epoch,  3000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "244 epoch,  4000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "244 epoch,  5000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "244 epoch,  6000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "244 epoch,  7000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "244 epoch,  8000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "244 epoch,  9000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "244 epoch, 10000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "244 epoch, 11000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "244 epoch, 12000 iteration, loss:0.354\n",
      " num 243 epoch \n",
      "####### Training Loss #######\n",
      "[0.32841043]\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "245 epoch,  1000 iteration, loss:0.284\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "245 epoch,  2000 iteration, loss:0.279\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "245 epoch,  3000 iteration, loss:0.319\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "245 epoch,  4000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "245 epoch,  5000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "245 epoch,  6000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "245 epoch,  7000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "245 epoch,  8000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "245 epoch,  9000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10)\n",
      "245 epoch, 10000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "245 epoch, 11000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "245 epoch, 12000 iteration, loss:0.363\n",
      " num 244 epoch \n",
      "####### Training Loss #######\n",
      "[0.32015223]\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "246 epoch,  1000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "246 epoch,  2000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "246 epoch,  3000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "246 epoch,  4000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "246 epoch,  5000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "246 epoch,  6000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "246 epoch,  7000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "246 epoch,  8000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "246 epoch,  9000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 802 / 1000 correct (80.20)\n",
      "246 epoch, 10000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "246 epoch, 11000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "246 epoch, 12000 iteration, loss:0.353\n",
      " num 245 epoch \n",
      "####### Training Loss #######\n",
      "[0.33059073]\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "247 epoch,  1000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "247 epoch,  2000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "247 epoch,  3000 iteration, loss:0.316\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "247 epoch,  4000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 793 / 1000 correct (79.30)\n",
      "247 epoch,  5000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "247 epoch,  6000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "247 epoch,  7000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "247 epoch,  8000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "247 epoch,  9000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "247 epoch, 10000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "247 epoch, 11000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "247 epoch, 12000 iteration, loss:0.359\n",
      " num 246 epoch \n",
      "####### Training Loss #######\n",
      "[0.33423633]\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "248 epoch,  1000 iteration, loss:0.284\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "248 epoch,  2000 iteration, loss:0.310\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "248 epoch,  3000 iteration, loss:0.316\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "248 epoch,  4000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "248 epoch,  5000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "248 epoch,  6000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "248 epoch,  7000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "248 epoch,  8000 iteration, loss:0.376\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "248 epoch,  9000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "248 epoch, 10000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "248 epoch, 11000 iteration, loss:0.366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30)\n",
      "248 epoch, 12000 iteration, loss:0.360\n",
      " num 247 epoch \n",
      "####### Training Loss #######\n",
      "[0.3308083]\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "249 epoch,  1000 iteration, loss:0.295\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "249 epoch,  2000 iteration, loss:0.310\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "249 epoch,  3000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "249 epoch,  4000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "249 epoch,  5000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "249 epoch,  6000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "249 epoch,  7000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "249 epoch,  8000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "249 epoch,  9000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "249 epoch, 10000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "249 epoch, 11000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "249 epoch, 12000 iteration, loss:0.385\n",
      " num 248 epoch \n",
      "####### Training Loss #######\n",
      "[0.32797779]\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "250 epoch,  1000 iteration, loss:0.293\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "250 epoch,  2000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "250 epoch,  3000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "250 epoch,  4000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "250 epoch,  5000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "250 epoch,  6000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "250 epoch,  7000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "250 epoch,  8000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "250 epoch,  9000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "250 epoch, 10000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "250 epoch, 11000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "250 epoch, 12000 iteration, loss:0.353\n",
      " num 249 epoch \n",
      "####### Training Loss #######\n",
      "[0.32960356]\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "251 epoch,  1000 iteration, loss:0.286\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "251 epoch,  2000 iteration, loss:0.294\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "251 epoch,  3000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "251 epoch,  4000 iteration, loss:0.315\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "251 epoch,  5000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "251 epoch,  6000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "251 epoch,  7000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "251 epoch,  8000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "251 epoch,  9000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "251 epoch, 10000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "251 epoch, 11000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "251 epoch, 12000 iteration, loss:0.372\n",
      " num 250 epoch \n",
      "####### Training Loss #######\n",
      "[0.32756657]\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "252 epoch,  1000 iteration, loss:0.307\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "252 epoch,  2000 iteration, loss:0.299\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "252 epoch,  3000 iteration, loss:0.304\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "252 epoch,  4000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "252 epoch,  5000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "252 epoch,  6000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "252 epoch,  7000 iteration, loss:0.315\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "252 epoch,  8000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "252 epoch,  9000 iteration, loss:0.371\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "252 epoch, 10000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "252 epoch, 11000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "252 epoch, 12000 iteration, loss:0.370\n",
      " num 251 epoch \n",
      "####### Training Loss #######\n",
      "[0.3270585]\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "253 epoch,  1000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "253 epoch,  2000 iteration, loss:0.304\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "253 epoch,  3000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "253 epoch,  4000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "253 epoch,  5000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "253 epoch,  6000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "253 epoch,  7000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "253 epoch,  8000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "253 epoch,  9000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "253 epoch, 10000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "253 epoch, 11000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "253 epoch, 12000 iteration, loss:0.357\n",
      " num 252 epoch \n",
      "####### Training Loss #######\n",
      "[0.33065908]\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "254 epoch,  1000 iteration, loss:0.304\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "254 epoch,  2000 iteration, loss:0.304\n",
      "Checking accuracy on validation set\n",
      "Got 785 / 1000 correct (78.50)\n",
      "254 epoch,  3000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "254 epoch,  4000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 798 / 1000 correct (79.80)\n",
      "254 epoch,  5000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "254 epoch,  6000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "254 epoch,  7000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "254 epoch,  8000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "254 epoch,  9000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "254 epoch, 10000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 779 / 1000 correct (77.90)\n",
      "254 epoch, 11000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "254 epoch, 12000 iteration, loss:0.357\n",
      " num 253 epoch \n",
      "####### Training Loss #######\n",
      "[0.32719518]\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "255 epoch,  1000 iteration, loss:0.279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "255 epoch,  2000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "255 epoch,  3000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "255 epoch,  4000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "255 epoch,  5000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "255 epoch,  6000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "255 epoch,  7000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "255 epoch,  8000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "255 epoch,  9000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "255 epoch, 10000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "255 epoch, 11000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "255 epoch, 12000 iteration, loss:0.343\n",
      " num 254 epoch \n",
      "####### Training Loss #######\n",
      "[0.33007724]\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "256 epoch,  1000 iteration, loss:0.300\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "256 epoch,  2000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "256 epoch,  3000 iteration, loss:0.294\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "256 epoch,  4000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "256 epoch,  5000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "256 epoch,  6000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "256 epoch,  7000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 796 / 1000 correct (79.60)\n",
      "256 epoch,  8000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 791 / 1000 correct (79.10)\n",
      "256 epoch,  9000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "256 epoch, 10000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "256 epoch, 11000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "256 epoch, 12000 iteration, loss:0.363\n",
      " num 255 epoch \n",
      "####### Training Loss #######\n",
      "[0.3249798]\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "257 epoch,  1000 iteration, loss:0.303\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "257 epoch,  2000 iteration, loss:0.304\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "257 epoch,  3000 iteration, loss:0.296\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "257 epoch,  4000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "257 epoch,  5000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "257 epoch,  6000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "257 epoch,  7000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "257 epoch,  8000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "257 epoch,  9000 iteration, loss:0.315\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "257 epoch, 10000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "257 epoch, 11000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "257 epoch, 12000 iteration, loss:0.366\n",
      " num 256 epoch \n",
      "####### Training Loss #######\n",
      "[0.32706333]\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "258 epoch,  1000 iteration, loss:0.319\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "258 epoch,  2000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "258 epoch,  3000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "258 epoch,  4000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "258 epoch,  5000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "258 epoch,  6000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "258 epoch,  7000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "258 epoch,  8000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "258 epoch,  9000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10)\n",
      "258 epoch, 10000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "258 epoch, 11000 iteration, loss:0.380\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "258 epoch, 12000 iteration, loss:0.346\n",
      " num 257 epoch \n",
      "####### Training Loss #######\n",
      "[0.33090587]\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "259 epoch,  1000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "259 epoch,  2000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "259 epoch,  3000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "259 epoch,  4000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "259 epoch,  5000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "259 epoch,  6000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "259 epoch,  7000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "259 epoch,  8000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "259 epoch,  9000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "259 epoch, 10000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "259 epoch, 11000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "259 epoch, 12000 iteration, loss:0.379\n",
      " num 258 epoch \n",
      "####### Training Loss #######\n",
      "[0.32789637]\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "260 epoch,  1000 iteration, loss:0.286\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "260 epoch,  2000 iteration, loss:0.309\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "260 epoch,  3000 iteration, loss:0.309\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "260 epoch,  4000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "260 epoch,  5000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "260 epoch,  6000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 858 / 1000 correct (85.80)\n",
      "260 epoch,  7000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "260 epoch,  8000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "260 epoch,  9000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "260 epoch, 10000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "260 epoch, 11000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "260 epoch, 12000 iteration, loss:0.341\n",
      " num 259 epoch \n",
      "####### Training Loss #######\n",
      "[0.32755848]\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "261 epoch,  1000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "261 epoch,  2000 iteration, loss:0.297\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "261 epoch,  3000 iteration, loss:0.320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "261 epoch,  4000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "261 epoch,  5000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "261 epoch,  6000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "261 epoch,  7000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "261 epoch,  8000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "261 epoch,  9000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "261 epoch, 10000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 792 / 1000 correct (79.20)\n",
      "261 epoch, 11000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "261 epoch, 12000 iteration, loss:0.337\n",
      " num 260 epoch \n",
      "####### Training Loss #######\n",
      "[0.32776962]\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "262 epoch,  1000 iteration, loss:0.296\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "262 epoch,  2000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "262 epoch,  3000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "262 epoch,  4000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "262 epoch,  5000 iteration, loss:0.307\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "262 epoch,  6000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "262 epoch,  7000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "262 epoch,  8000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "262 epoch,  9000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "262 epoch, 10000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "262 epoch, 11000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "262 epoch, 12000 iteration, loss:0.374\n",
      " num 261 epoch \n",
      "####### Training Loss #######\n",
      "[0.32211777]\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "263 epoch,  1000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "263 epoch,  2000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "263 epoch,  3000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "263 epoch,  4000 iteration, loss:0.297\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "263 epoch,  5000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "263 epoch,  6000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "263 epoch,  7000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 786 / 1000 correct (78.60)\n",
      "263 epoch,  8000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "263 epoch,  9000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "263 epoch, 10000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "263 epoch, 11000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "263 epoch, 12000 iteration, loss:0.364\n",
      " num 262 epoch \n",
      "####### Training Loss #######\n",
      "[0.33224552]\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "264 epoch,  1000 iteration, loss:0.298\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "264 epoch,  2000 iteration, loss:0.316\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "264 epoch,  3000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 799 / 1000 correct (79.90)\n",
      "264 epoch,  4000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "264 epoch,  5000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "264 epoch,  6000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "264 epoch,  7000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "264 epoch,  8000 iteration, loss:0.316\n",
      "Checking accuracy on validation set\n",
      "Got 854 / 1000 correct (85.40)\n",
      "264 epoch,  9000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "264 epoch, 10000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "264 epoch, 11000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 795 / 1000 correct (79.50)\n",
      "264 epoch, 12000 iteration, loss:0.347\n",
      " num 263 epoch \n",
      "####### Training Loss #######\n",
      "[0.32849764]\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "265 epoch,  1000 iteration, loss:0.299\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "265 epoch,  2000 iteration, loss:0.289\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "265 epoch,  3000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "265 epoch,  4000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "265 epoch,  5000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "265 epoch,  6000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "265 epoch,  7000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "265 epoch,  8000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "265 epoch,  9000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "265 epoch, 10000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "265 epoch, 11000 iteration, loss:0.384\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "265 epoch, 12000 iteration, loss:0.355\n",
      " num 264 epoch \n",
      "####### Training Loss #######\n",
      "[0.32940495]\n",
      "Checking accuracy on validation set\n",
      "Got 852 / 1000 correct (85.20)\n",
      "266 epoch,  1000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30)\n",
      "266 epoch,  2000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "266 epoch,  3000 iteration, loss:0.292\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "266 epoch,  4000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "266 epoch,  5000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "266 epoch,  6000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "266 epoch,  7000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "266 epoch,  8000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "266 epoch,  9000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "266 epoch, 10000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "266 epoch, 11000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 861 / 1000 correct (86.10)\n",
      "266 epoch, 12000 iteration, loss:0.364\n",
      " num 265 epoch \n",
      "####### Training Loss #######\n",
      "[0.32740488]\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "267 epoch,  1000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "267 epoch,  2000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "267 epoch,  3000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "267 epoch,  4000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "267 epoch,  5000 iteration, loss:0.312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "267 epoch,  6000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "267 epoch,  7000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "267 epoch,  8000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "267 epoch,  9000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "267 epoch, 10000 iteration, loss:0.377\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "267 epoch, 11000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "267 epoch, 12000 iteration, loss:0.356\n",
      " num 266 epoch \n",
      "####### Training Loss #######\n",
      "[0.3246982]\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "268 epoch,  1000 iteration, loss:0.303\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "268 epoch,  2000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "268 epoch,  3000 iteration, loss:0.299\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "268 epoch,  4000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "268 epoch,  5000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "268 epoch,  6000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "268 epoch,  7000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "268 epoch,  8000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "268 epoch,  9000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "268 epoch, 10000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "268 epoch, 11000 iteration, loss:0.378\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "268 epoch, 12000 iteration, loss:0.353\n",
      " num 267 epoch \n",
      "####### Training Loss #######\n",
      "[0.32896343]\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "269 epoch,  1000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "269 epoch,  2000 iteration, loss:0.300\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "269 epoch,  3000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "269 epoch,  4000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "269 epoch,  5000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "269 epoch,  6000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "269 epoch,  7000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "269 epoch,  8000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "269 epoch,  9000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "269 epoch, 10000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "269 epoch, 11000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "269 epoch, 12000 iteration, loss:0.369\n",
      " num 268 epoch \n",
      "####### Training Loss #######\n",
      "[0.32889544]\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "270 epoch,  1000 iteration, loss:0.299\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "270 epoch,  2000 iteration, loss:0.302\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "270 epoch,  3000 iteration, loss:0.310\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "270 epoch,  4000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "270 epoch,  5000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "270 epoch,  6000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "270 epoch,  7000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "270 epoch,  8000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "270 epoch,  9000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "270 epoch, 10000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "270 epoch, 11000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "270 epoch, 12000 iteration, loss:0.365\n",
      " num 269 epoch \n",
      "####### Training Loss #######\n",
      "[0.32845982]\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "271 epoch,  1000 iteration, loss:0.302\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "271 epoch,  2000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "271 epoch,  3000 iteration, loss:0.316\n",
      "Checking accuracy on validation set\n",
      "Got 788 / 1000 correct (78.80)\n",
      "271 epoch,  4000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "271 epoch,  5000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "271 epoch,  6000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "271 epoch,  7000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "271 epoch,  8000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "271 epoch,  9000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "271 epoch, 10000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "271 epoch, 11000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "271 epoch, 12000 iteration, loss:0.330\n",
      " num 270 epoch \n",
      "####### Training Loss #######\n",
      "[0.32710188]\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30)\n",
      "272 epoch,  1000 iteration, loss:0.288\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "272 epoch,  2000 iteration, loss:0.292\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "272 epoch,  3000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "272 epoch,  4000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "272 epoch,  5000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "272 epoch,  6000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "272 epoch,  7000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "272 epoch,  8000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "272 epoch,  9000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "272 epoch, 10000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "272 epoch, 11000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 793 / 1000 correct (79.30)\n",
      "272 epoch, 12000 iteration, loss:0.342\n",
      " num 271 epoch \n",
      "####### Training Loss #######\n",
      "[0.32245004]\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "273 epoch,  1000 iteration, loss:0.299\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "273 epoch,  2000 iteration, loss:0.296\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "273 epoch,  3000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "273 epoch,  4000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "273 epoch,  5000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "273 epoch,  6000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "273 epoch,  7000 iteration, loss:0.328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "273 epoch,  8000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "273 epoch,  9000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "273 epoch, 10000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "273 epoch, 11000 iteration, loss:0.396\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "273 epoch, 12000 iteration, loss:0.396\n",
      " num 272 epoch \n",
      "####### Training Loss #######\n",
      "[0.33125263]\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "274 epoch,  1000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 850 / 1000 correct (85.00)\n",
      "274 epoch,  2000 iteration, loss:0.299\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "274 epoch,  3000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "274 epoch,  4000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "274 epoch,  5000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "274 epoch,  6000 iteration, loss:0.316\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "274 epoch,  7000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "274 epoch,  8000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "274 epoch,  9000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 851 / 1000 correct (85.10)\n",
      "274 epoch, 10000 iteration, loss:0.372\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "274 epoch, 11000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "274 epoch, 12000 iteration, loss:0.356\n",
      " num 273 epoch \n",
      "####### Training Loss #######\n",
      "[0.33084491]\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "275 epoch,  1000 iteration, loss:0.298\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "275 epoch,  2000 iteration, loss:0.287\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "275 epoch,  3000 iteration, loss:0.298\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "275 epoch,  4000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "275 epoch,  5000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "275 epoch,  6000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "275 epoch,  7000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "275 epoch,  8000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "275 epoch,  9000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "275 epoch, 10000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "275 epoch, 11000 iteration, loss:0.375\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "275 epoch, 12000 iteration, loss:0.343\n",
      " num 274 epoch \n",
      "####### Training Loss #######\n",
      "[0.32827098]\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "276 epoch,  1000 iteration, loss:0.286\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "276 epoch,  2000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "276 epoch,  3000 iteration, loss:0.300\n",
      "Checking accuracy on validation set\n",
      "Got 792 / 1000 correct (79.20)\n",
      "276 epoch,  4000 iteration, loss:0.293\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "276 epoch,  5000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "276 epoch,  6000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "276 epoch,  7000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "276 epoch,  8000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "276 epoch,  9000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "276 epoch, 10000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30)\n",
      "276 epoch, 11000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "276 epoch, 12000 iteration, loss:0.375\n",
      " num 275 epoch \n",
      "####### Training Loss #######\n",
      "[0.32571501]\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "277 epoch,  1000 iteration, loss:0.288\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "277 epoch,  2000 iteration, loss:0.295\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "277 epoch,  3000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "277 epoch,  4000 iteration, loss:0.302\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "277 epoch,  5000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "277 epoch,  6000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "277 epoch,  7000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "277 epoch,  8000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "277 epoch,  9000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "277 epoch, 10000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "277 epoch, 11000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 799 / 1000 correct (79.90)\n",
      "277 epoch, 12000 iteration, loss:0.360\n",
      " num 276 epoch \n",
      "####### Training Loss #######\n",
      "[0.3238647]\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "278 epoch,  1000 iteration, loss:0.285\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "278 epoch,  2000 iteration, loss:0.300\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "278 epoch,  3000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 800 / 1000 correct (80.00)\n",
      "278 epoch,  4000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "278 epoch,  5000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "278 epoch,  6000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "278 epoch,  7000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "278 epoch,  8000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "278 epoch,  9000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "278 epoch, 10000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "278 epoch, 11000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "278 epoch, 12000 iteration, loss:0.349\n",
      " num 277 epoch \n",
      "####### Training Loss #######\n",
      "[0.32746669]\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "279 epoch,  1000 iteration, loss:0.292\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "279 epoch,  2000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "279 epoch,  3000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "279 epoch,  4000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "279 epoch,  5000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "279 epoch,  6000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "279 epoch,  7000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "279 epoch,  8000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "279 epoch,  9000 iteration, loss:0.367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "279 epoch, 10000 iteration, loss:0.319\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "279 epoch, 11000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "279 epoch, 12000 iteration, loss:0.375\n",
      " num 278 epoch \n",
      "####### Training Loss #######\n",
      "[0.32944968]\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "280 epoch,  1000 iteration, loss:0.273\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "280 epoch,  2000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "280 epoch,  3000 iteration, loss:0.290\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "280 epoch,  4000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "280 epoch,  5000 iteration, loss:0.304\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "280 epoch,  6000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "280 epoch,  7000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "280 epoch,  8000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "280 epoch,  9000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "280 epoch, 10000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "280 epoch, 11000 iteration, loss:0.387\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "280 epoch, 12000 iteration, loss:0.358\n",
      " num 279 epoch \n",
      "####### Training Loss #######\n",
      "[0.32865804]\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "281 epoch,  1000 iteration, loss:0.294\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "281 epoch,  2000 iteration, loss:0.291\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "281 epoch,  3000 iteration, loss:0.304\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "281 epoch,  4000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "281 epoch,  5000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 787 / 1000 correct (78.70)\n",
      "281 epoch,  6000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "281 epoch,  7000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "281 epoch,  8000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "281 epoch,  9000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "281 epoch, 10000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "281 epoch, 11000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "281 epoch, 12000 iteration, loss:0.379\n",
      " num 280 epoch \n",
      "####### Training Loss #######\n",
      "[0.3271058]\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "282 epoch,  1000 iteration, loss:0.280\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "282 epoch,  2000 iteration, loss:0.309\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "282 epoch,  3000 iteration, loss:0.299\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "282 epoch,  4000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "282 epoch,  5000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "282 epoch,  6000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "282 epoch,  7000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "282 epoch,  8000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "282 epoch,  9000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "282 epoch, 10000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "282 epoch, 11000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "282 epoch, 12000 iteration, loss:0.358\n",
      " num 281 epoch \n",
      "####### Training Loss #######\n",
      "[0.32890833]\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "283 epoch,  1000 iteration, loss:0.277\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "283 epoch,  2000 iteration, loss:0.292\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "283 epoch,  3000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "283 epoch,  4000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "283 epoch,  5000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "283 epoch,  6000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "283 epoch,  7000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "283 epoch,  8000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "283 epoch,  9000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "283 epoch, 10000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "283 epoch, 11000 iteration, loss:0.371\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "283 epoch, 12000 iteration, loss:0.360\n",
      " num 282 epoch \n",
      "####### Training Loss #######\n",
      "[0.3210475]\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "284 epoch,  1000 iteration, loss:0.290\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "284 epoch,  2000 iteration, loss:0.294\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "284 epoch,  3000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "284 epoch,  4000 iteration, loss:0.307\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "284 epoch,  5000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "284 epoch,  6000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "284 epoch,  7000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "284 epoch,  8000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "284 epoch,  9000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "284 epoch, 10000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "284 epoch, 11000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "284 epoch, 12000 iteration, loss:0.357\n",
      " num 283 epoch \n",
      "####### Training Loss #######\n",
      "[0.32933076]\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "285 epoch,  1000 iteration, loss:0.281\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "285 epoch,  2000 iteration, loss:0.302\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "285 epoch,  3000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "285 epoch,  4000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "285 epoch,  5000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "285 epoch,  6000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "285 epoch,  7000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "285 epoch,  8000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "285 epoch,  9000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "285 epoch, 10000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "285 epoch, 11000 iteration, loss:0.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "285 epoch, 12000 iteration, loss:0.361\n",
      " num 284 epoch \n",
      "####### Training Loss #######\n",
      "[0.33085974]\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "286 epoch,  1000 iteration, loss:0.285\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "286 epoch,  2000 iteration, loss:0.288\n",
      "Checking accuracy on validation set\n",
      "Got 800 / 1000 correct (80.00)\n",
      "286 epoch,  3000 iteration, loss:0.300\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "286 epoch,  4000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "286 epoch,  5000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "286 epoch,  6000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "286 epoch,  7000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "286 epoch,  8000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "286 epoch,  9000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "286 epoch, 10000 iteration, loss:0.371\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "286 epoch, 11000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "286 epoch, 12000 iteration, loss:0.340\n",
      " num 285 epoch \n",
      "####### Training Loss #######\n",
      "[0.32463101]\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "287 epoch,  1000 iteration, loss:0.291\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "287 epoch,  2000 iteration, loss:0.307\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "287 epoch,  3000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 799 / 1000 correct (79.90)\n",
      "287 epoch,  4000 iteration, loss:0.319\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "287 epoch,  5000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "287 epoch,  6000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "287 epoch,  7000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "287 epoch,  8000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 788 / 1000 correct (78.80)\n",
      "287 epoch,  9000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "287 epoch, 10000 iteration, loss:0.373\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "287 epoch, 11000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "287 epoch, 12000 iteration, loss:0.344\n",
      " num 286 epoch \n",
      "####### Training Loss #######\n",
      "[0.33110402]\n",
      "Checking accuracy on validation set\n",
      "Got 852 / 1000 correct (85.20)\n",
      "288 epoch,  1000 iteration, loss:0.303\n",
      "Checking accuracy on validation set\n",
      "Got 805 / 1000 correct (80.50)\n",
      "288 epoch,  2000 iteration, loss:0.288\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "288 epoch,  3000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "288 epoch,  4000 iteration, loss:0.319\n",
      "Checking accuracy on validation set\n",
      "Got 798 / 1000 correct (79.80)\n",
      "288 epoch,  5000 iteration, loss:0.310\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "288 epoch,  6000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "288 epoch,  7000 iteration, loss:0.310\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "288 epoch,  8000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "288 epoch,  9000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "288 epoch, 10000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "288 epoch, 11000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "288 epoch, 12000 iteration, loss:0.376\n",
      " num 287 epoch \n",
      "####### Training Loss #######\n",
      "[0.32644211]\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "289 epoch,  1000 iteration, loss:0.278\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "289 epoch,  2000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "289 epoch,  3000 iteration, loss:0.294\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "289 epoch,  4000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "289 epoch,  5000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "289 epoch,  6000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "289 epoch,  7000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 850 / 1000 correct (85.00)\n",
      "289 epoch,  8000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "289 epoch,  9000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "289 epoch, 10000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "289 epoch, 11000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "289 epoch, 12000 iteration, loss:0.342\n",
      " num 288 epoch \n",
      "####### Training Loss #######\n",
      "[0.32467882]\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "290 epoch,  1000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "290 epoch,  2000 iteration, loss:0.316\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "290 epoch,  3000 iteration, loss:0.294\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "290 epoch,  4000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "290 epoch,  5000 iteration, loss:0.298\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "290 epoch,  6000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "290 epoch,  7000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "290 epoch,  8000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "290 epoch,  9000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "290 epoch, 10000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "290 epoch, 11000 iteration, loss:0.377\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "290 epoch, 12000 iteration, loss:0.367\n",
      " num 289 epoch \n",
      "####### Training Loss #######\n",
      "[0.32588449]\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "291 epoch,  1000 iteration, loss:0.307\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "291 epoch,  2000 iteration, loss:0.300\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "291 epoch,  3000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "291 epoch,  4000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "291 epoch,  5000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "291 epoch,  6000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "291 epoch,  7000 iteration, loss:0.319\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "291 epoch,  8000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "291 epoch,  9000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "291 epoch, 10000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "291 epoch, 11000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "291 epoch, 12000 iteration, loss:0.380\n",
      " num 290 epoch \n",
      "####### Training Loss #######\n",
      "[0.32713485]\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "292 epoch,  1000 iteration, loss:0.310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "292 epoch,  2000 iteration, loss:0.300\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "292 epoch,  3000 iteration, loss:0.309\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "292 epoch,  4000 iteration, loss:0.307\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "292 epoch,  5000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "292 epoch,  6000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "292 epoch,  7000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "292 epoch,  8000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "292 epoch,  9000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "292 epoch, 10000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "292 epoch, 11000 iteration, loss:0.372\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "292 epoch, 12000 iteration, loss:0.381\n",
      " num 291 epoch \n",
      "####### Training Loss #######\n",
      "[0.32691471]\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "293 epoch,  1000 iteration, loss:0.297\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "293 epoch,  2000 iteration, loss:0.307\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "293 epoch,  3000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10)\n",
      "293 epoch,  4000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "293 epoch,  5000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "293 epoch,  6000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "293 epoch,  7000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "293 epoch,  8000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "293 epoch,  9000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "293 epoch, 10000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "293 epoch, 11000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "293 epoch, 12000 iteration, loss:0.355\n",
      " num 292 epoch \n",
      "####### Training Loss #######\n",
      "[0.32823026]\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "294 epoch,  1000 iteration, loss:0.287\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "294 epoch,  2000 iteration, loss:0.292\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "294 epoch,  3000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "294 epoch,  4000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "294 epoch,  5000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 799 / 1000 correct (79.90)\n",
      "294 epoch,  6000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "294 epoch,  7000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "294 epoch,  8000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "294 epoch,  9000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "294 epoch, 10000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "294 epoch, 11000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "294 epoch, 12000 iteration, loss:0.361\n",
      " num 293 epoch \n",
      "####### Training Loss #######\n",
      "[0.32838305]\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "295 epoch,  1000 iteration, loss:0.292\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "295 epoch,  2000 iteration, loss:0.298\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "295 epoch,  3000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "295 epoch,  4000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "295 epoch,  5000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "295 epoch,  6000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "295 epoch,  7000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "295 epoch,  8000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "295 epoch,  9000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "295 epoch, 10000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "295 epoch, 11000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "295 epoch, 12000 iteration, loss:0.351\n",
      " num 294 epoch \n",
      "####### Training Loss #######\n",
      "[0.32713515]\n",
      "Checking accuracy on validation set\n",
      "Got 852 / 1000 correct (85.20)\n",
      "296 epoch,  1000 iteration, loss:0.290\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "296 epoch,  2000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "296 epoch,  3000 iteration, loss:0.319\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "296 epoch,  4000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "296 epoch,  5000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "296 epoch,  6000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30)\n",
      "296 epoch,  7000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "296 epoch,  8000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 794 / 1000 correct (79.40)\n",
      "296 epoch,  9000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "296 epoch, 10000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "296 epoch, 11000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "296 epoch, 12000 iteration, loss:0.347\n",
      " num 295 epoch \n",
      "####### Training Loss #######\n",
      "[0.3285245]\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "297 epoch,  1000 iteration, loss:0.283\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "297 epoch,  2000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "297 epoch,  3000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "297 epoch,  4000 iteration, loss:0.310\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "297 epoch,  5000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "297 epoch,  6000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "297 epoch,  7000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "297 epoch,  8000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "297 epoch,  9000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "297 epoch, 10000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "297 epoch, 11000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 799 / 1000 correct (79.90)\n",
      "297 epoch, 12000 iteration, loss:0.347\n",
      " num 296 epoch \n",
      "####### Training Loss #######\n",
      "[0.3230955]\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "298 epoch,  1000 iteration, loss:0.276\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "298 epoch,  2000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "298 epoch,  3000 iteration, loss:0.311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "298 epoch,  4000 iteration, loss:0.289\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "298 epoch,  5000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "298 epoch,  6000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "298 epoch,  7000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "298 epoch,  8000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "298 epoch,  9000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "298 epoch, 10000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "298 epoch, 11000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "298 epoch, 12000 iteration, loss:0.379\n",
      " num 297 epoch \n",
      "####### Training Loss #######\n",
      "[0.32657958]\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "299 epoch,  1000 iteration, loss:0.282\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "299 epoch,  2000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "299 epoch,  3000 iteration, loss:0.316\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "299 epoch,  4000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "299 epoch,  5000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "299 epoch,  6000 iteration, loss:0.295\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "299 epoch,  7000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "299 epoch,  8000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "299 epoch,  9000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "299 epoch, 10000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "299 epoch, 11000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "299 epoch, 12000 iteration, loss:0.387\n",
      " num 298 epoch \n",
      "####### Training Loss #######\n",
      "[0.32549551]\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "300 epoch,  1000 iteration, loss:0.280\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "300 epoch,  2000 iteration, loss:0.316\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "300 epoch,  3000 iteration, loss:0.281\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "300 epoch,  4000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "300 epoch,  5000 iteration, loss:0.291\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "300 epoch,  6000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "300 epoch,  7000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "300 epoch,  8000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "300 epoch,  9000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 780 / 1000 correct (78.00)\n",
      "300 epoch, 10000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "300 epoch, 11000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "300 epoch, 12000 iteration, loss:0.363\n",
      " num 299 epoch \n",
      "####### Training Loss #######\n",
      "[0.31850475]\n",
      "Checking accuracy on validation set\n",
      "Got 854 / 1000 correct (85.40)\n",
      "301 epoch,  1000 iteration, loss:0.304\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "301 epoch,  2000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "301 epoch,  3000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "301 epoch,  4000 iteration, loss:0.309\n",
      "Checking accuracy on validation set\n",
      "Got 854 / 1000 correct (85.40)\n",
      "301 epoch,  5000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 765 / 1000 correct (76.50)\n",
      "301 epoch,  6000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "301 epoch,  7000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 859 / 1000 correct (85.90)\n",
      "301 epoch,  8000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "301 epoch,  9000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "301 epoch, 10000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "301 epoch, 11000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "301 epoch, 12000 iteration, loss:0.383\n",
      " num 300 epoch \n",
      "####### Training Loss #######\n",
      "[0.32581273]\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "302 epoch,  1000 iteration, loss:0.286\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "302 epoch,  2000 iteration, loss:0.300\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "302 epoch,  3000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "302 epoch,  4000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "302 epoch,  5000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "302 epoch,  6000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "302 epoch,  7000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "302 epoch,  8000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "302 epoch,  9000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "302 epoch, 10000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 851 / 1000 correct (85.10)\n",
      "302 epoch, 11000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "302 epoch, 12000 iteration, loss:0.354\n",
      " num 301 epoch \n",
      "####### Training Loss #######\n",
      "[0.32552918]\n",
      "Checking accuracy on validation set\n",
      "Got 802 / 1000 correct (80.20)\n",
      "303 epoch,  1000 iteration, loss:0.292\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "303 epoch,  2000 iteration, loss:0.295\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "303 epoch,  3000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "303 epoch,  4000 iteration, loss:0.303\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "303 epoch,  5000 iteration, loss:0.304\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "303 epoch,  6000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "303 epoch,  7000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "303 epoch,  8000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "303 epoch,  9000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "303 epoch, 10000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "303 epoch, 11000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "303 epoch, 12000 iteration, loss:0.328\n",
      " num 302 epoch \n",
      "####### Training Loss #######\n",
      "[0.31911609]\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "304 epoch,  1000 iteration, loss:0.300\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "304 epoch,  2000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "304 epoch,  3000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "304 epoch,  4000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "304 epoch,  5000 iteration, loss:0.345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "304 epoch,  6000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "304 epoch,  7000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "304 epoch,  8000 iteration, loss:0.366\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "304 epoch,  9000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "304 epoch, 10000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "304 epoch, 11000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "304 epoch, 12000 iteration, loss:0.342\n",
      " num 303 epoch \n",
      "####### Training Loss #######\n",
      "[0.32894917]\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "305 epoch,  1000 iteration, loss:0.275\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "305 epoch,  2000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "305 epoch,  3000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "305 epoch,  4000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "305 epoch,  5000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "305 epoch,  6000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "305 epoch,  7000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 800 / 1000 correct (80.00)\n",
      "305 epoch,  8000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 851 / 1000 correct (85.10)\n",
      "305 epoch,  9000 iteration, loss:0.377\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "305 epoch, 10000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "305 epoch, 11000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "305 epoch, 12000 iteration, loss:0.358\n",
      " num 304 epoch \n",
      "####### Training Loss #######\n",
      "[0.32561594]\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "306 epoch,  1000 iteration, loss:0.284\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "306 epoch,  2000 iteration, loss:0.293\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "306 epoch,  3000 iteration, loss:0.297\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "306 epoch,  4000 iteration, loss:0.310\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "306 epoch,  5000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30)\n",
      "306 epoch,  6000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "306 epoch,  7000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "306 epoch,  8000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "306 epoch,  9000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "306 epoch, 10000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "306 epoch, 11000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "306 epoch, 12000 iteration, loss:0.378\n",
      " num 305 epoch \n",
      "####### Training Loss #######\n",
      "[0.32918641]\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "307 epoch,  1000 iteration, loss:0.293\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "307 epoch,  2000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "307 epoch,  3000 iteration, loss:0.290\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "307 epoch,  4000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "307 epoch,  5000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "307 epoch,  6000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "307 epoch,  7000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "307 epoch,  8000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "307 epoch,  9000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "307 epoch, 10000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "307 epoch, 11000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "307 epoch, 12000 iteration, loss:0.336\n",
      " num 306 epoch \n",
      "####### Training Loss #######\n",
      "[0.32707034]\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "308 epoch,  1000 iteration, loss:0.284\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "308 epoch,  2000 iteration, loss:0.299\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "308 epoch,  3000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "308 epoch,  4000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "308 epoch,  5000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "308 epoch,  6000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "308 epoch,  7000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "308 epoch,  8000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "308 epoch,  9000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "308 epoch, 10000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "308 epoch, 11000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "308 epoch, 12000 iteration, loss:0.382\n",
      " num 307 epoch \n",
      "####### Training Loss #######\n",
      "[0.33013566]\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "309 epoch,  1000 iteration, loss:0.298\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "309 epoch,  2000 iteration, loss:0.297\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "309 epoch,  3000 iteration, loss:0.295\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "309 epoch,  4000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "309 epoch,  5000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "309 epoch,  6000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "309 epoch,  7000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 793 / 1000 correct (79.30)\n",
      "309 epoch,  8000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 798 / 1000 correct (79.80)\n",
      "309 epoch,  9000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "309 epoch, 10000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "309 epoch, 11000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "309 epoch, 12000 iteration, loss:0.356\n",
      " num 308 epoch \n",
      "####### Training Loss #######\n",
      "[0.32357]\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "310 epoch,  1000 iteration, loss:0.291\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "310 epoch,  2000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "310 epoch,  3000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "310 epoch,  4000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "310 epoch,  5000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "310 epoch,  6000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "310 epoch,  7000 iteration, loss:0.341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "310 epoch,  8000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "310 epoch,  9000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "310 epoch, 10000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "310 epoch, 11000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "310 epoch, 12000 iteration, loss:0.361\n",
      " num 309 epoch \n",
      "####### Training Loss #######\n",
      "[0.3285535]\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "311 epoch,  1000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "311 epoch,  2000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 850 / 1000 correct (85.00)\n",
      "311 epoch,  3000 iteration, loss:0.303\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "311 epoch,  4000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "311 epoch,  5000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 794 / 1000 correct (79.40)\n",
      "311 epoch,  6000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "311 epoch,  7000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "311 epoch,  8000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "311 epoch,  9000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "311 epoch, 10000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "311 epoch, 11000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "311 epoch, 12000 iteration, loss:0.346\n",
      " num 310 epoch \n",
      "####### Training Loss #######\n",
      "[0.32751125]\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "312 epoch,  1000 iteration, loss:0.295\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "312 epoch,  2000 iteration, loss:0.315\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "312 epoch,  3000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "312 epoch,  4000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "312 epoch,  5000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "312 epoch,  6000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "312 epoch,  7000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "312 epoch,  8000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "312 epoch,  9000 iteration, loss:0.381\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "312 epoch, 10000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "312 epoch, 11000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "312 epoch, 12000 iteration, loss:0.342\n",
      " num 311 epoch \n",
      "####### Training Loss #######\n",
      "[0.32302457]\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "313 epoch,  1000 iteration, loss:0.293\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "313 epoch,  2000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "313 epoch,  3000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "313 epoch,  4000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "313 epoch,  5000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "313 epoch,  6000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "313 epoch,  7000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "313 epoch,  8000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "313 epoch,  9000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 805 / 1000 correct (80.50)\n",
      "313 epoch, 10000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "313 epoch, 11000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "313 epoch, 12000 iteration, loss:0.350\n",
      " num 312 epoch \n",
      "####### Training Loss #######\n",
      "[0.32560795]\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "314 epoch,  1000 iteration, loss:0.302\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30)\n",
      "314 epoch,  2000 iteration, loss:0.308\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "314 epoch,  3000 iteration, loss:0.316\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "314 epoch,  4000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "314 epoch,  5000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "314 epoch,  6000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "314 epoch,  7000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "314 epoch,  8000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "314 epoch,  9000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "314 epoch, 10000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "314 epoch, 11000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "314 epoch, 12000 iteration, loss:0.347\n",
      " num 313 epoch \n",
      "####### Training Loss #######\n",
      "[0.32529754]\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "315 epoch,  1000 iteration, loss:0.283\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "315 epoch,  2000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "315 epoch,  3000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 770 / 1000 correct (77.00)\n",
      "315 epoch,  4000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "315 epoch,  5000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "315 epoch,  6000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "315 epoch,  7000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "315 epoch,  8000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 850 / 1000 correct (85.00)\n",
      "315 epoch,  9000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "315 epoch, 10000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "315 epoch, 11000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "315 epoch, 12000 iteration, loss:0.366\n",
      " num 314 epoch \n",
      "####### Training Loss #######\n",
      "[0.32624842]\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "316 epoch,  1000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "316 epoch,  2000 iteration, loss:0.290\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "316 epoch,  3000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "316 epoch,  4000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "316 epoch,  5000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "316 epoch,  6000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "316 epoch,  7000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "316 epoch,  8000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "316 epoch,  9000 iteration, loss:0.358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "316 epoch, 10000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "316 epoch, 11000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "316 epoch, 12000 iteration, loss:0.370\n",
      " num 315 epoch \n",
      "####### Training Loss #######\n",
      "[0.32638801]\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "317 epoch,  1000 iteration, loss:0.315\n",
      "Checking accuracy on validation set\n",
      "Got 805 / 1000 correct (80.50)\n",
      "317 epoch,  2000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "317 epoch,  3000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "317 epoch,  4000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "317 epoch,  5000 iteration, loss:0.309\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "317 epoch,  6000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "317 epoch,  7000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "317 epoch,  8000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "317 epoch,  9000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "317 epoch, 10000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "317 epoch, 11000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "317 epoch, 12000 iteration, loss:0.343\n",
      " num 316 epoch \n",
      "####### Training Loss #######\n",
      "[0.32486662]\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "318 epoch,  1000 iteration, loss:0.295\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "318 epoch,  2000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "318 epoch,  3000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "318 epoch,  4000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "318 epoch,  5000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "318 epoch,  6000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "318 epoch,  7000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "318 epoch,  8000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "318 epoch,  9000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "318 epoch, 10000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "318 epoch, 11000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "318 epoch, 12000 iteration, loss:0.366\n",
      " num 317 epoch \n",
      "####### Training Loss #######\n",
      "[0.32841183]\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "319 epoch,  1000 iteration, loss:0.280\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "319 epoch,  2000 iteration, loss:0.304\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "319 epoch,  3000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "319 epoch,  4000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "319 epoch,  5000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "319 epoch,  6000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "319 epoch,  7000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "319 epoch,  8000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "319 epoch,  9000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "319 epoch, 10000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "319 epoch, 11000 iteration, loss:0.379\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "319 epoch, 12000 iteration, loss:0.349\n",
      " num 318 epoch \n",
      "####### Training Loss #######\n",
      "[0.32806419]\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "320 epoch,  1000 iteration, loss:0.294\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "320 epoch,  2000 iteration, loss:0.310\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "320 epoch,  3000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "320 epoch,  4000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "320 epoch,  5000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "320 epoch,  6000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "320 epoch,  7000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "320 epoch,  8000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "320 epoch,  9000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "320 epoch, 10000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "320 epoch, 11000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "320 epoch, 12000 iteration, loss:0.384\n",
      " num 319 epoch \n",
      "####### Training Loss #######\n",
      "[0.32812493]\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "321 epoch,  1000 iteration, loss:0.279\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "321 epoch,  2000 iteration, loss:0.289\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "321 epoch,  3000 iteration, loss:0.319\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "321 epoch,  4000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "321 epoch,  5000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "321 epoch,  6000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 791 / 1000 correct (79.10)\n",
      "321 epoch,  7000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "321 epoch,  8000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 857 / 1000 correct (85.70)\n",
      "321 epoch,  9000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "321 epoch, 10000 iteration, loss:0.372\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "321 epoch, 11000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "321 epoch, 12000 iteration, loss:0.366\n",
      " num 320 epoch \n",
      "####### Training Loss #######\n",
      "[0.32513661]\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "322 epoch,  1000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "322 epoch,  2000 iteration, loss:0.286\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "322 epoch,  3000 iteration, loss:0.307\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "322 epoch,  4000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "322 epoch,  5000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "322 epoch,  6000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "322 epoch,  7000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "322 epoch,  8000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "322 epoch,  9000 iteration, loss:0.371\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "322 epoch, 10000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "322 epoch, 11000 iteration, loss:0.341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "322 epoch, 12000 iteration, loss:0.364\n",
      " num 321 epoch \n",
      "####### Training Loss #######\n",
      "[0.32421412]\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "323 epoch,  1000 iteration, loss:0.292\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "323 epoch,  2000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 846 / 1000 correct (84.60)\n",
      "323 epoch,  3000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "323 epoch,  4000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "323 epoch,  5000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "323 epoch,  6000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "323 epoch,  7000 iteration, loss:0.319\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "323 epoch,  8000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "323 epoch,  9000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "323 epoch, 10000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "323 epoch, 11000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "323 epoch, 12000 iteration, loss:0.366\n",
      " num 322 epoch \n",
      "####### Training Loss #######\n",
      "[0.32643224]\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "324 epoch,  1000 iteration, loss:0.292\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "324 epoch,  2000 iteration, loss:0.295\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "324 epoch,  3000 iteration, loss:0.292\n",
      "Checking accuracy on validation set\n",
      "Got 790 / 1000 correct (79.00)\n",
      "324 epoch,  4000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "324 epoch,  5000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "324 epoch,  6000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "324 epoch,  7000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "324 epoch,  8000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "324 epoch,  9000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "324 epoch, 10000 iteration, loss:0.381\n",
      "Checking accuracy on validation set\n",
      "Got 799 / 1000 correct (79.90)\n",
      "324 epoch, 11000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "324 epoch, 12000 iteration, loss:0.328\n",
      " num 323 epoch \n",
      "####### Training Loss #######\n",
      "[0.32505998]\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "325 epoch,  1000 iteration, loss:0.279\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "325 epoch,  2000 iteration, loss:0.279\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "325 epoch,  3000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "325 epoch,  4000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "325 epoch,  5000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "325 epoch,  6000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "325 epoch,  7000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "325 epoch,  8000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "325 epoch,  9000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 780 / 1000 correct (78.00)\n",
      "325 epoch, 10000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "325 epoch, 11000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "325 epoch, 12000 iteration, loss:0.366\n",
      " num 324 epoch \n",
      "####### Training Loss #######\n",
      "[0.32466352]\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "326 epoch,  1000 iteration, loss:0.286\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "326 epoch,  2000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "326 epoch,  3000 iteration, loss:0.307\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "326 epoch,  4000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "326 epoch,  5000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "326 epoch,  6000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "326 epoch,  7000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "326 epoch,  8000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "326 epoch,  9000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "326 epoch, 10000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "326 epoch, 11000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "326 epoch, 12000 iteration, loss:0.356\n",
      " num 325 epoch \n",
      "####### Training Loss #######\n",
      "[0.32497197]\n",
      "Checking accuracy on validation set\n",
      "Got 797 / 1000 correct (79.70)\n",
      "327 epoch,  1000 iteration, loss:0.282\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "327 epoch,  2000 iteration, loss:0.291\n",
      "Checking accuracy on validation set\n",
      "Got 793 / 1000 correct (79.30)\n",
      "327 epoch,  3000 iteration, loss:0.304\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "327 epoch,  4000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "327 epoch,  5000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "327 epoch,  6000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "327 epoch,  7000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "327 epoch,  8000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "327 epoch,  9000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "327 epoch, 10000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "327 epoch, 11000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "327 epoch, 12000 iteration, loss:0.346\n",
      " num 326 epoch \n",
      "####### Training Loss #######\n",
      "[0.32241956]\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "328 epoch,  1000 iteration, loss:0.289\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "328 epoch,  2000 iteration, loss:0.307\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "328 epoch,  3000 iteration, loss:0.302\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "328 epoch,  4000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "328 epoch,  5000 iteration, loss:0.303\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "328 epoch,  6000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "328 epoch,  7000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "328 epoch,  8000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "328 epoch,  9000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "328 epoch, 10000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "328 epoch, 11000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "328 epoch, 12000 iteration, loss:0.366\n",
      " num 327 epoch \n",
      "####### Training Loss #######\n",
      "[0.3199794]\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "329 epoch,  1000 iteration, loss:0.283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "329 epoch,  2000 iteration, loss:0.292\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "329 epoch,  3000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "329 epoch,  4000 iteration, loss:0.309\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "329 epoch,  5000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "329 epoch,  6000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "329 epoch,  7000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "329 epoch,  8000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "329 epoch,  9000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "329 epoch, 10000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "329 epoch, 11000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "329 epoch, 12000 iteration, loss:0.352\n",
      " num 328 epoch \n",
      "####### Training Loss #######\n",
      "[0.32378768]\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "330 epoch,  1000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "330 epoch,  2000 iteration, loss:0.300\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "330 epoch,  3000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "330 epoch,  4000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 802 / 1000 correct (80.20)\n",
      "330 epoch,  5000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "330 epoch,  6000 iteration, loss:0.330\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "330 epoch,  7000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "330 epoch,  8000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "330 epoch,  9000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "330 epoch, 10000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "330 epoch, 11000 iteration, loss:0.365\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "330 epoch, 12000 iteration, loss:0.351\n",
      " num 329 epoch \n",
      "####### Training Loss #######\n",
      "[0.32961933]\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "331 epoch,  1000 iteration, loss:0.277\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "331 epoch,  2000 iteration, loss:0.304\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "331 epoch,  3000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "331 epoch,  4000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "331 epoch,  5000 iteration, loss:0.315\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "331 epoch,  6000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "331 epoch,  7000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "331 epoch,  8000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "331 epoch,  9000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "331 epoch, 10000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "331 epoch, 11000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "331 epoch, 12000 iteration, loss:0.375\n",
      " num 330 epoch \n",
      "####### Training Loss #######\n",
      "[0.32957949]\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "332 epoch,  1000 iteration, loss:0.282\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "332 epoch,  2000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "332 epoch,  3000 iteration, loss:0.309\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "332 epoch,  4000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "332 epoch,  5000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "332 epoch,  6000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "332 epoch,  7000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 790 / 1000 correct (79.00)\n",
      "332 epoch,  8000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "332 epoch,  9000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "332 epoch, 10000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "332 epoch, 11000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "332 epoch, 12000 iteration, loss:0.369\n",
      " num 331 epoch \n",
      "####### Training Loss #######\n",
      "[0.32727041]\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "333 epoch,  1000 iteration, loss:0.299\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "333 epoch,  2000 iteration, loss:0.299\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "333 epoch,  3000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "333 epoch,  4000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "333 epoch,  5000 iteration, loss:0.319\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "333 epoch,  6000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "333 epoch,  7000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "333 epoch,  8000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "333 epoch,  9000 iteration, loss:0.374\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "333 epoch, 10000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "333 epoch, 11000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "333 epoch, 12000 iteration, loss:0.342\n",
      " num 332 epoch \n",
      "####### Training Loss #######\n",
      "[0.32542924]\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "334 epoch,  1000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "334 epoch,  2000 iteration, loss:0.291\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "334 epoch,  3000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "334 epoch,  4000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "334 epoch,  5000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "334 epoch,  6000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "334 epoch,  7000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "334 epoch,  8000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "334 epoch,  9000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "334 epoch, 10000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "334 epoch, 11000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "334 epoch, 12000 iteration, loss:0.358\n",
      " num 333 epoch \n",
      "####### Training Loss #######\n",
      "[0.32818906]\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "335 epoch,  1000 iteration, loss:0.283\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "335 epoch,  2000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "335 epoch,  3000 iteration, loss:0.321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "335 epoch,  4000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "335 epoch,  5000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "335 epoch,  6000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "335 epoch,  7000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "335 epoch,  8000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "335 epoch,  9000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 783 / 1000 correct (78.30)\n",
      "335 epoch, 10000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "335 epoch, 11000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "335 epoch, 12000 iteration, loss:0.369\n",
      " num 334 epoch \n",
      "####### Training Loss #######\n",
      "[0.32539954]\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "336 epoch,  1000 iteration, loss:0.303\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "336 epoch,  2000 iteration, loss:0.302\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "336 epoch,  3000 iteration, loss:0.309\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "336 epoch,  4000 iteration, loss:0.316\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "336 epoch,  5000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "336 epoch,  6000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "336 epoch,  7000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "336 epoch,  8000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "336 epoch,  9000 iteration, loss:0.355\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "336 epoch, 10000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "336 epoch, 11000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "336 epoch, 12000 iteration, loss:0.372\n",
      " num 335 epoch \n",
      "####### Training Loss #######\n",
      "[0.33197044]\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "337 epoch,  1000 iteration, loss:0.300\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "337 epoch,  2000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "337 epoch,  3000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "337 epoch,  4000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "337 epoch,  5000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "337 epoch,  6000 iteration, loss:0.320\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "337 epoch,  7000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "337 epoch,  8000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "337 epoch,  9000 iteration, loss:0.353\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "337 epoch, 10000 iteration, loss:0.359\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "337 epoch, 11000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "337 epoch, 12000 iteration, loss:0.357\n",
      " num 336 epoch \n",
      "####### Training Loss #######\n",
      "[0.32598219]\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "338 epoch,  1000 iteration, loss:0.269\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "338 epoch,  2000 iteration, loss:0.307\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "338 epoch,  3000 iteration, loss:0.316\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "338 epoch,  4000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "338 epoch,  5000 iteration, loss:0.316\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "338 epoch,  6000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "338 epoch,  7000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "338 epoch,  8000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "338 epoch,  9000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "338 epoch, 10000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "338 epoch, 11000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "338 epoch, 12000 iteration, loss:0.352\n",
      " num 337 epoch \n",
      "####### Training Loss #######\n",
      "[0.32327674]\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "339 epoch,  1000 iteration, loss:0.298\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "339 epoch,  2000 iteration, loss:0.318\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "339 epoch,  3000 iteration, loss:0.319\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "339 epoch,  4000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "339 epoch,  5000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "339 epoch,  6000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "339 epoch,  7000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "339 epoch,  8000 iteration, loss:0.354\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "339 epoch,  9000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "339 epoch, 10000 iteration, loss:0.369\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "339 epoch, 11000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 839 / 1000 correct (83.90)\n",
      "339 epoch, 12000 iteration, loss:0.338\n",
      " num 338 epoch \n",
      "####### Training Loss #######\n",
      "[0.32802661]\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "340 epoch,  1000 iteration, loss:0.297\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "340 epoch,  2000 iteration, loss:0.315\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "340 epoch,  3000 iteration, loss:0.309\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "340 epoch,  4000 iteration, loss:0.319\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "340 epoch,  5000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "340 epoch,  6000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "340 epoch,  7000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "340 epoch,  8000 iteration, loss:0.358\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "340 epoch,  9000 iteration, loss:0.336\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "340 epoch, 10000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "340 epoch, 11000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "340 epoch, 12000 iteration, loss:0.356\n",
      " num 339 epoch \n",
      "####### Training Loss #######\n",
      "[0.32479716]\n",
      "Checking accuracy on validation set\n",
      "Got 845 / 1000 correct (84.50)\n",
      "341 epoch,  1000 iteration, loss:0.291\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "341 epoch,  2000 iteration, loss:0.299\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "341 epoch,  3000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "341 epoch,  4000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "341 epoch,  5000 iteration, loss:0.308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "341 epoch,  6000 iteration, loss:0.344\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "341 epoch,  7000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 857 / 1000 correct (85.70)\n",
      "341 epoch,  8000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "341 epoch,  9000 iteration, loss:0.362\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "341 epoch, 10000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "341 epoch, 11000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "341 epoch, 12000 iteration, loss:0.361\n",
      " num 340 epoch \n",
      "####### Training Loss #######\n",
      "[0.32545975]\n",
      "Checking accuracy on validation set\n",
      "Got 799 / 1000 correct (79.90)\n",
      "342 epoch,  1000 iteration, loss:0.305\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "342 epoch,  2000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "342 epoch,  3000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "342 epoch,  4000 iteration, loss:0.329\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "342 epoch,  5000 iteration, loss:0.326\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "342 epoch,  6000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "342 epoch,  7000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 849 / 1000 correct (84.90)\n",
      "342 epoch,  8000 iteration, loss:0.349\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "342 epoch,  9000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "342 epoch, 10000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 850 / 1000 correct (85.00)\n",
      "342 epoch, 11000 iteration, loss:0.380\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "342 epoch, 12000 iteration, loss:0.364\n",
      " num 341 epoch \n",
      "####### Training Loss #######\n",
      "[0.32995212]\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "343 epoch,  1000 iteration, loss:0.289\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "343 epoch,  2000 iteration, loss:0.292\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "343 epoch,  3000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "343 epoch,  4000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "343 epoch,  5000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "343 epoch,  6000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "343 epoch,  7000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "343 epoch,  8000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "343 epoch,  9000 iteration, loss:0.356\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "343 epoch, 10000 iteration, loss:0.363\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "343 epoch, 11000 iteration, loss:0.351\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "343 epoch, 12000 iteration, loss:0.343\n",
      " num 342 epoch \n",
      "####### Training Loss #######\n",
      "[0.32645736]\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "344 epoch,  1000 iteration, loss:0.293\n",
      "Checking accuracy on validation set\n",
      "Got 830 / 1000 correct (83.00)\n",
      "344 epoch,  2000 iteration, loss:0.312\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "344 epoch,  3000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "344 epoch,  4000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "344 epoch,  5000 iteration, loss:0.307\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "344 epoch,  6000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "344 epoch,  7000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "344 epoch,  8000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "344 epoch,  9000 iteration, loss:0.347\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "344 epoch, 10000 iteration, loss:0.364\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "344 epoch, 11000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "344 epoch, 12000 iteration, loss:0.360\n",
      " num 343 epoch \n",
      "####### Training Loss #######\n",
      "[0.32354138]\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "345 epoch,  1000 iteration, loss:0.304\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "345 epoch,  2000 iteration, loss:0.285\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "345 epoch,  3000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "345 epoch,  4000 iteration, loss:0.314\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "345 epoch,  5000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "345 epoch,  6000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "345 epoch,  7000 iteration, loss:0.342\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "345 epoch,  8000 iteration, loss:0.370\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "345 epoch,  9000 iteration, loss:0.321\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "345 epoch, 10000 iteration, loss:0.357\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "345 epoch, 11000 iteration, loss:0.340\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "345 epoch, 12000 iteration, loss:0.355\n",
      " num 344 epoch \n",
      "####### Training Loss #######\n",
      "[0.32304745]\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "346 epoch,  1000 iteration, loss:0.288\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "346 epoch,  2000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 843 / 1000 correct (84.30)\n",
      "346 epoch,  3000 iteration, loss:0.291\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "346 epoch,  4000 iteration, loss:0.334\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "346 epoch,  5000 iteration, loss:0.339\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "346 epoch,  6000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "346 epoch,  7000 iteration, loss:0.323\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "346 epoch,  8000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "346 epoch,  9000 iteration, loss:0.352\n",
      "Checking accuracy on validation set\n",
      "Got 842 / 1000 correct (84.20)\n",
      "346 epoch, 10000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "346 epoch, 11000 iteration, loss:0.333\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "346 epoch, 12000 iteration, loss:0.358\n",
      " num 345 epoch \n",
      "####### Training Loss #######\n",
      "[0.32144364]\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "347 epoch,  1000 iteration, loss:0.307\n",
      "Checking accuracy on validation set\n",
      "Got 836 / 1000 correct (83.60)\n",
      "347 epoch,  2000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "347 epoch,  3000 iteration, loss:0.310\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "347 epoch,  4000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "347 epoch,  5000 iteration, loss:0.345\n",
      "Checking accuracy on validation set\n",
      "Got 832 / 1000 correct (83.20)\n",
      "347 epoch,  6000 iteration, loss:0.327\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "347 epoch,  7000 iteration, loss:0.324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 812 / 1000 correct (81.20)\n",
      "347 epoch,  8000 iteration, loss:0.324\n",
      "Checking accuracy on validation set\n",
      "Got 844 / 1000 correct (84.40)\n",
      "347 epoch,  9000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 837 / 1000 correct (83.70)\n",
      "347 epoch, 10000 iteration, loss:0.350\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "347 epoch, 11000 iteration, loss:0.348\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "347 epoch, 12000 iteration, loss:0.347\n",
      " num 346 epoch \n",
      "####### Training Loss #######\n",
      "[0.32384882]\n",
      "Checking accuracy on validation set\n",
      "Got 821 / 1000 correct (82.10)\n",
      "348 epoch,  1000 iteration, loss:0.302\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "348 epoch,  2000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 787 / 1000 correct (78.70)\n",
      "348 epoch,  3000 iteration, loss:0.313\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "348 epoch,  4000 iteration, loss:0.301\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "348 epoch,  5000 iteration, loss:0.346\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "348 epoch,  6000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 817 / 1000 correct (81.70)\n",
      "348 epoch,  7000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 838 / 1000 correct (83.80)\n",
      "348 epoch,  8000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "348 epoch,  9000 iteration, loss:0.361\n",
      "Checking accuracy on validation set\n",
      "Got 818 / 1000 correct (81.80)\n",
      "348 epoch, 10000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "348 epoch, 11000 iteration, loss:0.371\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "348 epoch, 12000 iteration, loss:0.365\n",
      " num 347 epoch \n",
      "####### Training Loss #######\n",
      "[0.32783673]\n",
      "Checking accuracy on validation set\n",
      "Got 834 / 1000 correct (83.40)\n",
      "349 epoch,  1000 iteration, loss:0.281\n",
      "Checking accuracy on validation set\n",
      "Got 796 / 1000 correct (79.60)\n",
      "349 epoch,  2000 iteration, loss:0.306\n",
      "Checking accuracy on validation set\n",
      "Got 828 / 1000 correct (82.80)\n",
      "349 epoch,  3000 iteration, loss:0.317\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "349 epoch,  4000 iteration, loss:0.295\n",
      "Checking accuracy on validation set\n",
      "Got 831 / 1000 correct (83.10)\n",
      "349 epoch,  5000 iteration, loss:0.335\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "349 epoch,  6000 iteration, loss:0.332\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "349 epoch,  7000 iteration, loss:0.319\n",
      "Checking accuracy on validation set\n",
      "Got 848 / 1000 correct (84.80)\n",
      "349 epoch,  8000 iteration, loss:0.367\n",
      "Checking accuracy on validation set\n",
      "Got 819 / 1000 correct (81.90)\n",
      "349 epoch,  9000 iteration, loss:0.328\n",
      "Checking accuracy on validation set\n",
      "Got 825 / 1000 correct (82.50)\n",
      "349 epoch, 10000 iteration, loss:0.368\n",
      "Checking accuracy on validation set\n",
      "Got 858 / 1000 correct (85.80)\n",
      "349 epoch, 11000 iteration, loss:0.337\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "349 epoch, 12000 iteration, loss:0.361\n",
      " num 348 epoch \n",
      "####### Training Loss #######\n",
      "[0.32279195]\n",
      "Checking accuracy on validation set\n",
      "Got 835 / 1000 correct (83.50)\n",
      "350 epoch,  1000 iteration, loss:0.300\n",
      "Checking accuracy on validation set\n",
      "Got 840 / 1000 correct (84.00)\n",
      "350 epoch,  2000 iteration, loss:0.297\n",
      "Checking accuracy on validation set\n",
      "Got 853 / 1000 correct (85.30)\n",
      "350 epoch,  3000 iteration, loss:0.322\n",
      "Checking accuracy on validation set\n",
      "Got 851 / 1000 correct (85.10)\n",
      "350 epoch,  4000 iteration, loss:0.303\n",
      "Checking accuracy on validation set\n",
      "Got 852 / 1000 correct (85.20)\n",
      "350 epoch,  5000 iteration, loss:0.341\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "350 epoch,  6000 iteration, loss:0.325\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "350 epoch,  7000 iteration, loss:0.311\n",
      "Checking accuracy on validation set\n",
      "Got 820 / 1000 correct (82.00)\n",
      "350 epoch,  8000 iteration, loss:0.343\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "350 epoch,  9000 iteration, loss:0.338\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "350 epoch, 10000 iteration, loss:0.331\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "350 epoch, 11000 iteration, loss:0.360\n",
      "Checking accuracy on validation set\n",
      "Got 822 / 1000 correct (82.20)\n",
      "350 epoch, 12000 iteration, loss:0.396\n",
      " num 349 epoch \n",
      "####### Training Loss #######\n",
      "[0.32459701]\n",
      "finish training \n",
      "\n",
      "Checking accuracy on test set\n",
      "Got 8328 / 10000 correct (83.28)\n",
      "#####################################\n",
      "Accuracy on testing set 8328.00\n",
      "#####################################\n",
      "now begin saving datum for next step plotting\n",
      "now plotting accuracies and losses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Anacondas/anaconda3/envs/cs231n/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type ALL_CNN_C. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1,) and (4200,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-df29c606427c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m orig_all_cnn_c = help_func.running_model(run_num, orig_all_cnn_c, net_name, lr, epoch, \n\u001b[0;32m---> 11\u001b[0;31m                         loader_train, loader_val, loader_test)\n\u001b[0m",
      "\u001b[0;32m~/DL_course/midterm-Quant95/Nets/help_func.py\u001b[0m in \u001b[0;36mrunning_model\u001b[0;34m(run_num, net, net_name, lr_list, epoch_list, loader_train, loader_val, loader_test)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_epoch_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_axis_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anacondas/anaconda3/envs/cs231n/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2747\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2748\u001b[0m     return gca().plot(\n\u001b[0;32m-> 2749\u001b[0;31m         *args, scalex=scalex, scaley=scaley, data=data, **kwargs)\n\u001b[0m\u001b[1;32m   2750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2751\u001b[0m \u001b[0;31m# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anacondas/anaconda3/envs/cs231n/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1783\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1785\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/Anacondas/anaconda3/envs/cs231n/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1602\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1604\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1605\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1606\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anacondas/anaconda3/envs/cs231n/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anacondas/anaconda3/envs/cs231n/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anacondas/anaconda3/envs/cs231n/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 231\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1,) and (4200,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lr = [0.01, 0.005, 0.001, 0.0005] #[0.005,0.001,0.0005,0.0001] may be better\n",
    "lr = [0.005,0.001,0.0005,0.0001]\n",
    "epoch = [200, 250, 300] # first20\n",
    "\n",
    "run_num = 15 # 2\n",
    "net_name = 'Orig_ALL_CNN_C'\n",
    "\n",
    "torch.cuda.set_device(1)\n",
    "\n",
    "orig_all_cnn_c = help_func.running_model(run_num, orig_all_cnn_c, net_name, lr, epoch, \n",
    "                        loader_train, loader_val, loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from six.moves import cPickle\n",
    "save_path = '../datum_for_plotting/run_num_15/Orig_ALL_CNN_C'\n",
    "f =open(save_path + '/array_epoch_acc.save' , 'rb')\n",
    "acc_array = cPickle.load(f )\n",
    "f.close()\n",
    "\n",
    "max_epoch = 350\n",
    "a = np.concatenate(acc_array)\n",
    "a /=100\n",
    "length = a.shape[0]\n",
    "acc_axis_test = np.array(np.linspace(1,length, num=length))\n",
    "plt.plot(acc_axis_test, a.reshape(-1,1), '--r', label='Test')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show\n",
    "plt.savefig(save_path + '/validation_accuracy' + str(max_epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path\n",
    "import errno\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 32, 32, 3)\n",
      "(1000, 32, 32, 3)\n",
      "(5000, 32, 32, 3)\n",
      "(1000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as dset\n",
    "from PIL import Image    \n",
    "import os\n",
    "import os.path\n",
    "import errno\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "class CIFAR100(dset.CIFAR10):\n",
    "\n",
    "    base_folder = '.'\n",
    "    train_list = [\n",
    "        ['train', '16019d7e3df5f24257cddd939b257f8d'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test', 'f0ef6b0ae62326f3e7ffdfab6717acfc'],\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, root, train=True,\n",
    "                 transform=None, target_transform=None,\n",
    "                 download=False):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train  # training set or test set\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError('Dataset not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        # now load the picked numpy arrays\n",
    "        self.test_data = []\n",
    "        if self.train:\n",
    "            self.train_data = []\n",
    "            self.train_labels = []\n",
    "            for fentry in self.train_list:\n",
    "                f = fentry[0]\n",
    "                file = os.path.join(self.root, self.base_folder, f)\n",
    "                fo = open(file, 'rb')\n",
    "                if sys.version_info[0] == 2:\n",
    "                    entry = pickle.load(fo)\n",
    "                else:\n",
    "                    entry = pickle.load(fo, encoding='latin1')\n",
    "                self.train_data.append(entry['data'])\n",
    "                if 'labels' in entry:\n",
    "                    self.train_labels += entry['labels']\n",
    "                else:\n",
    "                    self.train_labels += entry['fine_labels']\n",
    "                fo.close()\n",
    "\n",
    "            self.train_data = np.concatenate(self.train_data)\n",
    "            self.train_data = self.train_data.reshape((5000, 3, 32, 32))\n",
    "            self.train_data = self.train_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "            print(self.train_data.shape)\n",
    "        else:\n",
    "            f = 'test'\n",
    "            file = os.path.join(self.root, self.base_folder, f)\n",
    "            fo = open(file, 'rb')\n",
    "            if sys.version_info[0] == 2:\n",
    "                entry = pickle.load(fo)\n",
    "            else:\n",
    "                entry = pickle.load(fo, encoding='latin1')\n",
    "            self.test_data = np.array(entry['data'])\n",
    "            if 'labels' in entry:\n",
    "                self.test_labels = entry['data']\n",
    "            else:\n",
    "                self.test_labels = entry['fine_labels']\n",
    "            fo.close()\n",
    "            self.test_data = self.test_data.reshape((1000, 3, 32, 32))\n",
    "            self.test_data = self.test_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "            print(self.test_data.shape)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        if self.train:\n",
    "            img, target = self.train_data[index], self.train_labels[index]\n",
    "        else:\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img.astype('uint8')).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)                \n",
    "            \n",
    "    def _check_integrity(self):\n",
    "        return True\n",
    "    \n",
    "\n",
    "\n",
    "if sys.version_info[0] == 2:\n",
    "    import cPickle as pickle\n",
    "else:\n",
    "    import pickle\n",
    "\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "A_train = CIFAR100('./class1', train=True, download=False,\n",
    "                             transform=transform)\n",
    "loaderA_train = torch.utils.data.DataLoader(A_train, batch_size=4)\n",
    "\n",
    "\n",
    "\n",
    "A_test = CIFAR100('./class1', train=False, download=False,\n",
    "                             transform=transform)\n",
    "loaderA_test = torch.utils.data.DataLoader(A_test, batch_size=4)\n",
    "\n",
    "\n",
    "B_train = CIFAR100('./class2', train=True, download=False,\n",
    "                             transform=transform)\n",
    "loaderB_train = torch.utils.data.DataLoader(B_train, batch_size=4)\n",
    "\n",
    "\n",
    "B_test = CIFAR100('./class2', train=False, download=False,\n",
    "                             transform=transform)\n",
    "loaderB_test = torch.utils.data.DataLoader(B_test, batch_size=4)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import new_ALL_Conv\n",
    "tf_all_cnn_c_step1_class1 = new_ALL_Conv.ALL_CNN_C()\n",
    "tf_params = copy.deepcopy(orig_all_cnn_c.state_dict())\n",
    "tf_all_cnn_c_step1_class1.load_state_dict(tf_params)\n",
    "\n",
    "tf_all_cnn_c_step1_class1.conv9 = nn.Conv2d(192, 10 ,kernel_size=1)\n",
    "nn.init.kaiming_normal_(tf_all_cnn_c_step1_class1.conv9.weight)\n",
    "nn.init.constant_(tf_all_cnn_c_step1_class1.conv9.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(tf_all_cnn_c_step1_class1.conv9.parameters(),\n",
    "                         lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples *100\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples,  acc))\n",
    "    return acc*100\n",
    "\n",
    "def running_model_tf_step1(run_num, net, net_name, lr_list, epoch_list, loader_train, \n",
    "                   loader_test, optimizer):\n",
    "    train_batch_size = 4\n",
    "    test_batch_size = 4\n",
    "    \n",
    "\n",
    "    # Constant to control how frequently we print train loss\n",
    "    print_every = 100\n",
    "\n",
    "    print('using device:', device)\n",
    "    \n",
    "    #net = BaseNet_A()\n",
    "    net = net.to(device=device)\n",
    "    criterion = nn.CrossEntropyLoss()        \n",
    "        \n",
    "    lr_1, lr_2, lr_3, lr_4 = lr_list[0], lr_list[1], lr_list[2], lr_list[3]\n",
    "    weight_decay = 0.001\n",
    "\n",
    "    max_epoch = 50\n",
    "    display_interval = 500\n",
    "\n",
    "    train_size = 5000\n",
    "    test_size = 1000\n",
    "\n",
    "    num_train_batch = train_size/train_batch_size\n",
    "    num_test_batch = test_size/test_batch_size\n",
    "\n",
    "    train_loss = np.zeros((max_epoch,1))\n",
    "    val_acc = np.zeros((max_epoch,1))\n",
    "    \n",
    "\n",
    "    epoch_acc = [] # max_epoch x num\n",
    "    print(\"begin training\")\n",
    "    for epoch in range(max_epoch):\n",
    "        if(epoch<epoch_list[0]):\n",
    "            lr = lr_1\n",
    "        elif(epoch<epoch_list[1]):\n",
    "            lr = lr_2\n",
    "        elif(epoch<epoch_list[2]):\n",
    "            lr = lr_3\n",
    "        else:\n",
    "            lr = lr_4\n",
    "            \n",
    "        optimizer = optimizer\n",
    "    \n",
    "        running_epoch_loss = 0.\n",
    "        running_loss_print = 0.\n",
    "        epoch_total_num = 0\n",
    "        correct_num = 0\n",
    "    \n",
    "        i_acc = []\n",
    "        #for i, data in enumerate(trainloader):\n",
    "        for i, data in enumerate(loader_train):\n",
    "            net.train()\n",
    "        \n",
    "            inputs_data, labels_data = data\n",
    "            inputs, labels = Variable(inputs_data), Variable(labels_data)\n",
    "            inputs = inputs.to(device=device, dtype=dtype)\n",
    "            labels = labels.to(device=device, dtype=torch.long)\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            running_epoch_loss += loss.item()\n",
    "            running_loss_print += loss.item()\n",
    "            if i%500 == 499: #net a, b, c 500 print once\n",
    "                \n",
    "                acc = check_accuracy(loader_test, net)\n",
    "                i_acc.append(acc)\n",
    "                print('%d epoch, %5d iteration, loss:%.3f' \n",
    "                      %(epoch+1, i+1, running_loss_print/500) )\n",
    "                running_loss_print = 0.\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        train_loss[epoch] = running_epoch_loss/num_train_batch\n",
    "        epoch_acc.append(i_acc)\n",
    "        \n",
    "        val_acc[epoch] = np.sum(epoch_acc[epoch])/49\n",
    "        \n",
    "        print(\" num %d epoch \" %epoch)\n",
    "        print(\"####### Training Loss #######\")\n",
    "        print(train_loss[epoch])\n",
    "        \n",
    "    \n",
    "    print('finish training \\n')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "##################################################################################################\n",
    "    print('now begin saving datum for next step plotting')\n",
    "    \n",
    "    save_path = '../datum_for_plotting/run_num_' + str(run_num)+'/'+ net_name\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    f = open(save_path + '/train_loss.save', 'wb')\n",
    "    cPickle.dump(train_loss, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "\n",
    "    f = open(save_path + '/val_acc.save', 'wb')\n",
    "    cPickle.dump(val_acc, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "\n",
    "    f = open(save_path + '/epoch_acc.save', 'wb')\n",
    "    cPickle.dump(epoch_acc, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "\n",
    "    array_epoch_acc = np.array(epoch_acc)\n",
    "    f = open(save_path + '/array_epoch_acc.save', 'wb')\n",
    "    cPickle.dump(array_epoch_acc, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "\n",
    "    #f = open(save_path + '/test_acc.save', 'wb')\n",
    "    #cPickle.dump(test_acc, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "    #f.close()\n",
    "\n",
    "\n",
    "\n",
    "    torch.save(net, save_path+'/'+ net_name +'.pkl') # save whole net structure and params\n",
    "    torch.save(net.state_dict, save_path+'/'+ net_name +'_params.pkl') # only save model params\n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "##################################################################################################    \n",
    "    print(\"now plotting accuracies and losses\")  \n",
    "    itern_axis_train = np.array(np.linspace(1,max_epoch,num=max_epoch))\n",
    "    \n",
    "\n",
    "    plt.plot(itern_axis_train, train_loss,'-b.', label='Train')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show\n",
    "    plt.savefig(save_path + '/train_loss' + str(max_epoch) + '.png')\n",
    "    \n",
    "    #a = np.concatenate(array_epoch_acc)\n",
    "    #a /= 100\n",
    "    #length = a.shape[0]\n",
    "    #itern_axis_test = np.array(np.linspace(1,length, num=length))\n",
    "    #plt.plot(itern_axis_test, a.reshape(-1,1), '--r', label='Test')\n",
    "    #plt.xlabel('iteration')\n",
    "    #plt.ylabel('accuracy')\n",
    "    #plt.savefig(save_path + '/testing_accuracy' + str(max_epoch) + '.png')\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n",
      "begin training\n",
      "Checking accuracy on test set\n",
      "Got 459 / 1000 correct (45.90)\n",
      "1 epoch,   500 iteration, loss:1.502\n",
      "Checking accuracy on test set\n",
      "Got 477 / 1000 correct (47.70)\n",
      "1 epoch,  1000 iteration, loss:1.462\n",
      " num 0 epoch \n",
      "####### Training Loss #######\n",
      "[1.47700959]\n",
      "Checking accuracy on test set\n",
      "Got 476 / 1000 correct (47.60)\n",
      "2 epoch,   500 iteration, loss:1.453\n",
      "Checking accuracy on test set\n",
      "Got 486 / 1000 correct (48.60)\n",
      "2 epoch,  1000 iteration, loss:1.415\n",
      " num 1 epoch \n",
      "####### Training Loss #######\n",
      "[1.43411993]\n",
      "Checking accuracy on test set\n",
      "Got 474 / 1000 correct (47.40)\n",
      "3 epoch,   500 iteration, loss:1.437\n",
      "Checking accuracy on test set\n",
      "Got 497 / 1000 correct (49.70)\n",
      "3 epoch,  1000 iteration, loss:1.405\n",
      " num 2 epoch \n",
      "####### Training Loss #######\n",
      "[1.41563109]\n",
      "Checking accuracy on test set\n",
      "Got 474 / 1000 correct (47.40)\n",
      "4 epoch,   500 iteration, loss:1.417\n",
      "Checking accuracy on test set\n",
      "Got 506 / 1000 correct (50.60)\n",
      "4 epoch,  1000 iteration, loss:1.391\n",
      " num 3 epoch \n",
      "####### Training Loss #######\n",
      "[1.400024]\n",
      "Checking accuracy on test set\n",
      "Got 480 / 1000 correct (48.00)\n",
      "5 epoch,   500 iteration, loss:1.397\n",
      "Checking accuracy on test set\n",
      "Got 500 / 1000 correct (50.00)\n",
      "5 epoch,  1000 iteration, loss:1.394\n",
      " num 4 epoch \n",
      "####### Training Loss #######\n",
      "[1.39718742]\n",
      "Checking accuracy on test set\n",
      "Got 498 / 1000 correct (49.80)\n",
      "6 epoch,   500 iteration, loss:1.406\n",
      "Checking accuracy on test set\n",
      "Got 513 / 1000 correct (51.30)\n",
      "6 epoch,  1000 iteration, loss:1.386\n",
      " num 5 epoch \n",
      "####### Training Loss #######\n",
      "[1.3930733]\n",
      "Checking accuracy on test set\n",
      "Got 508 / 1000 correct (50.80)\n",
      "7 epoch,   500 iteration, loss:1.399\n",
      "Checking accuracy on test set\n",
      "Got 517 / 1000 correct (51.70)\n",
      "7 epoch,  1000 iteration, loss:1.368\n",
      " num 6 epoch \n",
      "####### Training Loss #######\n",
      "[1.3836281]\n",
      "Checking accuracy on test set\n",
      "Got 507 / 1000 correct (50.70)\n",
      "8 epoch,   500 iteration, loss:1.385\n",
      "Checking accuracy on test set\n",
      "Got 522 / 1000 correct (52.20)\n",
      "8 epoch,  1000 iteration, loss:1.373\n",
      " num 7 epoch \n",
      "####### Training Loss #######\n",
      "[1.37986965]\n",
      "Checking accuracy on test set\n",
      "Got 494 / 1000 correct (49.40)\n",
      "9 epoch,   500 iteration, loss:1.376\n",
      "Checking accuracy on test set\n",
      "Got 511 / 1000 correct (51.10)\n",
      "9 epoch,  1000 iteration, loss:1.377\n",
      " num 8 epoch \n",
      "####### Training Loss #######\n",
      "[1.37867885]\n",
      "Checking accuracy on test set\n",
      "Got 509 / 1000 correct (50.90)\n",
      "10 epoch,   500 iteration, loss:1.393\n",
      "Checking accuracy on test set\n",
      "Got 519 / 1000 correct (51.90)\n",
      "10 epoch,  1000 iteration, loss:1.366\n",
      " num 9 epoch \n",
      "####### Training Loss #######\n",
      "[1.37954713]\n",
      "Checking accuracy on test set\n",
      "Got 507 / 1000 correct (50.70)\n",
      "11 epoch,   500 iteration, loss:1.378\n",
      "Checking accuracy on test set\n",
      "Got 510 / 1000 correct (51.00)\n",
      "11 epoch,  1000 iteration, loss:1.372\n",
      " num 10 epoch \n",
      "####### Training Loss #######\n",
      "[1.3738328]\n",
      "Checking accuracy on test set\n",
      "Got 502 / 1000 correct (50.20)\n",
      "12 epoch,   500 iteration, loss:1.375\n",
      "Checking accuracy on test set\n",
      "Got 512 / 1000 correct (51.20)\n",
      "12 epoch,  1000 iteration, loss:1.372\n",
      " num 11 epoch \n",
      "####### Training Loss #######\n",
      "[1.37153433]\n",
      "Checking accuracy on test set\n",
      "Got 519 / 1000 correct (51.90)\n",
      "13 epoch,   500 iteration, loss:1.384\n",
      "Checking accuracy on test set\n",
      "Got 514 / 1000 correct (51.40)\n",
      "13 epoch,  1000 iteration, loss:1.344\n",
      " num 12 epoch \n",
      "####### Training Loss #######\n",
      "[1.3675202]\n",
      "Checking accuracy on test set\n",
      "Got 499 / 1000 correct (49.90)\n",
      "14 epoch,   500 iteration, loss:1.388\n",
      "Checking accuracy on test set\n",
      "Got 522 / 1000 correct (52.20)\n",
      "14 epoch,  1000 iteration, loss:1.358\n",
      " num 13 epoch \n",
      "####### Training Loss #######\n",
      "[1.37145026]\n",
      "Checking accuracy on test set\n",
      "Got 505 / 1000 correct (50.50)\n",
      "15 epoch,   500 iteration, loss:1.373\n",
      "Checking accuracy on test set\n",
      "Got 518 / 1000 correct (51.80)\n",
      "15 epoch,  1000 iteration, loss:1.356\n",
      " num 14 epoch \n",
      "####### Training Loss #######\n",
      "[1.36403213]\n",
      "Checking accuracy on test set\n",
      "Got 511 / 1000 correct (51.10)\n",
      "16 epoch,   500 iteration, loss:1.381\n",
      "Checking accuracy on test set\n",
      "Got 521 / 1000 correct (52.10)\n",
      "16 epoch,  1000 iteration, loss:1.365\n",
      " num 15 epoch \n",
      "####### Training Loss #######\n",
      "[1.36719312]\n",
      "Checking accuracy on test set\n",
      "Got 502 / 1000 correct (50.20)\n",
      "17 epoch,   500 iteration, loss:1.375\n",
      "Checking accuracy on test set\n",
      "Got 520 / 1000 correct (52.00)\n",
      "17 epoch,  1000 iteration, loss:1.369\n",
      " num 16 epoch \n",
      "####### Training Loss #######\n",
      "[1.37190872]\n",
      "Checking accuracy on test set\n",
      "Got 498 / 1000 correct (49.80)\n",
      "18 epoch,   500 iteration, loss:1.378\n",
      "Checking accuracy on test set\n",
      "Got 522 / 1000 correct (52.20)\n",
      "18 epoch,  1000 iteration, loss:1.358\n",
      " num 17 epoch \n",
      "####### Training Loss #######\n",
      "[1.36402432]\n",
      "Checking accuracy on test set\n",
      "Got 512 / 1000 correct (51.20)\n",
      "19 epoch,   500 iteration, loss:1.385\n",
      "Checking accuracy on test set\n",
      "Got 511 / 1000 correct (51.10)\n",
      "19 epoch,  1000 iteration, loss:1.364\n",
      " num 18 epoch \n",
      "####### Training Loss #######\n",
      "[1.36848246]\n",
      "Checking accuracy on test set\n",
      "Got 513 / 1000 correct (51.30)\n",
      "20 epoch,   500 iteration, loss:1.372\n",
      "Checking accuracy on test set\n",
      "Got 521 / 1000 correct (52.10)\n",
      "20 epoch,  1000 iteration, loss:1.360\n",
      " num 19 epoch \n",
      "####### Training Loss #######\n",
      "[1.36956262]\n",
      "Checking accuracy on test set\n",
      "Got 520 / 1000 correct (52.00)\n",
      "21 epoch,   500 iteration, loss:1.380\n",
      "Checking accuracy on test set\n",
      "Got 514 / 1000 correct (51.40)\n",
      "21 epoch,  1000 iteration, loss:1.365\n",
      " num 20 epoch \n",
      "####### Training Loss #######\n",
      "[1.36757127]\n",
      "Checking accuracy on test set\n",
      "Got 520 / 1000 correct (52.00)\n",
      "22 epoch,   500 iteration, loss:1.375\n",
      "Checking accuracy on test set\n",
      "Got 521 / 1000 correct (52.10)\n",
      "22 epoch,  1000 iteration, loss:1.353\n",
      " num 21 epoch \n",
      "####### Training Loss #######\n",
      "[1.36197278]\n",
      "Checking accuracy on test set\n",
      "Got 512 / 1000 correct (51.20)\n",
      "23 epoch,   500 iteration, loss:1.375\n",
      "Checking accuracy on test set\n",
      "Got 518 / 1000 correct (51.80)\n",
      "23 epoch,  1000 iteration, loss:1.352\n",
      " num 22 epoch \n",
      "####### Training Loss #######\n",
      "[1.36129709]\n",
      "Checking accuracy on test set\n",
      "Got 518 / 1000 correct (51.80)\n",
      "24 epoch,   500 iteration, loss:1.363\n",
      "Checking accuracy on test set\n",
      "Got 518 / 1000 correct (51.80)\n",
      "24 epoch,  1000 iteration, loss:1.349\n",
      " num 23 epoch \n",
      "####### Training Loss #######\n",
      "[1.35581601]\n",
      "Checking accuracy on test set\n",
      "Got 508 / 1000 correct (50.80)\n",
      "25 epoch,   500 iteration, loss:1.368\n",
      "Checking accuracy on test set\n",
      "Got 523 / 1000 correct (52.30)\n",
      "25 epoch,  1000 iteration, loss:1.354\n",
      " num 24 epoch \n",
      "####### Training Loss #######\n",
      "[1.35722765]\n",
      "Checking accuracy on test set\n",
      "Got 513 / 1000 correct (51.30)\n",
      "26 epoch,   500 iteration, loss:1.390\n",
      "Checking accuracy on test set\n",
      "Got 519 / 1000 correct (51.90)\n",
      "26 epoch,  1000 iteration, loss:1.347\n",
      " num 25 epoch \n",
      "####### Training Loss #######\n",
      "[1.3671001]\n",
      "Checking accuracy on test set\n",
      "Got 503 / 1000 correct (50.30)\n",
      "27 epoch,   500 iteration, loss:1.368\n",
      "Checking accuracy on test set\n",
      "Got 513 / 1000 correct (51.30)\n",
      "27 epoch,  1000 iteration, loss:1.360\n",
      " num 26 epoch \n",
      "####### Training Loss #######\n",
      "[1.36035418]\n",
      "Checking accuracy on test set\n",
      "Got 525 / 1000 correct (52.50)\n",
      "28 epoch,   500 iteration, loss:1.368\n",
      "Checking accuracy on test set\n",
      "Got 518 / 1000 correct (51.80)\n",
      "28 epoch,  1000 iteration, loss:1.354\n",
      " num 27 epoch \n",
      "####### Training Loss #######\n",
      "[1.35819489]\n",
      "Checking accuracy on test set\n",
      "Got 517 / 1000 correct (51.70)\n",
      "29 epoch,   500 iteration, loss:1.357\n",
      "Checking accuracy on test set\n",
      "Got 522 / 1000 correct (52.20)\n",
      "29 epoch,  1000 iteration, loss:1.351\n",
      " num 28 epoch \n",
      "####### Training Loss #######\n",
      "[1.35265665]\n",
      "Checking accuracy on test set\n",
      "Got 508 / 1000 correct (50.80)\n",
      "30 epoch,   500 iteration, loss:1.363\n",
      "Checking accuracy on test set\n",
      "Got 524 / 1000 correct (52.40)\n",
      "30 epoch,  1000 iteration, loss:1.358\n",
      " num 29 epoch \n",
      "####### Training Loss #######\n",
      "[1.35878998]\n",
      "Checking accuracy on test set\n",
      "Got 514 / 1000 correct (51.40)\n",
      "31 epoch,   500 iteration, loss:1.371\n",
      "Checking accuracy on test set\n",
      "Got 523 / 1000 correct (52.30)\n",
      "31 epoch,  1000 iteration, loss:1.362\n",
      " num 30 epoch \n",
      "####### Training Loss #######\n",
      "[1.36715161]\n",
      "Checking accuracy on test set\n",
      "Got 503 / 1000 correct (50.30)\n",
      "32 epoch,   500 iteration, loss:1.370\n",
      "Checking accuracy on test set\n",
      "Got 513 / 1000 correct (51.30)\n",
      "32 epoch,  1000 iteration, loss:1.347\n",
      " num 31 epoch \n",
      "####### Training Loss #######\n",
      "[1.35463941]\n",
      "Checking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 514 / 1000 correct (51.40)\n",
      "33 epoch,   500 iteration, loss:1.384\n",
      "Checking accuracy on test set\n",
      "Got 517 / 1000 correct (51.70)\n",
      "33 epoch,  1000 iteration, loss:1.364\n",
      " num 32 epoch \n",
      "####### Training Loss #######\n",
      "[1.36816619]\n",
      "Checking accuracy on test set\n",
      "Got 515 / 1000 correct (51.50)\n",
      "34 epoch,   500 iteration, loss:1.373\n",
      "Checking accuracy on test set\n",
      "Got 518 / 1000 correct (51.80)\n",
      "34 epoch,  1000 iteration, loss:1.354\n",
      " num 33 epoch \n",
      "####### Training Loss #######\n",
      "[1.3604734]\n",
      "Checking accuracy on test set\n",
      "Got 516 / 1000 correct (51.60)\n",
      "35 epoch,   500 iteration, loss:1.374\n",
      "Checking accuracy on test set\n",
      "Got 514 / 1000 correct (51.40)\n",
      "35 epoch,  1000 iteration, loss:1.351\n",
      " num 34 epoch \n",
      "####### Training Loss #######\n",
      "[1.36483865]\n",
      "Checking accuracy on test set\n",
      "Got 514 / 1000 correct (51.40)\n",
      "36 epoch,   500 iteration, loss:1.375\n",
      "Checking accuracy on test set\n",
      "Got 513 / 1000 correct (51.30)\n",
      "36 epoch,  1000 iteration, loss:1.350\n",
      " num 35 epoch \n",
      "####### Training Loss #######\n",
      "[1.36388519]\n",
      "Checking accuracy on test set\n",
      "Got 509 / 1000 correct (50.90)\n",
      "37 epoch,   500 iteration, loss:1.358\n",
      "Checking accuracy on test set\n",
      "Got 512 / 1000 correct (51.20)\n",
      "37 epoch,  1000 iteration, loss:1.351\n",
      " num 36 epoch \n",
      "####### Training Loss #######\n",
      "[1.35265599]\n",
      "Checking accuracy on test set\n",
      "Got 514 / 1000 correct (51.40)\n",
      "38 epoch,   500 iteration, loss:1.360\n",
      "Checking accuracy on test set\n",
      "Got 512 / 1000 correct (51.20)\n",
      "38 epoch,  1000 iteration, loss:1.349\n",
      " num 37 epoch \n",
      "####### Training Loss #######\n",
      "[1.35634563]\n",
      "Checking accuracy on test set\n",
      "Got 514 / 1000 correct (51.40)\n",
      "39 epoch,   500 iteration, loss:1.371\n",
      "Checking accuracy on test set\n",
      "Got 517 / 1000 correct (51.70)\n",
      "39 epoch,  1000 iteration, loss:1.340\n",
      " num 38 epoch \n",
      "####### Training Loss #######\n",
      "[1.3507044]\n",
      "Checking accuracy on test set\n",
      "Got 518 / 1000 correct (51.80)\n",
      "40 epoch,   500 iteration, loss:1.353\n",
      "Checking accuracy on test set\n",
      "Got 519 / 1000 correct (51.90)\n",
      "40 epoch,  1000 iteration, loss:1.361\n",
      " num 39 epoch \n",
      "####### Training Loss #######\n",
      "[1.35430673]\n",
      "Checking accuracy on test set\n",
      "Got 514 / 1000 correct (51.40)\n",
      "41 epoch,   500 iteration, loss:1.371\n",
      "Checking accuracy on test set\n",
      "Got 518 / 1000 correct (51.80)\n",
      "41 epoch,  1000 iteration, loss:1.345\n",
      " num 40 epoch \n",
      "####### Training Loss #######\n",
      "[1.35440627]\n",
      "Checking accuracy on test set\n",
      "Got 510 / 1000 correct (51.00)\n",
      "42 epoch,   500 iteration, loss:1.365\n",
      "Checking accuracy on test set\n",
      "Got 521 / 1000 correct (52.10)\n",
      "42 epoch,  1000 iteration, loss:1.355\n",
      " num 41 epoch \n",
      "####### Training Loss #######\n",
      "[1.35992217]\n",
      "Checking accuracy on test set\n",
      "Got 513 / 1000 correct (51.30)\n",
      "43 epoch,   500 iteration, loss:1.357\n",
      "Checking accuracy on test set\n",
      "Got 528 / 1000 correct (52.80)\n",
      "43 epoch,  1000 iteration, loss:1.326\n",
      " num 42 epoch \n",
      "####### Training Loss #######\n",
      "[1.33817501]\n",
      "Checking accuracy on test set\n",
      "Got 514 / 1000 correct (51.40)\n",
      "44 epoch,   500 iteration, loss:1.356\n",
      "Checking accuracy on test set\n",
      "Got 515 / 1000 correct (51.50)\n",
      "44 epoch,  1000 iteration, loss:1.349\n",
      " num 43 epoch \n",
      "####### Training Loss #######\n",
      "[1.35336749]\n",
      "Checking accuracy on test set\n",
      "Got 510 / 1000 correct (51.00)\n",
      "45 epoch,   500 iteration, loss:1.368\n",
      "Checking accuracy on test set\n",
      "Got 520 / 1000 correct (52.00)\n",
      "45 epoch,  1000 iteration, loss:1.336\n",
      " num 44 epoch \n",
      "####### Training Loss #######\n",
      "[1.35101328]\n",
      "Checking accuracy on test set\n",
      "Got 508 / 1000 correct (50.80)\n",
      "46 epoch,   500 iteration, loss:1.364\n",
      "Checking accuracy on test set\n",
      "Got 522 / 1000 correct (52.20)\n",
      "46 epoch,  1000 iteration, loss:1.347\n",
      " num 45 epoch \n",
      "####### Training Loss #######\n",
      "[1.35193886]\n",
      "Checking accuracy on test set\n",
      "Got 517 / 1000 correct (51.70)\n",
      "47 epoch,   500 iteration, loss:1.369\n",
      "Checking accuracy on test set\n",
      "Got 520 / 1000 correct (52.00)\n",
      "47 epoch,  1000 iteration, loss:1.337\n",
      " num 46 epoch \n",
      "####### Training Loss #######\n",
      "[1.35213045]\n",
      "Checking accuracy on test set\n",
      "Got 511 / 1000 correct (51.10)\n",
      "48 epoch,   500 iteration, loss:1.354\n",
      "Checking accuracy on test set\n",
      "Got 520 / 1000 correct (52.00)\n",
      "48 epoch,  1000 iteration, loss:1.348\n",
      " num 47 epoch \n",
      "####### Training Loss #######\n",
      "[1.34576044]\n",
      "Checking accuracy on test set\n",
      "Got 516 / 1000 correct (51.60)\n",
      "49 epoch,   500 iteration, loss:1.355\n",
      "Checking accuracy on test set\n",
      "Got 517 / 1000 correct (51.70)\n",
      "49 epoch,  1000 iteration, loss:1.352\n",
      " num 48 epoch \n",
      "####### Training Loss #######\n",
      "[1.35344583]\n",
      "Checking accuracy on test set\n",
      "Got 524 / 1000 correct (52.40)\n",
      "50 epoch,   500 iteration, loss:1.369\n",
      "Checking accuracy on test set\n",
      "Got 518 / 1000 correct (51.80)\n",
      "50 epoch,  1000 iteration, loss:1.325\n",
      " num 49 epoch \n",
      "####### Training Loss #######\n",
      "[1.34775529]\n",
      "finish training \n",
      "\n",
      "now begin saving datum for next step plotting\n",
      "now plotting accuracies and losses\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_num = 12 # 10\n",
    "net_name = 'tf_ALL_CNN_C_step1_class1'\n",
    "lr = [0.01, 0.005, 0.001, 0.0005]\n",
    "epoch = [35, 40, 45]\n",
    "\n",
    "tf_all_cnn_c_step1_class1 = running_model_tf_step1(run_num, tf_all_cnn_c_step1_class1, net_name, lr, epoch,\n",
    "                                    loaderA_train, loaderA_test, optimizer_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 2)\n"
     ]
    }
   ],
   "source": [
    "save_path = '../datum_for_plotting/run_num_12/tf_ALL_CNN_C_step1_class1'\n",
    "f =open(save_path + '/array_epoch_acc.save' , 'rb')\n",
    "acc_array = cPickle.load(f )\n",
    "f.close()\n",
    "print(acc_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.concatenate(acc_array)\n",
    "a /=100\n",
    "length = a.shape[0]\n",
    "acc_axis_test = np.array(np.linspace(1,length, num=length))\n",
    "plt.plot(acc_axis_test, a.reshape(-1,1), '--r', label='Test')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show\n",
    "plt.savefig(save_path + '/validation_accuracy' + str(max_epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_model_B(run_num, net, net_name, lr_list, epoch_list, loader_train, \n",
    "                   loader_test):\n",
    "    train_batch_size = 4\n",
    "    test_batch_size = 4\n",
    "    \n",
    "\n",
    "    # Constant to control how frequently we print train loss\n",
    "    print_every = 100\n",
    "\n",
    "    print('using device:', device)\n",
    "    \n",
    "    #net = BaseNet_A()\n",
    "    net = net.to(device=device)\n",
    "    criterion = nn.CrossEntropyLoss()        \n",
    "        \n",
    "    lr_1, lr_2, lr_3, lr_4 = lr_list[0], lr_list[1], lr_list[2], lr_list[3]\n",
    "    weight_decay = 0.001\n",
    "\n",
    "    max_epoch = 50 #350\n",
    "    display_interval = 500\n",
    "\n",
    "    train_size = 5000\n",
    "    test_size = 1000\n",
    "\n",
    "    num_train_batch = train_size/train_batch_size\n",
    "    num_test_batch = test_size/test_batch_size\n",
    "\n",
    "    train_loss = np.zeros((max_epoch,1))\n",
    "    val_acc = np.zeros((max_epoch,1))\n",
    "    \n",
    "    epoch_acc = [] # max_epoch x num\n",
    "    print(\"begin training\")\n",
    "    for epoch in range(max_epoch):\n",
    "        if(epoch<epoch_list[0]):\n",
    "            lr = lr_1\n",
    "        elif(epoch<epoch_list[1]):\n",
    "            lr = lr_2\n",
    "        elif(epoch<epoch_list[2]):\n",
    "            lr = lr_3\n",
    "        else:\n",
    "            lr = lr_4\n",
    "    \n",
    "        optimizer = optim.SGD( net.parameters(), lr=0.001,\n",
    "                              momentum=0.9, weight_decay=weight_decay)\n",
    "    \n",
    "        running_epoch_loss = 0.\n",
    "        running_loss_print = 0.\n",
    "        epoch_total_num = 0\n",
    "        correct_num = 0\n",
    "    \n",
    "        i_acc = []\n",
    "        \n",
    "        for i, data in enumerate(loader_train):\n",
    "            net.train()\n",
    "        \n",
    "            inputs_data, labels_data = data\n",
    "            inputs, labels = Variable(inputs_data), Variable(labels_data)\n",
    "            inputs = inputs.to(device=device, dtype=dtype)\n",
    "            labels = labels.to(device=device, dtype=torch.long)\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            running_epoch_loss += loss.item()\n",
    "            running_loss_print += loss.item()\n",
    "            if i%500 == 499: #net a, b, c 500 print once\n",
    "                \n",
    "                acc = check_accuracy(loader_test, net)\n",
    "                i_acc.append(acc)\n",
    "                print('%d epoch, %5d iteration, loss:%.3f' \n",
    "                      %(epoch+1, i+1, running_loss_print/500) )\n",
    "                running_loss_print = 0.\n",
    "            \n",
    "            \n",
    "        \n",
    "        train_loss[epoch] = running_epoch_loss/num_train_batch\n",
    "        epoch_acc.append(i_acc)\n",
    "        \n",
    "        val_acc[epoch] = np.sum(epoch_acc[epoch])/49\n",
    "        \n",
    "        print(\" num %d epoch \" %epoch)\n",
    "        print(\"####### Training Loss #######\")\n",
    "        print(train_loss[epoch])\n",
    "       \n",
    "    \n",
    "    print('finish training \\n')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "##################################################################################################\n",
    "    print('now begin saving datum for next step plotting')\n",
    "    \n",
    "    save_path = '../datum_for_plotting/run_num_' + str(run_num)+'/'+ net_name\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    f = open(save_path + '/train_loss.save', 'wb')\n",
    "    cPickle.dump(train_loss, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "\n",
    "    f = open(save_path + '/val_acc.save', 'wb')\n",
    "    cPickle.dump(val_acc, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "\n",
    "    f = open(save_path + '/epoch_acc.save', 'wb')\n",
    "    cPickle.dump(epoch_acc, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "\n",
    "    array_epoch_acc = np.array(epoch_acc)\n",
    "    f = open(save_path + '/array_epoch_acc.save', 'wb')\n",
    "    cPickle.dump(array_epoch_acc, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "\n",
    "    #f = open(save_path + '/test_acc.save', 'wb')\n",
    "    #cPickle.dump(test_acc, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "    #f.close()\n",
    "\n",
    "\n",
    "\n",
    "    torch.save(net, save_path+'/'+ net_name +'.pkl') # save whole net structure and params\n",
    "    torch.save(net.state_dict, save_path+'/'+ net_name +'_params.pkl') # only save model params\n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "##################################################################################################    \n",
    "    print(\"now plotting accuracies and losses\")  \n",
    "    itern_axis_train = np.array(np.linspace(1,max_epoch,num=max_epoch))\n",
    "    \n",
    "\n",
    "    plt.plot(itern_axis_train, train_loss,'-b.', label='Train')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.savefig(save_path + '/train_loss' + str(max_epoch) + '.png')\n",
    "    \n",
    "    #a = np.concatenate(array_epoch_acc)\n",
    "    #length = a.shape[0]\n",
    "    #itern_axis_test = np.array(np.linspace(1,length, num=length))\n",
    "    #plt.plot(itern_axis_test, a.reshape(-1,1), '--r', label='Test')\n",
    "    #plt.xlabel('iteration')\n",
    "    #plt.ylabel('loss')\n",
    "    #plt.savefig(save_path + '/testing_accuracy' + str(max_epoch) + '.png')\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n",
      "begin training\n",
      "Checking accuracy on test set\n",
      "Got 584 / 1000 correct (58.40)\n",
      "1 epoch,   500 iteration, loss:1.296\n",
      "Checking accuracy on test set\n",
      "Got 664 / 1000 correct (66.40)\n",
      "1 epoch,  1000 iteration, loss:1.104\n",
      " num 0 epoch \n",
      "####### Training Loss #######\n",
      "[1.16614052]\n",
      "Checking accuracy on test set\n",
      "Got 698 / 1000 correct (69.80)\n",
      "2 epoch,   500 iteration, loss:0.888\n",
      "Checking accuracy on test set\n",
      "Got 703 / 1000 correct (70.30)\n",
      "2 epoch,  1000 iteration, loss:0.835\n",
      " num 1 epoch \n",
      "####### Training Loss #######\n",
      "[0.84528832]\n",
      "Checking accuracy on test set\n",
      "Got 713 / 1000 correct (71.30)\n",
      "3 epoch,   500 iteration, loss:0.713\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "3 epoch,  1000 iteration, loss:0.708\n",
      " num 2 epoch \n",
      "####### Training Loss #######\n",
      "[0.69979437]\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "4 epoch,   500 iteration, loss:0.592\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "4 epoch,  1000 iteration, loss:0.577\n",
      " num 3 epoch \n",
      "####### Training Loss #######\n",
      "[0.57776461]\n",
      "Checking accuracy on test set\n",
      "Got 718 / 1000 correct (71.80)\n",
      "5 epoch,   500 iteration, loss:0.467\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "5 epoch,  1000 iteration, loss:0.493\n",
      " num 4 epoch \n",
      "####### Training Loss #######\n",
      "[0.47869529]\n",
      "Checking accuracy on test set\n",
      "Got 708 / 1000 correct (70.80)\n",
      "6 epoch,   500 iteration, loss:0.429\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "6 epoch,  1000 iteration, loss:0.448\n",
      " num 5 epoch \n",
      "####### Training Loss #######\n",
      "[0.43130797]\n",
      "Checking accuracy on test set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "7 epoch,   500 iteration, loss:0.363\n",
      "Checking accuracy on test set\n",
      "Got 754 / 1000 correct (75.40)\n",
      "7 epoch,  1000 iteration, loss:0.397\n",
      " num 6 epoch \n",
      "####### Training Loss #######\n",
      "[0.37317644]\n",
      "Checking accuracy on test set\n",
      "Got 755 / 1000 correct (75.50)\n",
      "8 epoch,   500 iteration, loss:0.324\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "8 epoch,  1000 iteration, loss:0.327\n",
      " num 7 epoch \n",
      "####### Training Loss #######\n",
      "[0.32716522]\n",
      "Checking accuracy on test set\n",
      "Got 762 / 1000 correct (76.20)\n",
      "9 epoch,   500 iteration, loss:0.293\n",
      "Checking accuracy on test set\n",
      "Got 759 / 1000 correct (75.90)\n",
      "9 epoch,  1000 iteration, loss:0.291\n",
      " num 8 epoch \n",
      "####### Training Loss #######\n",
      "[0.28891513]\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "10 epoch,   500 iteration, loss:0.270\n",
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "10 epoch,  1000 iteration, loss:0.287\n",
      " num 9 epoch \n",
      "####### Training Loss #######\n",
      "[0.27160495]\n",
      "Checking accuracy on test set\n",
      "Got 711 / 1000 correct (71.10)\n",
      "11 epoch,   500 iteration, loss:0.244\n",
      "Checking accuracy on test set\n",
      "Got 760 / 1000 correct (76.00)\n",
      "11 epoch,  1000 iteration, loss:0.274\n",
      " num 10 epoch \n",
      "####### Training Loss #######\n",
      "[0.2600881]\n",
      "Checking accuracy on test set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "12 epoch,   500 iteration, loss:0.223\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "12 epoch,  1000 iteration, loss:0.215\n",
      " num 11 epoch \n",
      "####### Training Loss #######\n",
      "[0.21231782]\n",
      "Checking accuracy on test set\n",
      "Got 762 / 1000 correct (76.20)\n",
      "13 epoch,   500 iteration, loss:0.217\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "13 epoch,  1000 iteration, loss:0.232\n",
      " num 12 epoch \n",
      "####### Training Loss #######\n",
      "[0.21167557]\n",
      "Checking accuracy on test set\n",
      "Got 719 / 1000 correct (71.90)\n",
      "14 epoch,   500 iteration, loss:0.182\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "14 epoch,  1000 iteration, loss:0.240\n",
      " num 13 epoch \n",
      "####### Training Loss #######\n",
      "[0.21529321]\n",
      "Checking accuracy on test set\n",
      "Got 713 / 1000 correct (71.30)\n",
      "15 epoch,   500 iteration, loss:0.168\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "15 epoch,  1000 iteration, loss:0.177\n",
      " num 14 epoch \n",
      "####### Training Loss #######\n",
      "[0.17107579]\n",
      "Checking accuracy on test set\n",
      "Got 761 / 1000 correct (76.10)\n",
      "16 epoch,   500 iteration, loss:0.160\n",
      "Checking accuracy on test set\n",
      "Got 732 / 1000 correct (73.20)\n",
      "16 epoch,  1000 iteration, loss:0.162\n",
      " num 15 epoch \n",
      "####### Training Loss #######\n",
      "[0.16166243]\n",
      "Checking accuracy on test set\n",
      "Got 722 / 1000 correct (72.20)\n",
      "17 epoch,   500 iteration, loss:0.137\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "17 epoch,  1000 iteration, loss:0.150\n",
      " num 16 epoch \n",
      "####### Training Loss #######\n",
      "[0.1533405]\n",
      "Checking accuracy on test set\n",
      "Got 770 / 1000 correct (77.00)\n",
      "18 epoch,   500 iteration, loss:0.124\n",
      "Checking accuracy on test set\n",
      "Got 759 / 1000 correct (75.90)\n",
      "18 epoch,  1000 iteration, loss:0.125\n",
      " num 17 epoch \n",
      "####### Training Loss #######\n",
      "[0.12491289]\n",
      "Checking accuracy on test set\n",
      "Got 759 / 1000 correct (75.90)\n",
      "19 epoch,   500 iteration, loss:0.124\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "19 epoch,  1000 iteration, loss:0.129\n",
      " num 18 epoch \n",
      "####### Training Loss #######\n",
      "[0.12070948]\n",
      "Checking accuracy on test set\n",
      "Got 777 / 1000 correct (77.70)\n",
      "20 epoch,   500 iteration, loss:0.126\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "20 epoch,  1000 iteration, loss:0.143\n",
      " num 19 epoch \n",
      "####### Training Loss #######\n",
      "[0.1371234]\n",
      "Checking accuracy on test set\n",
      "Got 773 / 1000 correct (77.30)\n",
      "21 epoch,   500 iteration, loss:0.126\n",
      "Checking accuracy on test set\n",
      "Got 757 / 1000 correct (75.70)\n",
      "21 epoch,  1000 iteration, loss:0.130\n",
      " num 20 epoch \n",
      "####### Training Loss #######\n",
      "[0.12398737]\n",
      "Checking accuracy on test set\n",
      "Got 774 / 1000 correct (77.40)\n",
      "22 epoch,   500 iteration, loss:0.107\n",
      "Checking accuracy on test set\n",
      "Got 782 / 1000 correct (78.20)\n",
      "22 epoch,  1000 iteration, loss:0.114\n",
      " num 21 epoch \n",
      "####### Training Loss #######\n",
      "[0.10621194]\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "23 epoch,   500 iteration, loss:0.135\n",
      "Checking accuracy on test set\n",
      "Got 777 / 1000 correct (77.70)\n",
      "23 epoch,  1000 iteration, loss:0.108\n",
      " num 22 epoch \n",
      "####### Training Loss #######\n",
      "[0.11966292]\n",
      "Checking accuracy on test set\n",
      "Got 784 / 1000 correct (78.40)\n",
      "24 epoch,   500 iteration, loss:0.089\n",
      "Checking accuracy on test set\n",
      "Got 778 / 1000 correct (77.80)\n",
      "24 epoch,  1000 iteration, loss:0.107\n",
      " num 23 epoch \n",
      "####### Training Loss #######\n",
      "[0.10018195]\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "25 epoch,   500 iteration, loss:0.084\n",
      "Checking accuracy on test set\n",
      "Got 768 / 1000 correct (76.80)\n",
      "25 epoch,  1000 iteration, loss:0.106\n",
      " num 24 epoch \n",
      "####### Training Loss #######\n",
      "[0.09713433]\n",
      "Checking accuracy on test set\n",
      "Got 797 / 1000 correct (79.70)\n",
      "26 epoch,   500 iteration, loss:0.092\n",
      "Checking accuracy on test set\n",
      "Got 775 / 1000 correct (77.50)\n",
      "26 epoch,  1000 iteration, loss:0.081\n",
      " num 25 epoch \n",
      "####### Training Loss #######\n",
      "[0.0865377]\n",
      "Checking accuracy on test set\n",
      "Got 774 / 1000 correct (77.40)\n",
      "27 epoch,   500 iteration, loss:0.072\n",
      "Checking accuracy on test set\n",
      "Got 783 / 1000 correct (78.30)\n",
      "27 epoch,  1000 iteration, loss:0.116\n",
      " num 26 epoch \n",
      "####### Training Loss #######\n",
      "[0.0911556]\n",
      "Checking accuracy on test set\n",
      "Got 789 / 1000 correct (78.90)\n",
      "28 epoch,   500 iteration, loss:0.096\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "28 epoch,  1000 iteration, loss:0.092\n",
      " num 27 epoch \n",
      "####### Training Loss #######\n",
      "[0.10412307]\n",
      "Checking accuracy on test set\n",
      "Got 791 / 1000 correct (79.10)\n",
      "29 epoch,   500 iteration, loss:0.079\n",
      "Checking accuracy on test set\n",
      "Got 783 / 1000 correct (78.30)\n",
      "29 epoch,  1000 iteration, loss:0.096\n",
      " num 28 epoch \n",
      "####### Training Loss #######\n",
      "[0.0894227]\n",
      "Checking accuracy on test set\n",
      "Got 783 / 1000 correct (78.30)\n",
      "30 epoch,   500 iteration, loss:0.070\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "30 epoch,  1000 iteration, loss:0.122\n",
      " num 29 epoch \n",
      "####### Training Loss #######\n",
      "[0.08661045]\n",
      "Checking accuracy on test set\n",
      "Got 752 / 1000 correct (75.20)\n",
      "31 epoch,   500 iteration, loss:0.086\n",
      "Checking accuracy on test set\n",
      "Got 787 / 1000 correct (78.70)\n",
      "31 epoch,  1000 iteration, loss:0.062\n",
      " num 30 epoch \n",
      "####### Training Loss #######\n",
      "[0.07226463]\n",
      "Checking accuracy on test set\n",
      "Got 776 / 1000 correct (77.60)\n",
      "32 epoch,   500 iteration, loss:0.087\n",
      "Checking accuracy on test set\n",
      "Got 783 / 1000 correct (78.30)\n",
      "32 epoch,  1000 iteration, loss:0.076\n",
      " num 31 epoch \n",
      "####### Training Loss #######\n",
      "[0.08012246]\n",
      "Checking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 770 / 1000 correct (77.00)\n",
      "33 epoch,   500 iteration, loss:0.069\n",
      "Checking accuracy on test set\n",
      "Got 770 / 1000 correct (77.00)\n",
      "33 epoch,  1000 iteration, loss:0.097\n",
      " num 32 epoch \n",
      "####### Training Loss #######\n",
      "[0.0825994]\n",
      "Checking accuracy on test set\n",
      "Got 788 / 1000 correct (78.80)\n",
      "34 epoch,   500 iteration, loss:0.065\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "34 epoch,  1000 iteration, loss:0.105\n",
      " num 33 epoch \n",
      "####### Training Loss #######\n",
      "[0.08593191]\n",
      "Checking accuracy on test set\n",
      "Got 780 / 1000 correct (78.00)\n",
      "35 epoch,   500 iteration, loss:0.098\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "35 epoch,  1000 iteration, loss:0.061\n",
      " num 34 epoch \n",
      "####### Training Loss #######\n",
      "[0.08208886]\n",
      "Checking accuracy on test set\n",
      "Got 783 / 1000 correct (78.30)\n",
      "36 epoch,   500 iteration, loss:0.060\n",
      "Checking accuracy on test set\n",
      "Got 767 / 1000 correct (76.70)\n",
      "36 epoch,  1000 iteration, loss:0.072\n",
      " num 35 epoch \n",
      "####### Training Loss #######\n",
      "[0.06723274]\n",
      "Checking accuracy on test set\n",
      "Got 784 / 1000 correct (78.40)\n",
      "37 epoch,   500 iteration, loss:0.052\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "37 epoch,  1000 iteration, loss:0.067\n",
      " num 36 epoch \n",
      "####### Training Loss #######\n",
      "[0.06550827]\n",
      "Checking accuracy on test set\n",
      "Got 761 / 1000 correct (76.10)\n",
      "38 epoch,   500 iteration, loss:0.057\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "38 epoch,  1000 iteration, loss:0.077\n",
      " num 37 epoch \n",
      "####### Training Loss #######\n",
      "[0.06344639]\n",
      "Checking accuracy on test set\n",
      "Got 789 / 1000 correct (78.90)\n",
      "39 epoch,   500 iteration, loss:0.066\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "39 epoch,  1000 iteration, loss:0.043\n",
      " num 38 epoch \n",
      "####### Training Loss #######\n",
      "[0.0520313]\n",
      "Checking accuracy on test set\n",
      "Got 786 / 1000 correct (78.60)\n",
      "40 epoch,   500 iteration, loss:0.065\n",
      "Checking accuracy on test set\n",
      "Got 781 / 1000 correct (78.10)\n",
      "40 epoch,  1000 iteration, loss:0.076\n",
      " num 39 epoch \n",
      "####### Training Loss #######\n",
      "[0.07147485]\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "41 epoch,   500 iteration, loss:0.078\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "41 epoch,  1000 iteration, loss:0.074\n",
      " num 40 epoch \n",
      "####### Training Loss #######\n",
      "[0.06800904]\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "42 epoch,   500 iteration, loss:0.099\n",
      "Checking accuracy on test set\n",
      "Got 778 / 1000 correct (77.80)\n",
      "42 epoch,  1000 iteration, loss:0.068\n",
      " num 41 epoch \n",
      "####### Training Loss #######\n",
      "[0.08531594]\n",
      "Checking accuracy on test set\n",
      "Got 789 / 1000 correct (78.90)\n",
      "43 epoch,   500 iteration, loss:0.057\n",
      "Checking accuracy on test set\n",
      "Got 772 / 1000 correct (77.20)\n",
      "43 epoch,  1000 iteration, loss:0.089\n",
      " num 42 epoch \n",
      "####### Training Loss #######\n",
      "[0.06888887]\n",
      "Checking accuracy on test set\n",
      "Got 766 / 1000 correct (76.60)\n",
      "44 epoch,   500 iteration, loss:0.050\n",
      "Checking accuracy on test set\n",
      "Got 784 / 1000 correct (78.40)\n",
      "44 epoch,  1000 iteration, loss:0.063\n",
      " num 43 epoch \n",
      "####### Training Loss #######\n",
      "[0.05421005]\n",
      "Checking accuracy on test set\n",
      "Got 785 / 1000 correct (78.50)\n",
      "45 epoch,   500 iteration, loss:0.037\n",
      "Checking accuracy on test set\n",
      "Got 785 / 1000 correct (78.50)\n",
      "45 epoch,  1000 iteration, loss:0.069\n",
      " num 44 epoch \n",
      "####### Training Loss #######\n",
      "[0.0502614]\n",
      "Checking accuracy on test set\n",
      "Got 783 / 1000 correct (78.30)\n",
      "46 epoch,   500 iteration, loss:0.076\n",
      "Checking accuracy on test set\n",
      "Got 782 / 1000 correct (78.20)\n",
      "46 epoch,  1000 iteration, loss:0.048\n",
      " num 45 epoch \n",
      "####### Training Loss #######\n",
      "[0.06212547]\n",
      "Checking accuracy on test set\n",
      "Got 782 / 1000 correct (78.20)\n",
      "47 epoch,   500 iteration, loss:0.041\n",
      "Checking accuracy on test set\n",
      "Got 772 / 1000 correct (77.20)\n",
      "47 epoch,  1000 iteration, loss:0.052\n",
      " num 46 epoch \n",
      "####### Training Loss #######\n",
      "[0.04918107]\n",
      "Checking accuracy on test set\n",
      "Got 791 / 1000 correct (79.10)\n",
      "48 epoch,   500 iteration, loss:0.059\n",
      "Checking accuracy on test set\n",
      "Got 777 / 1000 correct (77.70)\n",
      "48 epoch,  1000 iteration, loss:0.056\n",
      " num 47 epoch \n",
      "####### Training Loss #######\n",
      "[0.0584179]\n",
      "Checking accuracy on test set\n",
      "Got 798 / 1000 correct (79.80)\n",
      "49 epoch,   500 iteration, loss:0.038\n",
      "Checking accuracy on test set\n",
      "Got 773 / 1000 correct (77.30)\n",
      "49 epoch,  1000 iteration, loss:0.057\n",
      " num 48 epoch \n",
      "####### Training Loss #######\n",
      "[0.0450457]\n",
      "Checking accuracy on test set\n",
      "Got 766 / 1000 correct (76.60)\n",
      "50 epoch,   500 iteration, loss:0.035\n",
      "Checking accuracy on test set\n",
      "Got 735 / 1000 correct (73.50)\n",
      "50 epoch,  1000 iteration, loss:0.060\n",
      " num 49 epoch \n",
      "####### Training Loss #######\n",
      "[0.04994373]\n",
      "finish training \n",
      "\n",
      "now begin saving datum for next step plotting\n",
      "now plotting accuracies and losses\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_num = 12\n",
    "net_name = 'tf_ALL_CNN_C_step2_class1'\n",
    "lr = [0.01, 0.005, 0.001, 0.0005]\n",
    "epoch = [35, 40, 45]\n",
    "tf_all_cnn_c_step2_class1 = running_model_B(run_num, tf_all_cnn_c_step1_class1, net_name, \n",
    "                                lr, epoch,loaderA_train, loaderA_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJztnXd4VGX2x78nIaFJT0A6AWkKAiEquLIKWFGxLYqrglhwXbu4yK4Nu66uXRRsYF0FsfzEQrGwIKCA9CIdIp2EqAkQkpzfH2de753JnZmbzNzMZOZ8nmeeyb1zy3vnZt5z33O+57zEzFAURVGSl5RYN0BRFEWJLWoIFEVRkhw1BIqiKEmOGgJFUZQkRw2BoihKkqOGQFEUJclRQ6AoipLkqCFQFEVJctQQKIqiJDk1Yt0AN2RkZHC7du1i3QxFUZRqxaJFi/Yyc2a47aqFIWjXrh0WLlwY62YoiqJUK4hoi5vt1DWkKIqS5KghUBRFSXLUECiKoiQ5nhoCIrqNiFYS0Qoieo+IahFRFhEtIKJ1RPQ+EaV72QZFURQlNJ4ZAiJqCeBmADnM3A1AKoChAB4H8DQzdwSQD+Bqr9qgKIqihMdr11ANALWJqAaAOgB2ABgAYIrv80kAzve4DYqiKEoIPDMEzPwLgCcBbIUYgAIAiwDsZ+YS32a5AFo67U9EI4loIREt3LNnj1fNVBRFSXq8dA01AnAegCwALQDUBXCWw6aOc2Uy8wRmzmHmnMzMsPkQiqIo1Yc9e4D33491K/7AS9fQqQA2MfMeZj4MYCqAEwE09LmKAKAVgO0etkFRFCX+GDYMGDoUyM+PdUsAeGsItgLoQ0R1iIgADASwCsA3AP7i22Y4gE88bIOieM/IkcCHH8a6FUp1omFDICsLaNQo1i0B4G2MYAEkKLwYwHLfuSYAuBPA7US0HkATAK951QZF8ZxDh4BXXgFWrYp1S5TqxOrVQJcusW7FHxCzo4s+rsjJyWGtNaTEJRs2AEcdJX8XFwNpabFtjxL/lJUBderIQ8TTTwO33urZqYhoETPnhNtOM4sVJRK2brX+3rQpdu1Qqg9btogRAIDFi2PbFh9qCBQlErZts/5euzZ27VCqD23bAhs3At27y3scoIZAUSLh4EHrbzUESiB33gk0beq/LiVFAsU5OWoIFCUhGDkSYAYyMoCff3a3z+HDwL595dczA//+twSfk4n9+yW+4iU7d3p7/GD8+9+SM2B3Ib79NvDqq0D79sCOHUBRUWzaZkMNgaJEg5NPBo44wt22OTliOAKZMEGeIB96CCgtjW77wrF/f+w6y0aNgL/8Jfx2leWLL4Dmzate2WUX4tSrZ/09fjzw5ptAdjZw9tnAb79VbbscqBYzlClK3HLFFUCvXsCUKeG3BYAffwSWLQNGjCj/2bJl8r51KzBtGjB4cMXasnAhcMwxQO3aFdsPAK67DiAC/vvfiu8bCWVl8j5njnfnaNtW3n/8ETj6aO/OE8iuXfL+zDP++QKrVwMXXggMGiSvOEBHBIoSCZ9+Cmze7G5bZuCOO8Rn/Oyz5T//9VegdWugZUvgxRcr1o5ffwWOOw44v5I1HOfPF0NQ1aSkAAMGAF27lv9s2TJg5crIjs8MdO4sxnHJksiOVVFq1AAeeUTOP3WqrNu7V9yC9uuNAwm/GgJFqSwFBdIBt2kDLFggT5uLFgXf/tNPgdmzgSFDRD8eWF6goABo0kSezqdPB9atc9+W7b5KLdOnV/w68vNlFJKRARw4UPH9I2HXLqCwEMjNLf9Zjx5At27SeVaWb74Bjj0WqFnTnVSTWYzPU08BY8fKq7Ius4wM4J//BH76CbjoIjEAq1fLZyaZrFs3eTiIMWoIFMVOcTHw2GMS4AuHkY62bg3Ury8/cvNDd2LqVOkATjwRuO8+q/M2FBTIca69FjjrrIp1yvbOqrDQ/X6A5ZJ64QUxaJFQXAw88YT7tk+aJOfcujX4k3EkyaSffirKnPPPlw7ZuKKcmD0b6NBBOudRo4D775eX+W6XL3cO8gdj9Wpg927gpJNkec4c+Z8hskYEKSkVM/geoYZAUexMnChPcf/4R/htjSFo00Y6kNTU0BLSiRPlCbVJE1nev9//89atZVRx5JHA55/Lk+yYMcCll4o66fffgx87Kwv4z39EhVK3rv9nzz8vnVww7C6T9euDb2dn+3bgnnuAkhL/9c8/D4weLYFvN2zYIO+Biisjy73zTuDMM90dKxBmMQQDB4ohuPDC0N9hmzYSYxk/HvjlF9mfGejZU97/+legUycZJSxeHN6lM2wYcNll4rJLTwf+9z85RlGRnAsQ5VA8SEiZOe5fvXv3ZkXxnMOHmTt0YE5NZSZiXrw49Paff87cvTvzL7/I8lFHMV98cfntysqYf/3VWp4/X7qYadPCt2nwYOY2bWT7L790dx0HD1p/L1sm+w4ZEnz7Bx+Uc6SlMY8Z4+4cl10mx/38c//1I0bI+meecXecU09lPv748uvXr5fjTJwo39+77zLv2ePumIYVK+QYL79csf2CsWwZ82mnyf8GwNyyJfObb8pnu3czv/iitW1JCXPt2sy33SbLJ53kfJ233y7blZVFp40BAFjILvpYHREoycO6dcDNNwd/Atu2TZ7qX30VuPji8k/WgZx1lrhVWrSQ5U6dnEcEP/4INGsmowEAaNBA3gsKwrf5k0+A776Tv3/5Jfh2mzbJ0/yrrwKZmRK7AMTNdcQRwMsvB9/37rsl4J2V5X5EYJRJPXv6rzduFCdVlBMbN4o77Omn/b+79u3FrXLhhXJtw4bJ6KAifPqpvJ9zjrwzW99LIOPHywgnFN27Swxm507gjTeAPn0kJwQAvv4a+Ne/rNIRGzeKe6x7d1nu109GEZdcArzzjv91HjgQO+muDzUESnKwd690xM8/b/nEA8nKEq35sGEio+zUqWLnOPNMoG/f8usnTZJOKDtblp0MAbPkFzglkxlD4xRQNdx3n7hAunQRXfpXX4nb5b//Ba6/Xs4ZKnZAJO4t46oxTJnirPE/dEjcG82b+6/PzhbXSf36wc9lKCmRujsZGcDttwPz5vm3JzNT9Pft2wPnngvMnRv+mIFtGT1aVFiAfD8XXui87fvvuw+0N20KXHmlfDdXXSXr6tWT+zlzpiwvXy7v3brJ+003AWvWAJMn+z+IHH888Le/xV455GbYEOuXuoaUiHnoIePxZX766fKfr1/P/Pvv/us2bmQeNUpcRk5ceinz9deHPu/Bg8yNGjEPHWqtKy1lzssT94GhsFDa9thjzsd57z3mVauCn+e008T1UFLC3KQJ8+WXM48cyVyzplxHkybMY8eW32/lSuYTThB31bRpzB984P+5+c4KCvzXDxggrpEpU5zbOnly8LYaDh2S/Y2r7OGHrc+mTWO+9175rpjle27SJPwxQ3HttXIvAt0wZWXMjRvL55Xl0CHmhg2Zhw+X5bFjxYVUWGhts3ixXGfgd+whUNeQkpCUlFQ867akRIb+AwfKk1tglVBm4PLLgVNO8V+/ZIkEYINNOvPDD+UloMyWuwCQxLD8fGD4cGtdSookGKWmWuvM6MCMFgIZOtRZa2/YuVOezlNTJUnJHmzOygLatRP3RSCLF4tqp25d2W/IEOfj24vrAfLU37mzjBZM0PvAAbk3L7wAjBsXvK2G9HSRVZ5wgkzUYldRTZsmo7cUXxeVmQnk5bm/97m5Mrqzq4R695Z7sWVL+W3z8kSuWlnS04HzzgM+/liUU5ddBnzwgZSbNowdK++B8xCUlsY8u1gNgVK96NLF2f0Sis8+k47shhukQww0BD/9JAlVV17pv/7cc6VjNcN8O2Vl0oEY9Qcg7qcGDfwVM5MmiQro1FP993/oIeC996zlcIZgzZrQrosdO+Q8gGQk5+WJf9p0Pv37yzUG1rVZulQ6sc6dRakzf7745gE5BiDfi5lzwdCvnxgZwJJ3PvWUGLh69axjhGLtWnHXlZSI+8tuCLZtExWVISNDjKxb+eb48WII7YbAuOYC8wmWLpX3SAwBIHGlggJg1iz5vgJdasaYduzov75jR+DGGyM7d4SoIVCqDwcOiA/7xx8rtt+LLwKtWknH3r59eQmhkU8GyhRr1JD9nDKH9+wRP7m9s2rSxEpIMjzyiARwawRUc5k4UQyUwQQxg/nWn3tOpIdOHD4sRsj46884QwxNVpa1zYAB8qT6/ff++y5dKn7stDS5zr59Jb4AAI0bi+F47jlJyDIcPCiBWON7N/dj8WIxRu3aWeUVQjFxorSVqLwhyM2V794wfLiMepxqNDmxebPsb//eu3cXwx5oCAoKJJh/7LHujh2MU08Vw/bnP8sDQGBwf+ZMiYPUquW/vnXrmEtI1RAo1Qd7MDFUYpCdvDzpqK67TjqFqVPLu0hWr5aOrl278vu3bVvelQD45xAYiKSzeeklyQe48055Mjz77PL7N2jgn0eQni6F60xgOJCWLeVp2ClRi1ncECYQWq8ecNdd/kbqpJOkEzTKJbPfkiXWk3BWllyDPWBcu7YEnGfMsNZt2SJukMWL5frshiA7W4Kp+/aVzzEIZONG+c5TU4F33/W/L9u2+RuC+vWls05x2WVt2WLVGDLUqiXJbmec4b/+ssvEyLgJcIciPV3ci2vXyigq0Og2bixKo0DiIJdADYFSfSgtlQJv+fnlO4TcXOcM1MaN5bObb5Zlp45kzRpRCNl99oZ27Zz9tzVqiE89cJj/4YdSZKxFC/EXp6c7X0uDBv6qoZ49gW+/letzwnSKgdnIgJxjyBBLquhEvXrSrnPPtdYdPCgGon9/Wa5ZUwybkZD+858yGnjgASmdbDBtaNlSVC8//CAGd/NmMQTNmrlz42zcKJ0gIDEA408vLpZRm92Q5eWJMsrtjF6bNzsb9ttuE7eWV+TnA6edJn+Huh92OnSQ79Q+t0VV4yaiHOuXqoaUsNx8sygyjMokGCtWMJ93HvPy5da6pUuZv/3WeXu7sqeiFBcH/+yCC5i7dXN/rBkz5Pqc2pmbyzxrFnNRUcXbGMiAAcx9+oiSpkkT5quuYj7xROb+/a1t3npL2rJmjSiStm9nnjlT1s2YIclze/eGT5Jq3NhSXS1aJMlX+fmyXFYmShzD9u1y/HHjwl9DcTFzSgrzPfeU/+zAAebvv2fev1+Wf/uN+eijndVPleHQIUtpFUxtFsjUqbL9Z59Fpw02oKohJaE4fFjcIgUFUm4hMHBq3BuBdVsGDwZef91aLi2VJC17bfpjjxW3jBNOowTAne471ET2DRr4B25ffdXKAXDCjAiccgm++EIUUeHqI5WUSHKaSdxyct0cdZSMCDZvlif6446TJ3P7xCrG992ihbiTmjeXkcR994kyp149iZeEqma6f7885ZsRwcaNklRmzkPkP5oysQE3NaAA4KOPJHkrkDVrpNbTCy/I8vLl8r8QGMOpLOnpwDXXiPvJ7THPOQe4997go8EqQA2BEjuYJajppujWzJmiSFm5UjpNu/+VuXzgEpBO4//+z1K/AFYA1SiHtm8H3noreIXLDRvE7RLodrr8csulUhlefdXfF5+bKx20XW5oJytL1CiB/m3Aykpt1iz0OQ8fBk4/XTrIyy4TOeqf/uS/zY03StLTDz/I8vHHiyHIzbWM3/bt0tmbyVaeeUaUV2PHyj0qKJAYxfz5wdtSt67IVk1nbWIj27fLdV51lf99S0sT4+nGEKSlyQPAMceU/6xnT+CCCyTjetcuSzEUmCEdCa+8Anz5pfvt09KkuF2w+FAVoIZAiR1btkha/4AB4bf95hsJEPfsKZ2+XQK6c6el+LEbgp9+kncjGwSsp1WjBJo7VzKJQ2XtTplSXkK6cWPw0YIbAvf99VcpBRHsmDVryvfkpJrZsUNiIXZljxO1a0uWcWGh1dEbf7ahe3cJeP74oxyve3d52j90yJKE3nab6PwNb7whFVNNzINZ1FL24H4gaWmWkQH8DcEPP8gxA68nM9NdSeq1a0X5ZM/nsPPYY+KPHztWDEHDhv5B/1jx3XdSpiIGqCFQYoepOJmbG14F9PXXIm2sU0eeju2GwF6jxm4ITGDRbggA//1XrxY3RLByEq1by+eBEtKtW/2DmRXl229FWWKkrAUFwXMIDNOn+0tODTt3WjkE4XjmGRmBmZfJMzAcOCAjgnXrxN2UlibSzbw8axL2du38A65duoghe+45WW7QQFwkoSSkc+dapTcAS/q6fbv8PzRqVL7WU2amuzyC996TOlDB3HedOolBfOUV2fbYY2MzKU8g8+YBjz4aek4Lj1BDoMQO04F/9VV4f/JPP1mumHbt/DtmY1Duu89/hq7Fi8UH3bCh//Gysy2p4OrVIjMM5pJJT5enVbuEND9fOqyK1iKys2GDdISmY3NjCJ54QlxpgdiTySKltFQSo/r2tZ7669eXjtnco0mT/NU7xi1nVDpEYjRCJZW99ZZMyGKOWbOmjNTy88UQOBnZGTPcuVy2bJF7FkyxBYhPvkMHGWHZlVSxxNSEeuyxKj+1zlmsxI7+/eUJ9bTTQhuC2bNlxGBcSJ06SYygtNSaA6B2bflx2+WhzZo5zwk7frz195o1oUs3ANLB2Q2BcTn17h16v1AEFp7Lzg7vnmjVyl/Pb3jxxfCafbcccYR8b/YqpMXF4sM++WRJmrrmGunEzUjr3nvFkF58sbVPOENgl44atm+Xzjs72z+HwBCuGqwhmHTUTkaGPAS4zUuoCho0kBjNI48450F4SBx9C0rS0a0bcMstMnPTvfeG3u6RR6QmDSBlk9evt/zpa9eKnj8lxXpaB6RWzfPPBz9uWZnsG84QHHusdJCGJk3EJx7ocqoIZpRiDMG//iUlGkLRsqW4gQI7/V69RN0TLXbtAl57zXLtpKVJ26ZPl2BtSYk1CgDkWh56yN+n37Spf7A3ECdDYJ7g09PL52cAMnIcOTK8YsttJxpPRsAwaJBcn13VVgXE4TehJA1ffy0d2/z5wIMP+ksU7bRvL8lNwYKh110nnzNLB3LffaFjDkuWSMnnhQvFRRNuzthx40R9ZOjRQ+oJuS134IQZEQTOUhaKVq1kFGT3vR84ALz5pnMZjMpiRiaZmfJOJK6abdv8k8lC8fHHwctGz5wp7Q2sX/Tuu1KSef58GSkGsmKF+PWDzSkAiJHati38iCBeadtWgvWBZSg8Rg1BvMMc3R+5E7t3l6+i6TVFRRKMfOUVy0frFAh99FF/hQognedZZ4maB5D9hw6VDisnR1QnTz8tPyqnqQlr1ZKA3M8/S5AysKZ+ODZudF/iIhgNG8rLKFu6dg0/8YrpfO01bLZulWBuRWv1h2L+fPl+7E/MJpfAnkMQipo1g7v7Fi2SEhw33OC/3kiDg323xjCFUg4RiSz12mtDty9eadlSFHKRSJMrgRqCeGfSJFG5PPqod+d4/XXRp5vZlSpLaan7icZN7kDnzvLq2NH/qRuQOMBdd5U3EPXqyVPl4sViwObPt2rwHHecdChz5kiHYnfpGMzT4ssvy/carrTxsmVSI2b+fEn4OuqoyO9Hx47SdlMfaOvW8O0wdWzsmneTQxCtYDEghjHQ7WVGBMYQhBsRzJ4tBsqeILdjh7yPHi3fZWCbW7Swyog4uUaMIQiVS5CaKm2vriOCGKGGIN4xGbQ5OZXb/3//C+9+6NFDZJcPPFC5cxgeekg6YhNMDYVRDHXuLE9x554rriLTcRw4INMdtmkD/Pvf/vumpsr6TZukw+nb19L5H3ecdCYffxzch1+rlnR2c+eK7ztcPkCtWvKU+fPPojtnjm4C0uHDMkIKpxqqV08C5XY1jDEEFR3VVJQ2beTeXHqpfNfhzrdli7isTPtycyXBa9Uqud9OKi1zzGXLnO+JG0OwZImMKpyK81UXhgxxnhXOQ9QQxDs//CCZkCbx5/PP3bslDhyQkrhmztZg25xwgnS6jz/u/oneCfMDDZWcZTCST+MnHjxY1CobNojr5bLLZJvXXrMyWO2YXABzHCPltAdNQwVzzRNjuEAxYPnMt2wJnptQGa64Qq7PGD831S9feMHfVWaesqM5InDinnvkgaJ+fQnehzOeJufAKIe+/15GQIHzIdixu5ucVEOZmaIOCzXl5mefVV+3kOHwYee5rz1EDUE8s3u3dIymdO2CBdKpL1jgbn+j2gjlP54+XVQwf/2rdCZXXll5F9Ho0fLuphb92rXibjCSwH79pKPt2VMUQR99JMcbONB5f2MI1q6VTseocJo3tzqCUPJOc9zA2aKcqFVLvhtjCI48MjpP4NOni6EPNymNnaee8p/QZudOUfU0ahR5e0KRliZP8hMnSsJZOIwhMP8L8+ZJJx5q8he7IXCSirZpI4Zk6NDgx9i8WR4oatcO38Z4pWXL8nMZeIwagnjmwAEpf2D082aWptWr3e1vnjCd/OQGM4nKCSdI4HblSv+OpiK0aCEBxmDqHzv33CNJRYaUFCu4eOqpol1//PHg+2dnSye+cqW4l+zccgvw97+Hdqfdcou8uxkRABJ43rzZqrkfDUwp6po1xQC7MUqBncQdd8iDgdeZsXv3yv/iiBH+9y0Ypu6RGRHMmyf3I1QhvjZtZGQYrHyzm2vcsqX6xwdatQo/eooymlAWjMJCYNQo8Zubp5vK8vbbMpS+9NKK7de2rQSLDe3aSafh1hDUqyf6dFNXxomVK+UHWK+eKHFmz5Ya9ZUhJ0fcVm6qKHbqFDwzNyUlvMb7+uvl1bSpTJJi55hjJMkqFFu2SKfkpvMFJFBbUCAGJFgWckVp2FCO2aKF1NZxQ8uW/iUIMjIik7G6pWZNywC4KY6WmSkPIocOSV2fxYulRlE4jjwydPG8UaPkO7j9dufPN2+OLNEvHrCrw5zyKbzATa3qWL9iMh/BlClSI/ySSyI/lqlP7sTvvzN/9BHzE0+U/2z79vI13Y89lvnss92dd+dO5jlzQtep79mT+cwz3R0vFIWFco0PPxx+2/x85gkTmLdti+ycZWVSn3/Jksrtf/hw6DkDvObUU63a/+Fq9xtGjWKuXdvafsIEmQOgKqhdW+7xAw9UbL99+5hvuin4nA8VITubedAg/3WlpTLPRGkpc3o68+jRkZ8nlixaxHz55cwbNkR8KOh8BBFihpf2+Wcryz//KbXJi4v9148fL/75Cy4QN4jdN19SIoHUQG15ly5SFsENX3whT/cmoBhIaakcy16ud9YsedKuqE7eFHHLygqdUQqIKmTkyMi+24ICyfhdt67yk47XqBHaVRHI0qVSITLSHAJDVpbc/3fekSdue1nqYLRsKS5Dk/dx113ufPbRwNTXDycdDaRxYylIF2zOh4qQmemvGurfX1yfffqIvDU3N3yCYLyTnS2jr8DMaw/xzBAQUWciWmJ7/UpEtxLRWCL6xbbeoRhMHNC7t9RU2bYtvL47HN27S8ce2IG/+64ETGfOlGFgSopVw335cvERBsoUb7rJOevSCdMhn3GGzDsbSEmJ/ECHDLHWrVwp+vqKJpiZOVcnTJCOIlQZALt0tLLUry+Zpg89VN7AesG8eXIvTjklev74CRNE5VJQIEqRULEcw8iR4rZs0EBcLvZJ673GKIXc1s1/+GFx4WzaFLwkdEWxG4Jdu6SK6zXXyPI114ibzMhMqzPM0fvOXOCZIWDmtczck5l7AugNoAjAR76PnzafMfPnXrUhYgYMkE4t2BO1G0pKRJEDSMdlKCsTvf3pp4uCJT1dyiz06yfnM7Xc+/b1P95JJ4WWg9oxnfnGjfIUHkjNmqKwMTV8gPJqD8OOHeUn47Zjnmb79bM6qGCsXWvNj1tZTGfsNLG8F9gVPdEOzFZENVS3rsQoTj9dlDHMVWcIRoyQ0aPbrNelS0Xu3K8fcPXV0WlDRoZlCEzJ8SFDpDLrzJkSaLXPBV1dadMmeBzEA6rKNTQQwAZmrqJfbRS44w4Zdq9c6axpdos9mcueZVlcLC4jk1kKiCqjpETUO/PnS9AsUAFRXCwVKI1+PhT5+TIs79DBeRaw1av9jRNQXu1hGDdOftDB3CKtWwMXXWQFirdtC96un3+2isRFg1DlhqOFKWJ24onRO+Z//yt5Hnl5cg0VqS8zYoQ8ODz+uH/VTy956in5fwk3AY6hWTMx+r/8Er2ieG3biuErLhZDkJIirpSRI8Uwbt8evWknY0mDBu7ycaJEVX1jQwHYNYk3EtEwAAsBjGLmKi504wL7EzFz5Z8CzVP5W2/J9IaGWrXEENg56ihx44wfLx1D377lz1taKtvcd5+8QpGXJ/ryjh2dDcFDD0nmsV3uGZgIZMjMFCOQl+esUrnoInkZRcu2bcFllmvXBpcIVoSNG0MnF0WTunVFURWNdht27ZLvv3lzd6MBO/b/pXjFrrYLHNlWlltvlRcghuCYY6ycg9xcGWW7LVcdz1RxLoHnIwIiSgcwGICJaL0EoAOAngB2APhPkP1GEtFCIlq4x+2E1dFk717p8F5+WYZplfXXGT9948b+69etc06Vv+EGearp2xe4+ebyn9euLaMENxLSf/wDeOklMQTr15f3269aVX5e16ZNJYAaOIm60d0HqzFvvh8zoUioXIJ589zHOUKRlSVZrlVFv37lJ7mJBNP59+wpAfpEwy4DPfbY6B+/Wzf/+FbjxsETEKsbrVpV6YigKlxDZwFYzMy7AICZdzFzKTOXAXgFwPFOOzHzBGbOYeaczFgEf4whyMiQG1LZ0gv27N6ePS3/5d//bs2za2fQIDE8aWnBfbFdu7pTDvXqJaUpTjxRRhH2BBUnxRAg13vokL9P125AnAxBWZl0kA88ICOHe++V+WiD0bhxZO62RMEYlTPPlIlfEg3zUNCsWfTcdz//LJ39999LDap77onOceMNM/dEFQWMq8IQXAqbW4iI7JGtCwCsKLdHPLB3r0j7TjlFlr/+unLHadZMskbbtJHg2cqV0rEuXuyc+JKaKu6CUAlGXbqIeyWcmumLL0R9dPHFwIcf+g+ZN22SoO7RR/vvQ1TeHWWv/+40itm5U4xMRobse//9/gFoO8uXi0vLTRmKRMeMCHJzozfDWDxx1lnyu3n77ege9+uvJVYRLRlvPNK/v0jHq0IRB48NARER/LR6AAAdXUlEQVTVAXAagKm21f8mouVEtAxAfwAu0g1jwJAh8jSdkSHD2m++qdxxsrOlUzdP/8uXi9skLy+4D71Nm9CB1K5dpRMPV8ph2DAJ8hrsPxyj4Q8cEQDSkdvnxjWTkVx4oXOw1EhHje45Pz94MPv772XkUEX/4HFN06Yyahs8uMqrTVYZ/ftLyZBoYeJTf/+7xFYilXbHK/37S6nzKop3eBosZuYiAE0C1l3h5Tmjhr308YABEis4dMi9YsJQUmKVTa5XTwyBcXVVtmbN4MGyb6jEHmZLNcQscYVLL7Umxu7XT6R9TsHPOXNkQpe775ZlYwhuvtn5nMYQdOgg77feKobTyVBt3ixuL7da9ETmmGNkZNiuXcWDxclKw4byeyotlRhRuCqo1RVmURymprqrShshmlnsRGmp/xPrRRdJnZTK1Di/4w558iOS4Nby5fLjT02tvAKlaVMxBKH8rr/9JtfRqJFV/93+lN64sQzdnermBE48npEh+QY7dljabTsbN8o5jMSyTRtRPDi5OzZtku0S9QdcGQoK1BC4JSXFEl5Ec57meGPfPrlOtzWoIkQNgRMrV8qT/0e+/LeTTpLJ0yujGMnLszJGBw0Sn/yVVwLvvx9ZqdzJk8XvHwwjWzU/GruElFmyWp06dUAMgd2Hb+boffBBa0Rh54QTgDFjLMPUurW4oZwS8TZtkic5RQx1To5V519xh/kdJrIhaNJE+qAqkpCqIXDCZMXaa7ybRK6KBqjy8qzO+O67Rc551FEyyoiE55+3JJgHD0o8wz69n1ErmWvo1EkkpGVlUlP+uuv8q1jaadZM9PlGo19YKPsFjhQMZ50lhtJgMoadksp27qz+ZYKjRWqqdQ90ROCef/1L3hPZEBCJG7aKJKRqCJwwhsCeOPXBB5LWH6qksxP5+f4GZd8+mSM4mB7fLV27WrkE+/ZJev1331mfd+woCVD9+lnLBw9K7frbbpOM1pEjnY/dqpV01kbqOmKEuLGCGYItW/zdQKFyCTZvBp59tiJXmtiYkUBlS38nI716iWw0klpV1YFWrXREEFP27ZN3uyE491xxfVS00qN9RPD773LMq692VyIiFF26SDuff15quKem+v/THHGEGAFzDX36SFLY9dfL6Ob114Mrky6/XFw4JqC7fbuMEpo2LS8fLSoSo2F3GWVliSvJKZeAqHrPHhVtWrQQxVC0Mm+TgR49RHkWrRIl8YqOCGKMGRE0sQmeGjSQpKzJkyvmHho+HDj/fPnbXl0y0snPTaB5/Hj5QTRv7v9Ps3Kl6LcPHpTlHj3EH710qXTaRuHjhu3bpcNq2lRGOPZA+ubN8m4/Xp06ElwOLKM7b56MLowKSRE/8KpVVVppUqkmDBtWvgyNR6ghcKJPH7kBgbXqhwwRv3dF3ENjxljVRwGrIJabksOhGDgQ+PJLyXgmKp+SPm2aTI5u11kPGiT5ATfeGPrYeXmS9/DxxxJYNobgiiskD8D+JBaYQ2BYvbr897RwocQnEqEoWLQoKRFDECxwryQvZ55pldj2GDUETpx2mn/w0zB4sLiHPvvM3XFKS2V0Ye+Mt261Os9IIJIRiqlY2bq1f3A2P18MmV0e2rixVFQNN6SuUwf46ivpoPLzJX+iRQtxAfXt69+Rm/LTgYbgjjvK18/ZtEmOnQj14qPFvffKuwaLlUAOHhS5uT2z3yPUEDixe7dzVcsGDaS64QMPuDtObq50ehMnWuuaN/dGPjlunLTNYGITlamaWquWBDF37xajcf/9EszMz5c5lM1sZIBIUhs0KF+RtHXr8sHiTZvEmHg90Xp1wvzI1RAogezcKTMGVkGFXR2jOzFokARHp00r/1lgbR47334rHZ2RRxotv1015BWBHXGgWqmimFyChg2tp9aff5YciLfesozZJZeIiiOwc2/dWkZDBw5YweHNmzWHIBDz3WoegRJIu3ZWyW2P0RGBE6byqBPMUip6wgT/9YcPS32QPn2sdcFKUHvBunXAqFFW8NauVqoMzZrJiCAvTxLDmJ3nKgg2+5RTLkGNGokv+aso5oceacxIUSJADYEToQwBkdTimTLFf/3SpfI+dKi1rioNwb59MoOUSSp74w1/l1RF6dVLAtDjx0t84MABcV+kpVmG4PBhyV2wz8Jm6NJF3hcssNb9+CPwH8fpJ5KX0aPFyCa6FFKJa/S/L5ADB8QnF8wQABIwXbDAX0Zq5hgeNcpaF1jmwUtMfX/zBN66tSSRVZbnn5d4wPbt4h6qU0eMoD2pbMMGKdPtFDzv3VtKdESaQa0oiueoIQjEJJM1aRJ8m759JchnnyVs3jxRFK1aZense/eWwHIooxItjjxSniqNhPSZZ0JPNu8WIx012A2BSYpzMjgpKZI/YVRL06eLGivUXMaKosQENQSB1K0r7otQk5SbLFAzCgAkQaxFC9H+GlVNdrakwldkUvLKUqOGnD83V+Sqt90mnW9l+fhjqZa6dKkonQzvvw+8+qr8bYrYBRt5HDwoMlwzQc7MmeoLV5Q4RFVDgTRqBNx+e+htOnaUTt6eHzB6tEgs//QnyRPo3FlKPpis36qgdWvx1xuffSSqocOHrclr7EbR3umvWydur2Cur/R0KbKXnS1ta9CgahRUiqJUCDUEgezdK0He9u2DZ8AS+Vfu3L9fJJImqcokjN1yi7iPTIfqNd99J8Hc9etlOVLVECBp7sOGWevnz5fz3HmnGIJQcYiUFKmjM26c1B1S6aiixCXqGgrk/fflad7ECkLBLK9HH5XEscaNxSAYQ5CXV7VPwKYkRmAJ6spgpKJnnCHlLAzffSdlMwoLgSeflFcohgyRmMmcOVp+WlHiFDUEgZiCc+GeplesEKXOV19JrODoo8UV0r69vyGoCsWQ4bvvJMHLxCgiObcxBJ995p/ZaM8l6NUrfPnkPn2s6S2dqpEqihJz1BAEsnevyCUDC84F0ratpID/739STM0kkk2YICMEwJozuKrYtUvmTejYUYLGvXtX/lhmNPHee1aOBGAZguXLpbqpMZzBSEmRonsXXigjCUVR4g41BIHs2+dO7lmvnqhqxo+X3AOjJDrxRCuZqqpdQ2ZCmJ075Sm8Zs3KH4tI5iwA/IPdpmDcJ59INVKTyRyKxx+XaTW1xpCixCVqCAIJlVUcSN++VizBGIJt20ReWVAAPP20+MirCpNUNnGi5C9UdFrNQMy8AXZDYEYEc+fKu5ukNTUAihLXqCEI5I47pFSzG4w76NprrafxZctkefVqqSUeKh8h2jRvLq6YyZPlKTzSsgV33y3v9jyI1q2l9lDfvjI60KqZilLtUfloIKef7n7bk0+WSV5uucV66jUS0mXLZPrIzp2rrrJkjRrAMceI/z4aLqlRo8pPLpOaKlnMmzZFVsJCUZS4QUcEgXz7rfupFLOypCbPUUdZ64xE8uOPRSVjzz6uCpYtk9IO0TAETz4JzJ5dfv1zz4lCSQ2BoiQEagjsFBVJKek336z8MWrXllIPCxfKclWqhgxey1bffRfo2lUmrFEUpdqjhsCOCfxGWiSufXtgzx75u6pLKkyaJE/xXp63aVNRJLVt6905FEWpMtQQ2DGa+FCVR93w5ptSbA6o+hGBMWbjxnl3jq1bgSVLRBmlKEq1Rw2BnZ075T3SEUFWlgSPiapeVWMkpG5KZESKTqaiKAmBq18yEX1IRGcTUWL/8j//XKSSvXpFdpwNG6TQ3JNPisqmKjHF4t56y7tzTJsGTJ0qSXWKolR73HbsLwH4K4B1RPQYEXXxsE2x4557RO0Tac38nTslk7Zr1+i0qyKYEUFRkXfnaNkSuOAC746vKEqV4soQMPNMZr4MQDaAzQBmENH3RDSCiMIU5alGNG0q1TYjxeQSfPhh5MeqKB06yDSaOjewoiguce3qIaImAK4EcA2AnwA8CzEMMzxpWVXz0kuRTfZu58gj5f2116JzvIpy/PGR1RlSFCWpcBsjmArgfwDqADiXmQcz8/vMfBOA6j/3YFkZ8OCDwP/9X3SOZ7KMTz45OsdTFEXxELclJl5g5q+dPmDmnCi2JzbMnSv1c6JZIK64WFU1iqJUC9z2VF2JqKFZIKJGRPR3j9pU9UyeLGqhc86J3jHT0qpeMaQoilIJ3BqCa5l5v1lg5nwA13rTpCqmrAyYMgUYNChytZCiKEo1xK0hSCGyisoTUSqA9FA7EFFnIlpie/1KRLcSUWMimkFE63zvVVyDIYBdu6S08sUXx7QZiqIoscJtjOArAB8Q0csAGMDfAHwZagdmXgugJ/CH4fgFwEcAxgCYxcyPEdEY3/KdlWt+FGjeXOSWzDFrgqIoSixxOyK4E8DXAK4HcAOAWQBGV+A8AwFsYOYtAM4DMMm3fhKA8ytwnOjywQdWcTidRUtRlCTF1YiAmcsg2cUvVfI8QwG85/u7GTPv8B13BxE1reQxI2PRIplU/W9/A154ISZNUBRFiQfc5hF0JKIpRLSKiDaal8t90wEMBjC5Ig0jopFEtJCIFu4xT+3R4tAh4MorJZP4wQeje2xFUZRqhlvX0BuQ0UAJgP4A3gTgtqrZWQAWM/Mu3/IuImoOAL733U47MfMEZs5h5pzMzEyXp3LJ228DK1YA48dX/XwBiqIocYZbQ1CbmWcBIGbewsxjAQxwue+lsNxCAPApgOG+v4cD+MTlcaLH+vUyv+/ZZ1f5qRVFUeINt6qhg74S1OuI6EaIAiisb5+I6gA4DcB1ttWPQRRIVwPYCiCK6bwuycwEBg7UzF9FURTIE374jYiOA7AaQEMADwKoD+AJZp7vbfOEnJwcXmjmAFYURVFcQUSL3JQBCjsi8OUAXMzM/wDwO4ARUWifoiiKEieE9Y0wcymA3vbM4mpPr17A44/HuhWKoihxgdsYwU8APiGiyQAKzUpmnupJq7ykuFgmXtcZthRFUQC4NwSNAeyDv1KIAVQ/Q7DLp2Jt3jy27VAURYkT3GYWJ05cYMcOeVdDoCiKAsClISCiNyAjAD+Y+aqot8hr1BAoiqL44dY19Jnt71oALgCwPfrNqQIaNpQJaFq3jnVLFEVR4gK3rqEP7ctE9B6AmZ60yGtOPlnnElYURbFR2dTajgDaRLMhVYbOO6AoiuKH2xjBb/CPEexELCeTiYQLLwSKioCvvop1SxRFUeICt66hel43pMrYuhVo1izWrVAURYkb3M5HcAERNbAtNySi2M0sFgk7dqhiSFEUxYbbGMF9zFxgFph5P4D7vGmSh5SWSkKZGgJFUZQ/cGsInLZzKz2NH/bsAcrK1BAoiqLYcGsIFhLRU0TUgYjaE9HTABZ52TBPIAKuvx7Izo51SxRFUeIGt0/1NwG4B8D7vuXpAO72pEVe0qwZMG5crFuhKIoSV7hVDRUCGONxW7zn4EGZorJG9fNqKYqieIVb1dAMImpoW25ERNVPiP/kk0DNmsChQ7FuiaIoStzgNkaQ4VMKAQCYOR8u5iyOO3bsABo0EGOgKIqiAHBvCMqI6I+SEkTUDg7VSOOeHTuAFi1i3QpFUZS4wq2z/C4Ac4joO9/ynwGM9KZJHqLJZIqiKOVwNSJg5i8B5ABYC1EOjQJwwMN2eYMaAkVRlHK4LTp3DYBbALQCsARAHwDz4D91Zfxzww1Ap06xboWiKEpc4dY1dAuA4wDMZ+b+RNQFwP3eNcsj/vGPWLdAURQl7nAbLD7IzAcBgIhqMvMaAJ29a5YHFBUB27YBJSWxbomiKEpc4dYQ5PryCD4GMIOIPkF1m6py7lygTRvg++9j3RJFUZS4wm1m8QW+P8cS0TcAGgD40rNWeYFOWq8oiuJIhWstMPN34beKQ9QQKIqiOFLZOYurH/n5QHo6cMQRsW6JoihKXJE8hqCoCKhbN9atUBRFiTuSpwznRRcB3brFuhWKoihxR/IYgpNPlpeiKIriR/K4hjZsADZtinUrFEVR4o7kGRGMHCnzEMyZE+uWKIqixBXJMyIoLNRgsaIoigPJZQjq1Il1KxRFUeKO5DEEKh9VFEVxxFNDQEQNiWgKEa0hotVE1JeIxhLRL0S0xPca5GUb/kBdQ4qiKI54HSx+FsCXzPwXIkoHUAfAGQCeZuYnPT63P889B7RqVaWnVBRFqQ54ZgiIqD5kSssrAYCZiwEUE5FXpwzNxRfH5ryKoihxjpeuofYA9gB4g4h+IqJXicj4Zm4komVE9DoRNfKwDUJJCTB7tlV4TlEURfkDLw1BDQDZAF5i5l4ACgGMAfASgA4AegLYAeA/TjsT0UgiWkhEC/fs2RNZSwoKJKt48uTIjqMoipKAeGkIcgHkMvMC3/IUANnMvIuZS5m5DMArAI532pmZJzBzDjPnZGZmRtaSwkJ5V/mooihKOTwzBMy8E8A2IjJTWg4EsIqI7BMCXABghVdt+IOiInlX1ZCiKEo5vFYN3QTgHZ9iaCOAEQCeI6KeABjAZgDXedwGa0SghkBRFKUcnhoCZl4CICdg9RVentMRMyJQ15CiKEo5kiOzuGtX4KOPgB49Yt0SRVGUuCM5qo9mZADnnx/rViiKosQlyTEi2LIF+Pxz4MCBWLdEURQl7kgOQ/DFF8DZZ8sE9oqiKIofyWEIVD6qKIoSlOQwBCofVRRFCUpyGIKiIiA9HaiRHLFxRVGUipAchkDnIlAURQlKchiCm26SPAJFURSlHMnhK+nYUV6KoihKOZJjRPD118DMmbFuhaIoSlySHCOChx8GDh0CTj011i1RFEWJO5JjRFBYqAXnFEVRgpAchqCoSFVDiqIoQUgOQ6DyUUVRlKAkjyFQ15CiKIojyREsnjEDqFcv1q1QFEWJS5LDEHTvHusWKIqixC2J7xo6fBgYNw5YtizWLVEURYlLEt8Q/PYbcMMNwDffxLoliqIocUniGwKdi0BRFCUkiW8IdC4CRVGUkCSPIVD5qKIoiiOJbwjUNaQoihKSxJeP5uQAP/8MtGgR65YoiqLEJYlvCGrV0rkIFEVRQpD4rqFly4AnngAKCmLdEkVRlLgk8Q3BvHnA6NFW0FhRFEXxI/ENgcpHFUVRQpI8hkDlo4qiKI4kviEoKgLS0uSlKIqilCPxDYFOSqMoihKSxDcEjz4KrFkT61YoiqLELYmfR1C3ro4IFEVRQpD4I4I33gDGj491KxRFUeKWxDcEb78NvPVWrFuhKIoStyS+IdCJ6xVFUULiqSEgooZENIWI1hDRaiLqS0SNiWgGEa3zvTfysg0oKtIYgaIoSgi8HhE8C+BLZu4CoAeA1QDGAJjFzB0BzPIte4fKRxVFUULimSEgovoA/gzgNQBg5mJm3g/gPACTfJtNAnC+V20AICMCdQ0piqIExUv5aHsAewC8QUQ9ACwCcAuAZsy8AwCYeQcRNfWwDcDWrUBpqaenUBRFqc546RqqASAbwEvM3AtAISrgBiKikUS0kIgW7tmzp/KtSEuTOQkURVEUR7w0BLkAcpl5gW95CsQw7CKi5gDge9/ttDMzT2DmHGbOyczMrFwLiouBG24AZs2q3P6KoihJgGeGgJl3AthGRJ19qwYCWAXgUwDDfeuGA/jEqzbg99+BceOA5cs9O4WiKEp1x+sSEzcBeIeI0gFsBDACYnw+IKKrAWwFMMSzs+vE9YqiKGHx1BAw8xIAOQ4fDfTyvH+gk9IoiqKEJbEzi3VEoCiKEpbENgSHDgHp6WoIFEVRQpDYZaj79BFjwBzrliiKosQtiT0iMBDFugWKoihxS2IbgtmzgeHDgUgS0hRFURKcxDYEq1cDb74JHD4c65YoiqLELYltCIx8VIvOKYqiBCWxDYHKRxVFUcKS2IagsFCKzqWlxboliqIocUtiG4K0NKBFi1i3QlEUJa5JbEPwwAPA5s2xboWiKEpck9iGQFEURQmLGgJFUZQkRw2BoihKkqOGQFEUJclRQ6AoipLkqCFQFEVJctQQKIqiJDlqCBRFUZIcNQSKoihJDnE1mL2LiPYA2FKBXTIA7PWoOfFMMl53Ml4zkJzXnYzXDER23W2ZOTPcRtXCEFQUIlrIzDmxbkdVk4zXnYzXDCTndSfjNQNVc93qGlIURUly1BAoiqIkOYlqCCbEugExIhmvOxmvGUjO607Gawaq4LoTMkagKIqiuCdRRwSKoiiKSxLOEBDRmUS0lojWE9GYWLfHC4ioNRF9Q0SriWglEd3iW9+YiGYQ0Trfe6NYtzXaEFEqEf1ERJ/5lrOIaIHvmt8novRYtzHaEFFDIppCRGt897xvot9rIrrN97+9gojeI6JaiXivieh1ItpNRCts6xzvLQnP+fq2ZUSUHa12JJQhIKJUAC8COAvA0QAuJaKjY9sqTygBMIqZuwLoA+AG33WOATCLmTsCmOVbTjRuAbDatvw4gKd915wP4OqYtMpbngXwJTN3AdADcv0Je6+JqCWAmwHkMHM3AKkAhiIx7/VEAGcGrAt2b88C0NH3GgngpWg1IqEMAYDjAaxn5o3MXAzgvwDOi3Gbog4z72Dmxb6/f4N0DC0h1zrJt9kkAOfHpoXeQEStAJwN4FXfMgEYAGCKb5NEvOb6AP4M4DUAYOZiZt6PBL/XAGoAqE1ENQDUAbADCXivmXk2gLyA1cHu7XkA3mRhPoCGRNQ8Gu1INEPQEsA223Kub13CQkTtAPQCsABAM2beAYixANA0di3zhGcAjAZQ5ltuAmA/M5f4lhPxfrcHsAfAGz6X2KtEVBcJfK+Z+RcATwLYCjEABQAWIfHvtSHYvfWsf0s0Q0AO6xJWFkVERwD4EMCtzPxrrNvjJUR0DoDdzLzIvtph00S73zUAZAN4iZl7AShEArmBnPD5xM8DkAWgBYC6ELdIIIl2r8Ph2f97ohmCXACtbcutAGyPUVs8hYjSIEbgHWae6lu9ywwVfe+7Y9U+D/gTgMFEtBni8hsAGSE09LkPgMS837kAcpl5gW95CsQwJPK9PhXAJmbew8yHAUwFcCIS/14bgt1bz/q3RDMEPwLo6FMXpEMCTJ/GuE1Rx+cbfw3AamZ+yvbRpwCG+/4eDuCTqm6bVzDzP5m5FTO3g9zXr5n5MgDfAPiLb7OEumYAYOadALYRUWffqoEAViGB7zXEJdSHiOr4/tfNNSf0vbYR7N5+CmCYTz3UB0CBcSFFDDMn1AvAIAA/A9gA4K5Yt8ejazwJMiRcBmCJ7zUI4jOfBWCd771xrNvq0fWfAuAz39/tAfwAYD2AyQBqxrp9HlxvTwALfff7YwCNEv1eA7gfwBoAKwC8BaBmIt5rAO9B4iCHIU/8Vwe7txDX0Iu+vm05RFUVlXZoZrGiKEqSk2iuIUVRFKWCqCFQFEVJctQQKIqiJDlqCBRFUZIcNQSKoihJjhoCJakgou997+2I6K9RPva/nM6lKPGOykeVpISITgFwBzOfU4F9Upm5NMTnvzPzEdFon6JUJToiUJIKIvrd9+djAPoR0RJf7ftUInqCiH701Xq/zrf9Kb65H96FJPGAiD4mokW+evkjfeseg1TLXEJE79jP5csEfcJXW385EV1iO/a3trkG3vFl0ipKlVIj/CaKkpCMgW1E4OvQC5j5OCKqCWAuEU33bXs8gG7MvMm3fBUz5xFRbQA/EtGHzDyGiG5k5p4O57oQkh3cA0CGb5/Zvs96ATgGUjNmLqSm0pzoX66iBEdHBIoinA6p47IEUtK7CWQCEAD4wWYEAOBmIloKYD6kCFhHhOYkAO8xcykz7wLwHYDjbMfOZeYySKmQdlG5GkWpADoiUBSBANzEzF/5rZRYQmHA8qkA+jJzERF9C6CWi2MH45Dt71Lob1KJAToiUJKV3wDUsy1/BeB6X3lvEFEn3wQwgTQAkO8zAl0gU4UaDpv9A5gN4BJfHCITMuPYD1G5CkWJAvr0oSQrywCU+Fw8EyHzArcDsNgXsN0D56kQvwTwNyJaBmAtxD1kmABgGREtZimRbfgIQF8ASyFVY0cz806fIVGUmKPyUUVRlCRHXUOKoihJjhoCRVGUJEcNgaIoSpKjhkBRFCXJUUOgKIqS5KghUBRFSXLUECiKoiQ5aggURVGSnP8HOCqc0SqpFVQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path = '../datum_for_plotting/run_num_12/tf_ALL_CNN_C_step2_class1'\n",
    "f =open(save_path + '/array_epoch_acc.save' , 'rb')\n",
    "acc_array = cPickle.load(f )\n",
    "f.close()\n",
    "a = np.concatenate(acc_array)\n",
    "length = a.shape[0]\n",
    "a /= 100\n",
    "acc_axis_test = np.array(np.linspace(1,length, num=length))\n",
    "plt.plot(acc_axis_test, a.reshape(-1,1), '--r', label='Test')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig(save_path + '/validation_accuracy' + str(max_epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "tf_all_cnn_c_step1_class2 = ALL_CNN_C(num_classes=10)\n",
    "tf_params_class2 = copy.deepcopy(orig_all_cnn_c.state_dict())\n",
    "tf_all_cnn_c_step1_class2.load_state_dict(tf_params_class2)\n",
    "\n",
    "tf_all_cnn_c_step1_class2.conv9 = nn.Conv2d(192, 10 ,kernel_size=1)\n",
    "nn.init.kaiming_normal_(tf_all_cnn_c_step1_class2.conv9.weight)\n",
    "nn.init.constant_(tf_all_cnn_c_step1_class2.conv9.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft_class2 = optim.SGD(tf_all_cnn_c_step1_class2.conv9.parameters(),\n",
    "                         lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n",
      "begin training\n",
      "Checking accuracy on test set\n",
      "Got 274 / 1000 correct (27.40)\n",
      "1 epoch,   500 iteration, loss:2.207\n",
      "Checking accuracy on test set\n",
      "Got 296 / 1000 correct (29.60)\n",
      "1 epoch,  1000 iteration, loss:2.060\n",
      " num 0 epoch \n",
      "####### Training Loss #######\n",
      "[2.10762772]\n",
      "Checking accuracy on test set\n",
      "Got 324 / 1000 correct (32.40)\n",
      "2 epoch,   500 iteration, loss:1.948\n",
      "Checking accuracy on test set\n",
      "Got 322 / 1000 correct (32.20)\n",
      "2 epoch,  1000 iteration, loss:1.898\n",
      " num 1 epoch \n",
      "####### Training Loss #######\n",
      "[1.91534363]\n",
      "Checking accuracy on test set\n",
      "Got 333 / 1000 correct (33.30)\n",
      "3 epoch,   500 iteration, loss:1.875\n",
      "Checking accuracy on test set\n",
      "Got 336 / 1000 correct (33.60)\n",
      "3 epoch,  1000 iteration, loss:1.860\n",
      " num 2 epoch \n",
      "####### Training Loss #######\n",
      "[1.86264899]\n",
      "Checking accuracy on test set\n",
      "Got 334 / 1000 correct (33.40)\n",
      "4 epoch,   500 iteration, loss:1.852\n",
      "Checking accuracy on test set\n",
      "Got 349 / 1000 correct (34.90)\n",
      "4 epoch,  1000 iteration, loss:1.833\n",
      " num 3 epoch \n",
      "####### Training Loss #######\n",
      "[1.842772]\n",
      "Checking accuracy on test set\n",
      "Got 345 / 1000 correct (34.50)\n",
      "5 epoch,   500 iteration, loss:1.846\n",
      "Checking accuracy on test set\n",
      "Got 348 / 1000 correct (34.80)\n",
      "5 epoch,  1000 iteration, loss:1.812\n",
      " num 4 epoch \n",
      "####### Training Loss #######\n",
      "[1.83159182]\n",
      "Checking accuracy on test set\n",
      "Got 337 / 1000 correct (33.70)\n",
      "6 epoch,   500 iteration, loss:1.844\n",
      "Checking accuracy on test set\n",
      "Got 356 / 1000 correct (35.60)\n",
      "6 epoch,  1000 iteration, loss:1.805\n",
      " num 5 epoch \n",
      "####### Training Loss #######\n",
      "[1.82526703]\n",
      "Checking accuracy on test set\n",
      "Got 338 / 1000 correct (33.80)\n",
      "7 epoch,   500 iteration, loss:1.823\n",
      "Checking accuracy on test set\n",
      "Got 361 / 1000 correct (36.10)\n",
      "7 epoch,  1000 iteration, loss:1.816\n",
      " num 6 epoch \n",
      "####### Training Loss #######\n",
      "[1.81874075]\n",
      "Checking accuracy on test set\n",
      "Got 350 / 1000 correct (35.00)\n",
      "8 epoch,   500 iteration, loss:1.816\n",
      "Checking accuracy on test set\n",
      "Got 357 / 1000 correct (35.70)\n",
      "8 epoch,  1000 iteration, loss:1.814\n",
      " num 7 epoch \n",
      "####### Training Loss #######\n",
      "[1.81510532]\n",
      "Checking accuracy on test set\n",
      "Got 347 / 1000 correct (34.70)\n",
      "9 epoch,   500 iteration, loss:1.817\n",
      "Checking accuracy on test set\n",
      "Got 360 / 1000 correct (36.00)\n",
      "9 epoch,  1000 iteration, loss:1.820\n",
      " num 8 epoch \n",
      "####### Training Loss #######\n",
      "[1.8186525]\n",
      "Checking accuracy on test set\n",
      "Got 350 / 1000 correct (35.00)\n",
      "10 epoch,   500 iteration, loss:1.820\n",
      "Checking accuracy on test set\n",
      "Got 357 / 1000 correct (35.70)\n",
      "10 epoch,  1000 iteration, loss:1.816\n",
      " num 9 epoch \n",
      "####### Training Loss #######\n",
      "[1.81635825]\n",
      "Checking accuracy on test set\n",
      "Got 359 / 1000 correct (35.90)\n",
      "11 epoch,   500 iteration, loss:1.812\n",
      "Checking accuracy on test set\n",
      "Got 356 / 1000 correct (35.60)\n",
      "11 epoch,  1000 iteration, loss:1.810\n",
      " num 10 epoch \n",
      "####### Training Loss #######\n",
      "[1.81237053]\n",
      "Checking accuracy on test set\n",
      "Got 360 / 1000 correct (36.00)\n",
      "12 epoch,   500 iteration, loss:1.806\n",
      "Checking accuracy on test set\n",
      "Got 368 / 1000 correct (36.80)\n",
      "12 epoch,  1000 iteration, loss:1.799\n",
      " num 11 epoch \n",
      "####### Training Loss #######\n",
      "[1.80796129]\n",
      "Checking accuracy on test set\n",
      "Got 358 / 1000 correct (35.80)\n",
      "13 epoch,   500 iteration, loss:1.813\n",
      "Checking accuracy on test set\n",
      "Got 362 / 1000 correct (36.20)\n",
      "13 epoch,  1000 iteration, loss:1.799\n",
      " num 12 epoch \n",
      "####### Training Loss #######\n",
      "[1.80711299]\n",
      "Checking accuracy on test set\n",
      "Got 349 / 1000 correct (34.90)\n",
      "14 epoch,   500 iteration, loss:1.815\n",
      "Checking accuracy on test set\n",
      "Got 367 / 1000 correct (36.70)\n",
      "14 epoch,  1000 iteration, loss:1.794\n",
      " num 13 epoch \n",
      "####### Training Loss #######\n",
      "[1.80565483]\n",
      "Checking accuracy on test set\n",
      "Got 352 / 1000 correct (35.20)\n",
      "15 epoch,   500 iteration, loss:1.810\n",
      "Checking accuracy on test set\n",
      "Got 362 / 1000 correct (36.20)\n",
      "15 epoch,  1000 iteration, loss:1.806\n",
      " num 14 epoch \n",
      "####### Training Loss #######\n",
      "[1.81021966]\n",
      "Checking accuracy on test set\n",
      "Got 355 / 1000 correct (35.50)\n",
      "16 epoch,   500 iteration, loss:1.810\n",
      "Checking accuracy on test set\n",
      "Got 357 / 1000 correct (35.70)\n",
      "16 epoch,  1000 iteration, loss:1.791\n",
      " num 15 epoch \n",
      "####### Training Loss #######\n",
      "[1.80346611]\n",
      "Checking accuracy on test set\n",
      "Got 363 / 1000 correct (36.30)\n",
      "17 epoch,   500 iteration, loss:1.801\n",
      "Checking accuracy on test set\n",
      "Got 366 / 1000 correct (36.60)\n",
      "17 epoch,  1000 iteration, loss:1.787\n",
      " num 16 epoch \n",
      "####### Training Loss #######\n",
      "[1.79687572]\n",
      "Checking accuracy on test set\n",
      "Got 361 / 1000 correct (36.10)\n",
      "18 epoch,   500 iteration, loss:1.797\n",
      "Checking accuracy on test set\n",
      "Got 368 / 1000 correct (36.80)\n",
      "18 epoch,  1000 iteration, loss:1.778\n",
      " num 17 epoch \n",
      "####### Training Loss #######\n",
      "[1.79411947]\n",
      "Checking accuracy on test set\n",
      "Got 372 / 1000 correct (37.20)\n",
      "19 epoch,   500 iteration, loss:1.811\n",
      "Checking accuracy on test set\n",
      "Got 364 / 1000 correct (36.40)\n",
      "19 epoch,  1000 iteration, loss:1.796\n",
      " num 18 epoch \n",
      "####### Training Loss #######\n",
      "[1.80297319]\n",
      "Checking accuracy on test set\n",
      "Got 357 / 1000 correct (35.70)\n",
      "20 epoch,   500 iteration, loss:1.814\n",
      "Checking accuracy on test set\n",
      "Got 368 / 1000 correct (36.80)\n",
      "20 epoch,  1000 iteration, loss:1.781\n",
      " num 19 epoch \n",
      "####### Training Loss #######\n",
      "[1.79800989]\n",
      "Checking accuracy on test set\n",
      "Got 371 / 1000 correct (37.10)\n",
      "21 epoch,   500 iteration, loss:1.798\n",
      "Checking accuracy on test set\n",
      "Got 372 / 1000 correct (37.20)\n",
      "21 epoch,  1000 iteration, loss:1.769\n",
      " num 20 epoch \n",
      "####### Training Loss #######\n",
      "[1.7847774]\n",
      "Checking accuracy on test set\n",
      "Got 368 / 1000 correct (36.80)\n",
      "22 epoch,   500 iteration, loss:1.796\n",
      "Checking accuracy on test set\n",
      "Got 364 / 1000 correct (36.40)\n",
      "22 epoch,  1000 iteration, loss:1.780\n",
      " num 21 epoch \n",
      "####### Training Loss #######\n",
      "[1.78899014]\n",
      "Checking accuracy on test set\n",
      "Got 357 / 1000 correct (35.70)\n",
      "23 epoch,   500 iteration, loss:1.816\n",
      "Checking accuracy on test set\n",
      "Got 365 / 1000 correct (36.50)\n",
      "23 epoch,  1000 iteration, loss:1.793\n",
      " num 22 epoch \n",
      "####### Training Loss #######\n",
      "[1.803643]\n",
      "Checking accuracy on test set\n",
      "Got 366 / 1000 correct (36.60)\n",
      "24 epoch,   500 iteration, loss:1.786\n",
      "Checking accuracy on test set\n",
      "Got 374 / 1000 correct (37.40)\n",
      "24 epoch,  1000 iteration, loss:1.781\n",
      " num 23 epoch \n",
      "####### Training Loss #######\n",
      "[1.78875956]\n",
      "Checking accuracy on test set\n",
      "Got 359 / 1000 correct (35.90)\n",
      "25 epoch,   500 iteration, loss:1.799\n",
      "Checking accuracy on test set\n",
      "Got 371 / 1000 correct (37.10)\n",
      "25 epoch,  1000 iteration, loss:1.779\n",
      " num 24 epoch \n",
      "####### Training Loss #######\n",
      "[1.79365129]\n",
      "Checking accuracy on test set\n",
      "Got 359 / 1000 correct (35.90)\n",
      "26 epoch,   500 iteration, loss:1.787\n",
      "Checking accuracy on test set\n",
      "Got 370 / 1000 correct (37.00)\n",
      "26 epoch,  1000 iteration, loss:1.787\n",
      " num 25 epoch \n",
      "####### Training Loss #######\n",
      "[1.79154652]\n",
      "Checking accuracy on test set\n",
      "Got 365 / 1000 correct (36.50)\n",
      "27 epoch,   500 iteration, loss:1.791\n",
      "Checking accuracy on test set\n",
      "Got 365 / 1000 correct (36.50)\n",
      "27 epoch,  1000 iteration, loss:1.757\n",
      " num 26 epoch \n",
      "####### Training Loss #######\n",
      "[1.77821141]\n",
      "Checking accuracy on test set\n",
      "Got 366 / 1000 correct (36.60)\n",
      "28 epoch,   500 iteration, loss:1.784\n",
      "Checking accuracy on test set\n",
      "Got 369 / 1000 correct (36.90)\n",
      "28 epoch,  1000 iteration, loss:1.777\n",
      " num 27 epoch \n",
      "####### Training Loss #######\n",
      "[1.77872796]\n",
      "Checking accuracy on test set\n",
      "Got 368 / 1000 correct (36.80)\n",
      "29 epoch,   500 iteration, loss:1.779\n",
      "Checking accuracy on test set\n",
      "Got 380 / 1000 correct (38.00)\n",
      "29 epoch,  1000 iteration, loss:1.771\n",
      " num 28 epoch \n",
      "####### Training Loss #######\n",
      "[1.77889096]\n",
      "Checking accuracy on test set\n",
      "Got 370 / 1000 correct (37.00)\n",
      "30 epoch,   500 iteration, loss:1.776\n",
      "Checking accuracy on test set\n",
      "Got 377 / 1000 correct (37.70)\n",
      "30 epoch,  1000 iteration, loss:1.783\n",
      " num 29 epoch \n",
      "####### Training Loss #######\n",
      "[1.78086462]\n",
      "Checking accuracy on test set\n",
      "Got 369 / 1000 correct (36.90)\n",
      "31 epoch,   500 iteration, loss:1.785\n",
      "Checking accuracy on test set\n",
      "Got 362 / 1000 correct (36.20)\n",
      "31 epoch,  1000 iteration, loss:1.766\n",
      " num 30 epoch \n",
      "####### Training Loss #######\n",
      "[1.77567398]\n",
      "Checking accuracy on test set\n",
      "Got 374 / 1000 correct (37.40)\n",
      "32 epoch,   500 iteration, loss:1.779\n",
      "Checking accuracy on test set\n",
      "Got 382 / 1000 correct (38.20)\n",
      "32 epoch,  1000 iteration, loss:1.769\n",
      " num 31 epoch \n",
      "####### Training Loss #######\n",
      "[1.77805924]\n",
      "Checking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 369 / 1000 correct (36.90)\n",
      "33 epoch,   500 iteration, loss:1.773\n",
      "Checking accuracy on test set\n",
      "Got 377 / 1000 correct (37.70)\n",
      "33 epoch,  1000 iteration, loss:1.773\n",
      " num 32 epoch \n",
      "####### Training Loss #######\n",
      "[1.78118909]\n",
      "Checking accuracy on test set\n",
      "Got 374 / 1000 correct (37.40)\n",
      "34 epoch,   500 iteration, loss:1.793\n",
      "Checking accuracy on test set\n",
      "Got 386 / 1000 correct (38.60)\n",
      "34 epoch,  1000 iteration, loss:1.771\n",
      " num 33 epoch \n",
      "####### Training Loss #######\n",
      "[1.78336965]\n",
      "Checking accuracy on test set\n",
      "Got 364 / 1000 correct (36.40)\n",
      "35 epoch,   500 iteration, loss:1.787\n",
      "Checking accuracy on test set\n",
      "Got 379 / 1000 correct (37.90)\n",
      "35 epoch,  1000 iteration, loss:1.765\n",
      " num 34 epoch \n",
      "####### Training Loss #######\n",
      "[1.77435395]\n",
      "Checking accuracy on test set\n",
      "Got 368 / 1000 correct (36.80)\n",
      "36 epoch,   500 iteration, loss:1.782\n",
      "Checking accuracy on test set\n",
      "Got 374 / 1000 correct (37.40)\n",
      "36 epoch,  1000 iteration, loss:1.770\n",
      " num 35 epoch \n",
      "####### Training Loss #######\n",
      "[1.78025115]\n",
      "Checking accuracy on test set\n",
      "Got 369 / 1000 correct (36.90)\n",
      "37 epoch,   500 iteration, loss:1.770\n",
      "Checking accuracy on test set\n",
      "Got 377 / 1000 correct (37.70)\n",
      "37 epoch,  1000 iteration, loss:1.769\n",
      " num 36 epoch \n",
      "####### Training Loss #######\n",
      "[1.77433741]\n",
      "Checking accuracy on test set\n",
      "Got 371 / 1000 correct (37.10)\n",
      "38 epoch,   500 iteration, loss:1.792\n",
      "Checking accuracy on test set\n",
      "Got 380 / 1000 correct (38.00)\n",
      "38 epoch,  1000 iteration, loss:1.766\n",
      " num 37 epoch \n",
      "####### Training Loss #######\n",
      "[1.77983935]\n",
      "Checking accuracy on test set\n",
      "Got 374 / 1000 correct (37.40)\n",
      "39 epoch,   500 iteration, loss:1.789\n",
      "Checking accuracy on test set\n",
      "Got 386 / 1000 correct (38.60)\n",
      "39 epoch,  1000 iteration, loss:1.763\n",
      " num 38 epoch \n",
      "####### Training Loss #######\n",
      "[1.77651293]\n",
      "Checking accuracy on test set\n",
      "Got 368 / 1000 correct (36.80)\n",
      "40 epoch,   500 iteration, loss:1.783\n",
      "Checking accuracy on test set\n",
      "Got 383 / 1000 correct (38.30)\n",
      "40 epoch,  1000 iteration, loss:1.766\n",
      " num 39 epoch \n",
      "####### Training Loss #######\n",
      "[1.76975304]\n",
      "Checking accuracy on test set\n",
      "Got 371 / 1000 correct (37.10)\n",
      "41 epoch,   500 iteration, loss:1.778\n",
      "Checking accuracy on test set\n",
      "Got 375 / 1000 correct (37.50)\n",
      "41 epoch,  1000 iteration, loss:1.766\n",
      " num 40 epoch \n",
      "####### Training Loss #######\n",
      "[1.76962149]\n",
      "Checking accuracy on test set\n",
      "Got 377 / 1000 correct (37.70)\n",
      "42 epoch,   500 iteration, loss:1.779\n",
      "Checking accuracy on test set\n",
      "Got 378 / 1000 correct (37.80)\n",
      "42 epoch,  1000 iteration, loss:1.751\n",
      " num 41 epoch \n",
      "####### Training Loss #######\n",
      "[1.76870419]\n",
      "Checking accuracy on test set\n",
      "Got 371 / 1000 correct (37.10)\n",
      "43 epoch,   500 iteration, loss:1.792\n",
      "Checking accuracy on test set\n",
      "Got 384 / 1000 correct (38.40)\n",
      "43 epoch,  1000 iteration, loss:1.743\n",
      " num 42 epoch \n",
      "####### Training Loss #######\n",
      "[1.77025443]\n",
      "Checking accuracy on test set\n",
      "Got 377 / 1000 correct (37.70)\n",
      "44 epoch,   500 iteration, loss:1.778\n",
      "Checking accuracy on test set\n",
      "Got 380 / 1000 correct (38.00)\n",
      "44 epoch,  1000 iteration, loss:1.761\n",
      " num 43 epoch \n",
      "####### Training Loss #######\n",
      "[1.77209617]\n",
      "Checking accuracy on test set\n",
      "Got 364 / 1000 correct (36.40)\n",
      "45 epoch,   500 iteration, loss:1.770\n",
      "Checking accuracy on test set\n",
      "Got 391 / 1000 correct (39.10)\n",
      "45 epoch,  1000 iteration, loss:1.771\n",
      " num 44 epoch \n",
      "####### Training Loss #######\n",
      "[1.77437736]\n",
      "Checking accuracy on test set\n",
      "Got 369 / 1000 correct (36.90)\n",
      "46 epoch,   500 iteration, loss:1.790\n",
      "Checking accuracy on test set\n",
      "Got 386 / 1000 correct (38.60)\n",
      "46 epoch,  1000 iteration, loss:1.760\n",
      " num 45 epoch \n",
      "####### Training Loss #######\n",
      "[1.77359979]\n",
      "Checking accuracy on test set\n",
      "Got 371 / 1000 correct (37.10)\n",
      "47 epoch,   500 iteration, loss:1.772\n",
      "Checking accuracy on test set\n",
      "Got 376 / 1000 correct (37.60)\n",
      "47 epoch,  1000 iteration, loss:1.763\n",
      " num 46 epoch \n",
      "####### Training Loss #######\n",
      "[1.77014448]\n",
      "Checking accuracy on test set\n",
      "Got 381 / 1000 correct (38.10)\n",
      "48 epoch,   500 iteration, loss:1.789\n",
      "Checking accuracy on test set\n",
      "Got 390 / 1000 correct (39.00)\n",
      "48 epoch,  1000 iteration, loss:1.760\n",
      " num 47 epoch \n",
      "####### Training Loss #######\n",
      "[1.77682868]\n",
      "Checking accuracy on test set\n",
      "Got 372 / 1000 correct (37.20)\n",
      "49 epoch,   500 iteration, loss:1.772\n",
      "Checking accuracy on test set\n",
      "Got 387 / 1000 correct (38.70)\n",
      "49 epoch,  1000 iteration, loss:1.753\n",
      " num 48 epoch \n",
      "####### Training Loss #######\n",
      "[1.76362996]\n",
      "Checking accuracy on test set\n",
      "Got 382 / 1000 correct (38.20)\n",
      "50 epoch,   500 iteration, loss:1.759\n",
      "Checking accuracy on test set\n",
      "Got 391 / 1000 correct (39.10)\n",
      "50 epoch,  1000 iteration, loss:1.765\n",
      " num 49 epoch \n",
      "####### Training Loss #######\n",
      "[1.75932857]\n",
      "finish training \n",
      "\n",
      "now begin saving datum for next step plotting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Anacondas/anaconda3/envs/cs231n/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type ALL_CNN_C. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now plotting accuracies and losses\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_num = 10\n",
    "net_name = 'tf_ALL_CNN_C_step1_class2'\n",
    "lr = [0.01, 0.005, 0.001, 0.0005]\n",
    "epoch = [35, 40, 45]\n",
    "tf_all_cnn_c_step1_class2 = running_model_tf_step1(run_num, tf_all_cnn_c_step1_class2, net_name, lr, epoch,\n",
    "                                    loaderB_train, loaderB_test, optimizer_ft_class2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path = '../datum_for_plotting/run_num_10/tf_ALL_CNN_C_step1_class2'\n",
    "f =open(save_path + '/array_epoch_acc.save' , 'rb')\n",
    "acc_array = cPickle.load(f )\n",
    "f.close()\n",
    "a = np.concatenate(acc_array)\n",
    "length = a.shape[0]\n",
    "a /= 100\n",
    "acc_axis_test = np.array(np.linspace(1,length, num=length))\n",
    "plt.plot(acc_axis_test, a.reshape(-1,1), '--r', label='Test')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig(save_path + '/validation_accuracy' + str(max_epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n",
      "begin training\n",
      "Checking accuracy on test set\n",
      "Got 554 / 1000 correct (55.40)\n",
      "1 epoch,   500 iteration, loss:1.483\n",
      "Checking accuracy on test set\n",
      "Got 587 / 1000 correct (58.70)\n",
      "1 epoch,  1000 iteration, loss:1.237\n",
      " num 0 epoch \n",
      "####### Training Loss #######\n",
      "[1.31161387]\n",
      "Checking accuracy on test set\n",
      "Got 624 / 1000 correct (62.40)\n",
      "2 epoch,   500 iteration, loss:1.025\n",
      "Checking accuracy on test set\n",
      "Got 646 / 1000 correct (64.60)\n",
      "2 epoch,  1000 iteration, loss:0.928\n",
      " num 1 epoch \n",
      "####### Training Loss #######\n",
      "[0.95516873]\n",
      "Checking accuracy on test set\n",
      "Got 675 / 1000 correct (67.50)\n",
      "3 epoch,   500 iteration, loss:0.872\n",
      "Checking accuracy on test set\n",
      "Got 672 / 1000 correct (67.20)\n",
      "3 epoch,  1000 iteration, loss:0.782\n",
      " num 2 epoch \n",
      "####### Training Loss #######\n",
      "[0.81577081]\n",
      "Checking accuracy on test set\n",
      "Got 688 / 1000 correct (68.80)\n",
      "4 epoch,   500 iteration, loss:0.737\n",
      "Checking accuracy on test set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "4 epoch,  1000 iteration, loss:0.667\n",
      " num 3 epoch \n",
      "####### Training Loss #######\n",
      "[0.68867512]\n",
      "Checking accuracy on test set\n",
      "Got 650 / 1000 correct (65.00)\n",
      "5 epoch,   500 iteration, loss:0.651\n",
      "Checking accuracy on test set\n",
      "Got 713 / 1000 correct (71.30)\n",
      "5 epoch,  1000 iteration, loss:0.586\n",
      " num 4 epoch \n",
      "####### Training Loss #######\n",
      "[0.61475387]\n",
      "Checking accuracy on test set\n",
      "Got 706 / 1000 correct (70.60)\n",
      "6 epoch,   500 iteration, loss:0.562\n",
      "Checking accuracy on test set\n",
      "Got 717 / 1000 correct (71.70)\n",
      "6 epoch,  1000 iteration, loss:0.499\n",
      " num 5 epoch \n",
      "####### Training Loss #######\n",
      "[0.52419829]\n",
      "Checking accuracy on test set\n",
      "Got 710 / 1000 correct (71.00)\n",
      "7 epoch,   500 iteration, loss:0.505\n",
      "Checking accuracy on test set\n",
      "Got 701 / 1000 correct (70.10)\n",
      "7 epoch,  1000 iteration, loss:0.451\n",
      " num 6 epoch \n",
      "####### Training Loss #######\n",
      "[0.4763113]\n",
      "Checking accuracy on test set\n",
      "Got 706 / 1000 correct (70.60)\n",
      "8 epoch,   500 iteration, loss:0.469\n",
      "Checking accuracy on test set\n",
      "Got 716 / 1000 correct (71.60)\n",
      "8 epoch,  1000 iteration, loss:0.401\n",
      " num 7 epoch \n",
      "####### Training Loss #######\n",
      "[0.43317723]\n",
      "Checking accuracy on test set\n",
      "Got 706 / 1000 correct (70.60)\n",
      "9 epoch,   500 iteration, loss:0.385\n",
      "Checking accuracy on test set\n",
      "Got 718 / 1000 correct (71.80)\n",
      "9 epoch,  1000 iteration, loss:0.377\n",
      " num 8 epoch \n",
      "####### Training Loss #######\n",
      "[0.38780895]\n",
      "Checking accuracy on test set\n",
      "Got 721 / 1000 correct (72.10)\n",
      "10 epoch,   500 iteration, loss:0.341\n",
      "Checking accuracy on test set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "10 epoch,  1000 iteration, loss:0.332\n",
      " num 9 epoch \n",
      "####### Training Loss #######\n",
      "[0.33836799]\n",
      "Checking accuracy on test set\n",
      "Got 688 / 1000 correct (68.80)\n",
      "11 epoch,   500 iteration, loss:0.332\n",
      "Checking accuracy on test set\n",
      "Got 713 / 1000 correct (71.30)\n",
      "11 epoch,  1000 iteration, loss:0.295\n",
      " num 10 epoch \n",
      "####### Training Loss #######\n",
      "[0.31505352]\n",
      "Checking accuracy on test set\n",
      "Got 721 / 1000 correct (72.10)\n",
      "12 epoch,   500 iteration, loss:0.312\n",
      "Checking accuracy on test set\n",
      "Got 704 / 1000 correct (70.40)\n",
      "12 epoch,  1000 iteration, loss:0.244\n",
      " num 11 epoch \n",
      "####### Training Loss #######\n",
      "[0.28074345]\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "13 epoch,   500 iteration, loss:0.283\n",
      "Checking accuracy on test set\n",
      "Got 725 / 1000 correct (72.50)\n",
      "13 epoch,  1000 iteration, loss:0.239\n",
      " num 12 epoch \n",
      "####### Training Loss #######\n",
      "[0.26048946]\n",
      "Checking accuracy on test set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "14 epoch,   500 iteration, loss:0.243\n",
      "Checking accuracy on test set\n",
      "Got 696 / 1000 correct (69.60)\n",
      "14 epoch,  1000 iteration, loss:0.229\n",
      " num 13 epoch \n",
      "####### Training Loss #######\n",
      "[0.23593301]\n",
      "Checking accuracy on test set\n",
      "Got 721 / 1000 correct (72.10)\n",
      "15 epoch,   500 iteration, loss:0.239\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "15 epoch,  1000 iteration, loss:0.206\n",
      " num 14 epoch \n",
      "####### Training Loss #######\n",
      "[0.21772871]\n",
      "Checking accuracy on test set\n",
      "Got 718 / 1000 correct (71.80)\n",
      "16 epoch,   500 iteration, loss:0.212\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "16 epoch,  1000 iteration, loss:0.189\n",
      " num 15 epoch \n",
      "####### Training Loss #######\n",
      "[0.21311628]\n",
      "Checking accuracy on test set\n",
      "Got 692 / 1000 correct (69.20)\n",
      "17 epoch,   500 iteration, loss:0.199\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "17 epoch,  1000 iteration, loss:0.152\n",
      " num 16 epoch \n",
      "####### Training Loss #######\n",
      "[0.18086586]\n",
      "Checking accuracy on test set\n",
      "Got 712 / 1000 correct (71.20)\n",
      "18 epoch,   500 iteration, loss:0.212\n",
      "Checking accuracy on test set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "18 epoch,  1000 iteration, loss:0.158\n",
      " num 17 epoch \n",
      "####### Training Loss #######\n",
      "[0.17745993]\n",
      "Checking accuracy on test set\n",
      "Got 692 / 1000 correct (69.20)\n",
      "19 epoch,   500 iteration, loss:0.186\n",
      "Checking accuracy on test set\n",
      "Got 759 / 1000 correct (75.90)\n",
      "19 epoch,  1000 iteration, loss:0.163\n",
      " num 18 epoch \n",
      "####### Training Loss #######\n",
      "[0.17437934]\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "20 epoch,   500 iteration, loss:0.153\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "20 epoch,  1000 iteration, loss:0.160\n",
      " num 19 epoch \n",
      "####### Training Loss #######\n",
      "[0.15495438]\n",
      "Checking accuracy on test set\n",
      "Got 734 / 1000 correct (73.40)\n",
      "21 epoch,   500 iteration, loss:0.171\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "21 epoch,  1000 iteration, loss:0.120\n",
      " num 20 epoch \n",
      "####### Training Loss #######\n",
      "[0.14834482]\n",
      "Checking accuracy on test set\n",
      "Got 715 / 1000 correct (71.50)\n",
      "22 epoch,   500 iteration, loss:0.133\n",
      "Checking accuracy on test set\n",
      "Got 732 / 1000 correct (73.20)\n",
      "22 epoch,  1000 iteration, loss:0.142\n",
      " num 21 epoch \n",
      "####### Training Loss #######\n",
      "[0.13270285]\n",
      "Checking accuracy on test set\n",
      "Got 726 / 1000 correct (72.60)\n",
      "23 epoch,   500 iteration, loss:0.146\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "23 epoch,  1000 iteration, loss:0.114\n",
      " num 22 epoch \n",
      "####### Training Loss #######\n",
      "[0.13610531]\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "24 epoch,   500 iteration, loss:0.133\n",
      "Checking accuracy on test set\n",
      "Got 724 / 1000 correct (72.40)\n",
      "24 epoch,  1000 iteration, loss:0.100\n",
      " num 23 epoch \n",
      "####### Training Loss #######\n",
      "[0.11705019]\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "25 epoch,   500 iteration, loss:0.124\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "25 epoch,  1000 iteration, loss:0.122\n",
      " num 24 epoch \n",
      "####### Training Loss #######\n",
      "[0.13450713]\n",
      "Checking accuracy on test set\n",
      "Got 696 / 1000 correct (69.60)\n",
      "26 epoch,   500 iteration, loss:0.133\n",
      "Checking accuracy on test set\n",
      "Got 759 / 1000 correct (75.90)\n",
      "26 epoch,  1000 iteration, loss:0.145\n",
      " num 25 epoch \n",
      "####### Training Loss #######\n",
      "[0.13118026]\n",
      "Checking accuracy on test set\n",
      "Got 742 / 1000 correct (74.20)\n",
      "27 epoch,   500 iteration, loss:0.104\n",
      "Checking accuracy on test set\n",
      "Got 744 / 1000 correct (74.40)\n",
      "27 epoch,  1000 iteration, loss:0.106\n",
      " num 26 epoch \n",
      "####### Training Loss #######\n",
      "[0.10019099]\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "28 epoch,   500 iteration, loss:0.112\n",
      "Checking accuracy on test set\n",
      "Got 733 / 1000 correct (73.30)\n",
      "28 epoch,  1000 iteration, loss:0.104\n",
      " num 27 epoch \n",
      "####### Training Loss #######\n",
      "[0.11793006]\n",
      "Checking accuracy on test set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "29 epoch,   500 iteration, loss:0.090\n",
      "Checking accuracy on test set\n",
      "Got 754 / 1000 correct (75.40)\n",
      "29 epoch,  1000 iteration, loss:0.096\n",
      " num 28 epoch \n",
      "####### Training Loss #######\n",
      "[0.09173181]\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "30 epoch,   500 iteration, loss:0.097\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "30 epoch,  1000 iteration, loss:0.082\n",
      " num 29 epoch \n",
      "####### Training Loss #######\n",
      "[0.09146565]\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "31 epoch,   500 iteration, loss:0.093\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "31 epoch,  1000 iteration, loss:0.067\n",
      " num 30 epoch \n",
      "####### Training Loss #######\n",
      "[0.09127711]\n",
      "Checking accuracy on test set\n",
      "Got 768 / 1000 correct (76.80)\n",
      "32 epoch,   500 iteration, loss:0.069\n",
      "Checking accuracy on test set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "32 epoch,  1000 iteration, loss:0.069\n",
      " num 31 epoch \n",
      "####### Training Loss #######\n",
      "[0.07487074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on test set\n",
      "Got 732 / 1000 correct (73.20)\n",
      "33 epoch,   500 iteration, loss:0.072\n",
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "33 epoch,  1000 iteration, loss:0.082\n",
      " num 32 epoch \n",
      "####### Training Loss #######\n",
      "[0.07437417]\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "34 epoch,   500 iteration, loss:0.075\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "34 epoch,  1000 iteration, loss:0.073\n",
      " num 33 epoch \n",
      "####### Training Loss #######\n",
      "[0.07603262]\n",
      "Checking accuracy on test set\n",
      "Got 741 / 1000 correct (74.10)\n",
      "35 epoch,   500 iteration, loss:0.060\n",
      "Checking accuracy on test set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "35 epoch,  1000 iteration, loss:0.070\n",
      " num 34 epoch \n",
      "####### Training Loss #######\n",
      "[0.07477679]\n",
      "Checking accuracy on test set\n",
      "Got 725 / 1000 correct (72.50)\n",
      "36 epoch,   500 iteration, loss:0.087\n",
      "Checking accuracy on test set\n",
      "Got 739 / 1000 correct (73.90)\n",
      "36 epoch,  1000 iteration, loss:0.085\n",
      " num 35 epoch \n",
      "####### Training Loss #######\n",
      "[0.08332183]\n",
      "Checking accuracy on test set\n",
      "Got 747 / 1000 correct (74.70)\n",
      "37 epoch,   500 iteration, loss:0.054\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "37 epoch,  1000 iteration, loss:0.091\n",
      " num 36 epoch \n",
      "####### Training Loss #######\n",
      "[0.07570489]\n",
      "Checking accuracy on test set\n",
      "Got 726 / 1000 correct (72.60)\n",
      "38 epoch,   500 iteration, loss:0.086\n",
      "Checking accuracy on test set\n",
      "Got 762 / 1000 correct (76.20)\n",
      "38 epoch,  1000 iteration, loss:0.083\n",
      " num 37 epoch \n",
      "####### Training Loss #######\n",
      "[0.08591158]\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "39 epoch,   500 iteration, loss:0.069\n",
      "Checking accuracy on test set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "39 epoch,  1000 iteration, loss:0.055\n",
      " num 38 epoch \n",
      "####### Training Loss #######\n",
      "[0.06297667]\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "40 epoch,   500 iteration, loss:0.069\n",
      "Checking accuracy on test set\n",
      "Got 761 / 1000 correct (76.10)\n",
      "40 epoch,  1000 iteration, loss:0.072\n",
      " num 39 epoch \n",
      "####### Training Loss #######\n",
      "[0.06833102]\n",
      "Checking accuracy on test set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "41 epoch,   500 iteration, loss:0.052\n",
      "Checking accuracy on test set\n",
      "Got 726 / 1000 correct (72.60)\n",
      "41 epoch,  1000 iteration, loss:0.056\n",
      " num 40 epoch \n",
      "####### Training Loss #######\n",
      "[0.06740374]\n",
      "Checking accuracy on test set\n",
      "Got 671 / 1000 correct (67.10)\n",
      "42 epoch,   500 iteration, loss:0.084\n",
      "Checking accuracy on test set\n",
      "Got 730 / 1000 correct (73.00)\n",
      "42 epoch,  1000 iteration, loss:0.077\n",
      " num 41 epoch \n",
      "####### Training Loss #######\n",
      "[0.07418082]\n",
      "Checking accuracy on test set\n",
      "Got 690 / 1000 correct (69.00)\n",
      "43 epoch,   500 iteration, loss:0.073\n",
      "Checking accuracy on test set\n",
      "Got 759 / 1000 correct (75.90)\n",
      "43 epoch,  1000 iteration, loss:0.062\n",
      " num 42 epoch \n",
      "####### Training Loss #######\n",
      "[0.06636671]\n",
      "Checking accuracy on test set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "44 epoch,   500 iteration, loss:0.071\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "44 epoch,  1000 iteration, loss:0.068\n",
      " num 43 epoch \n",
      "####### Training Loss #######\n",
      "[0.07510909]\n",
      "Checking accuracy on test set\n",
      "Got 708 / 1000 correct (70.80)\n",
      "45 epoch,   500 iteration, loss:0.073\n",
      "Checking accuracy on test set\n",
      "Got 749 / 1000 correct (74.90)\n",
      "45 epoch,  1000 iteration, loss:0.079\n",
      " num 44 epoch \n",
      "####### Training Loss #######\n",
      "[0.06762085]\n",
      "Checking accuracy on test set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "46 epoch,   500 iteration, loss:0.051\n",
      "Checking accuracy on test set\n",
      "Got 718 / 1000 correct (71.80)\n",
      "46 epoch,  1000 iteration, loss:0.073\n",
      " num 45 epoch \n",
      "####### Training Loss #######\n",
      "[0.06649649]\n",
      "Checking accuracy on test set\n",
      "Got 725 / 1000 correct (72.50)\n",
      "47 epoch,   500 iteration, loss:0.059\n",
      "Checking accuracy on test set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "47 epoch,  1000 iteration, loss:0.077\n",
      " num 46 epoch \n",
      "####### Training Loss #######\n",
      "[0.06294462]\n",
      "Checking accuracy on test set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "48 epoch,   500 iteration, loss:0.082\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "48 epoch,  1000 iteration, loss:0.052\n",
      " num 47 epoch \n",
      "####### Training Loss #######\n",
      "[0.06319237]\n",
      "Checking accuracy on test set\n",
      "Got 724 / 1000 correct (72.40)\n",
      "49 epoch,   500 iteration, loss:0.052\n",
      "Checking accuracy on test set\n",
      "Got 715 / 1000 correct (71.50)\n",
      "49 epoch,  1000 iteration, loss:0.067\n",
      " num 48 epoch \n",
      "####### Training Loss #######\n",
      "[0.05885147]\n",
      "Checking accuracy on test set\n",
      "Got 756 / 1000 correct (75.60)\n",
      "50 epoch,   500 iteration, loss:0.058\n",
      "Checking accuracy on test set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "50 epoch,  1000 iteration, loss:0.055\n",
      " num 49 epoch \n",
      "####### Training Loss #######\n",
      "[0.0627764]\n",
      "finish training \n",
      "\n",
      "now begin saving datum for next step plotting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Anacondas/anaconda3/envs/cs231n/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type ALL_CNN_C. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now plotting accuracies and losses\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_num = 10\n",
    "net_name = 'tf_ALL_CNN_C_step2_class2'\n",
    "lr = [0.01, 0.005, 0.001, 0.0005]\n",
    "epoch = [35, 40, 45]\n",
    "tf_all_cnn_c_step2_class2 = running_model_B(run_num, tf_all_cnn_c_step1_class2, net_name, \n",
    "                                lr, epoch,loaderB_train, loaderB_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path = '../datum_for_plotting/run_num_10/tf_ALL_CNN_C_step2_class2'\n",
    "f =open(save_path + '/array_epoch_acc.save' , 'rb')\n",
    "acc_array = cPickle.load(f )\n",
    "f.close()\n",
    "a = np.concatenate(acc_array)\n",
    "length = a.shape[0]\n",
    "a /= 100\n",
    "acc_axis_test = np.array(np.linspace(1,length, num=length))\n",
    "plt.plot(acc_axis_test, a.reshape(-1,1), '--r', label='Test')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig(save_path + '/validation_accuracy' + str(max_epoch) + '.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
